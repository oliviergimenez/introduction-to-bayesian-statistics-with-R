[{"path":"index.html","id":"introduction","chapter":"Introduction","heading":"Introduction","text":"Bayesian statistics can found almost everywhere science. example, epidemiology predict spread viruses, ecology understand extinction plant animal species, computer science filter unwanted emails. widespread adoption Bayesian methods past decades largely driven advances computing power. also due nature approach , closely matches learn, reason, accumulate knowledge.book, offer introduction Bayesian statistics. currently reading electronic version book, English version book published Quae March 2026.goals writing book twofold:\n1) synthesize key methodological concepts essential understand, \n2) provide practical tools can apply Bayesian statistics .learn best , use software practice statistics. software R, free open-source environment statistical computing data science.Bayesian analysis specifically, present two practical tools:brms, provides simple familiar syntax similar classical regression modeling R;NIMBLE, requires programming offers great flexibility.Rather adopting formal academic style, chose write book room - video call - explaining Bayesian statistics directly. result, occasionally (sometimes often) use informal language mathematical shortcuts make ideas easier grasp. hope mind.","code":""},{"path":"index.html","id":"why-learn-bayesian-statistics","chapter":"Introduction","heading":"Why learn Bayesian statistics?","text":"Bayesian statistics provides framework analyzing data making decisions uncertainty, much like predicting weather rolling die: know exactly happen, can estimate probability different outcomes.adopt approach? Several reasons may motivate use:natural interpretation probability: Bayesian statistics, probability represents degree belief hypothesis parameter, aligning well intuitively reason uncertainty;Great flexibility: Bayesian framework handles incomplete, heterogeneous, scarce data, well complex models (hierarchical, nonlinear, dynamic, etc.);Integration prior knowledge: previous studies expert knowledge can incorporated transparently formally;Explicit uncertainty quantification: Bayesian inference provides parameter estimates also direct measures uncertainty.","code":""},{"path":"index.html","id":"what-you-will-learn-in-this-book","chapter":"Introduction","heading":"What you will learn in this book","text":"goal guide learning process Bayesian statistics. gathered material consider essential understanding applying approach. end, feel comfortable using Bayesian methods data.objectives :demystify Bayesian statistics Markov chain Monte Carlo (MCMC) methods;understand differences Bayesian frequentist approaches;read interpret “methods” sections scientific articles using Bayesian analysis;implement Bayesian analyses R.Chapter ?? introduces foundations, revisiting key probability concepts presenting core ideas simple example.Chapter 2 takes behind scenes Bayesian inference, explaining MCMC methods guiding coding Bayesian analysis.Chapter ?? introduces two powerful tools Bayesian modeling: NIMBLE brms.Chapter ?? focuses prior distributions—choose , incorporate existing knowledge, avoid common pitfalls.Chapter ?? presents Bayesian linear regression, including model comparison validation, examples using NIMBLE brms.Chapter ?? extends discussion generalized linear models, without random effects, illustrated simulated data.Finally, last chapter summarizes key take-home messages offers practical advice applying Bayesian statistics.","code":""},{"path":"index.html","id":"how-to-read-this-book","chapter":"Introduction","heading":"How to read this book","text":"single “best” way read book. Personally, always find difficult absorb information technical book one pass. may read sequentially dip specific sections needed.chapter, R code provided; hosted https://github.com/oliviergimenez/introduction--bayesian-statistics--R update . Practicing helps better understand check indeed understood. reading electronic version available https://oliviergimenez.github.io/introduction--bayesian-statistics--R, can copy lines code paste R run . save space avoid disrupting reading much, code shown, particular code used produce figures, available https://github.com/oliviergimenez/introduction--bayesian-statistics--R. find () complete R code texts make chapters book (following R Markdown files: index.Rmd, 01-principles.Rmd, 02-mcmcmethods.Rmd, 03-implementation.Rmd, 04-priors.Rmd, 05-regression.Rmd, 06-glms.Rmd 07-conclusions.Rmd) well (ii) R scripts cleaned text allow run code easily (compressed file scriptsR.zip).","code":""},{"path":"index.html","id":"further-reading","chapter":"Introduction","heading":"Further reading","text":"like go , recommend following books, whose list course exhaustive. books source inspiration writing book. hesitated provide references, cite (many) scientific articles, ; books sufficient.Bayesian Methods Ecology (McCarthy 2007). short truly accessible book understand apply Bayesian statistics ecology without getting lost mathematics. book website https://bit.ly/4jSlfQL.Bayesian Methods Ecology (McCarthy 2007). short truly accessible book understand apply Bayesian statistics ecology without getting lost mathematics. book website https://bit.ly/4jSlfQL.Applied Statistical Modelling Ecologists: Practical Guide Bayesian Likelihood Inference Using R, JAGS, NIMBLE, Stan TMB (Kéry Kellner 2010). practical manual learn model main Bayesian tools R (JAGS, NIMBLE, Stan TMB), based concrete ecological examples comparisons results. companion website code https://www.elsevier.com/books--journals/book-companion/9780443137150.Applied Statistical Modelling Ecologists: Practical Guide Bayesian Likelihood Inference Using R, JAGS, NIMBLE, Stan TMB (Kéry Kellner 2010). practical manual learn model main Bayesian tools R (JAGS, NIMBLE, Stan TMB), based concrete ecological examples comparisons results. companion website code https://www.elsevier.com/books--journals/book-companion/9780443137150.Bayes Rules!: Introduction Applied Bayesian Modeling (Johnson, Ott, Dogucu 2022). pedagogical book discover principles applications Bayesian statistics intuitive progressive way. book available online https://www.bayesrulesbook.com/.Bayes Rules!: Introduction Applied Bayesian Modeling (Johnson, Ott, Dogucu 2022). pedagogical book discover principles applications Bayesian statistics intuitive progressive way. book available online https://www.bayesrulesbook.com/.Bayesian Data Analysis: Tutorial R Bugs (Kruschke 2010). thorough visual tutorial guides learning Bayesian statistics step step many practical examples. Everything available https://sites.google.com/site/doingbayesiandataanalysis/.Bayesian Data Analysis: Tutorial R Bugs (Kruschke 2010). thorough visual tutorial guides learning Bayesian statistics step step many practical examples. Everything available https://sites.google.com/site/doingbayesiandataanalysis/.Bayesian Data Analysis (. Gelman et al. 2013). reference book wish acquire solid theoretical applied understanding Bayesian statistics. book website https://sites.stat.columbia.edu/gelman/book/.Bayesian Data Analysis (. Gelman et al. 2013). reference book wish acquire solid theoretical applied understanding Bayesian statistics. book website https://sites.stat.columbia.edu/gelman/book/.Statistical Rethinking: Bayesian Course Examples R Stan (McElreath 2020). captivating book learn build interpret Bayesian models first developing statistical intuition. details https://xcelab.net/rm/, highly recommend video course https://github.com/rmcelreath/stat_rethinking_2024.Statistical Rethinking: Bayesian Course Examples R Stan (McElreath 2020). captivating book learn build interpret Bayesian models first developing statistical intuition. details https://xcelab.net/rm/, highly recommend video course https://github.com/rmcelreath/stat_rethinking_2024.","code":""},{"path":"index.html","id":"how-this-book-was-written","chapter":"Introduction","heading":"How this book was written","text":"book written RStudio (http://www.rstudio.com/ide/) using bookdown package (http://bookdown.org/). website hosted via GitHub Pages (https://pages.github.com/).used R version R-4.5.2_2025-10-31 following packages:","code":""},{"path":"index.html","id":"about-the-author","chapter":"Introduction","heading":"About the author","text":"name Olivier Gimenez (https://oliviergimenez.github.io/). senior scientist CNRS. studying mathematics, completed PhD statistics applied ecology. later obtained habilitation (HDR) ecology evolution returned university study sociology.authored scientific articles (https://oliviergimenez.github.io/publication/papers/) using Bayesian statistics co-written several books (https://oliviergimenez.github.io/publication/books/), also cover Bayesian methods.can find BlueSky (oaggimenez.bsky.social) LinkedIn (olivier-gimenez-545451115/), contact email.","code":""},{"path":"index.html","id":"acknowledgements","chapter":"Introduction","heading":"Acknowledgements","text":"thank employer, French National Centre Scientific Research (CNRS). researcher meaningful valuable profession. However, witnessing gradual deterioration working conditions academia, increased competition, precarity, fewer permanent positions. fortunate work supportive environment Centre Functional Evolutionary Ecology (CEFE), collaboration collective spirit remain strong.interest Bayesian statistics dates back postdoctoral years England Scotland. thank Byron Morgan giving freedom explore field, Ruth King collaborations first experience writing book, Steve Brooks many stimulating discussions.grateful Master’s students taught ten years - unknowingly contributed shaping project. also thank students postdoctoral researchers shared part journey .Thanks people kindly agreed read parts book.Finally, book dedicated Eleni, Gabriel, Mélina.","code":""},{"path":"principes.html","id":"principes","chapter":"1 The Bayesian approach","heading":"1 The Bayesian approach","text":"","code":""},{"path":"principes.html","id":"introduction-1","chapter":"1 The Bayesian approach","heading":"1.1 Introduction","text":"chapter, lay foundations revisiting probability concepts useful later . introduce key ideas Bayesian statistics simple example helps fix ideas, often use throughout book. also draw parallels classical (frequentist) statistics Bayesian statistics.","code":""},{"path":"principes.html","id":"bayes-theorem","chapter":"1 The Bayesian approach","heading":"1.2 Bayes’ theorem","text":"Let us delay get heart matter. Bayesian statistics relies Bayes’ theorem (Bayes’ formula), whose first formulation attributed mathematician Reverend Thomas Bayes. theorem published 1763, two years Bayes’ death, thanks efforts friend Richard Price. also discovered independently Pierre-Simon Laplace.Bayes’ theorem concerns conditional probabilities, can sometimes bit tricky understand. conditional probability event given event B, denoted \\(\\Pr(\\mid B)\\), probability occurs, revised taking account additional information event B occurred. example, imagine one friends rolls (fair) die asks probability result six (). answer 1/6 face die chance appearing. Now, imagine told number obtained even (B) answer. Since three even numbers, one six, can revise answer: \\(\\Pr(\\mid B) = 1/3\\).see additional information (, knowing number even) changes estimate? exactly kind reasoning Bayes’ theorem formalizes generalizes: makes possible compute probability event given another event B occurred. precisely, Bayes’ theorem gives \\(\\Pr(\\mid B)\\) using marginal probabilities \\(\\Pr()\\) \\(\\Pr(B)\\) probability \\(\\Pr(B \\mid )\\):\\[\\Pr(\\mid B) = \\displaystyle{\\frac{ \\Pr(B \\mid ) \\; \\Pr()}{\\Pr(B)}}.\\]talk marginal probability interested probability event “”, without particular condition. example, \\(\\Pr()\\) \\(\\Pr(B)\\) overall chances B, without taking anything else account. say “marginal” , made table possible combinations (instance, die outcomes classified even/odd “six/six”), \\(\\Pr()\\) \\(\\Pr(B)\\) obtained adding cells row column—.e., read margin table.Bayes’ theorem often seen way go effect B back unknown cause , knowing probability effect B given cause . Think, example, situation medical diagnosis needed, unknown disease B symptoms; physician knows risks certain symptoms depending several diseases, .e. \\(\\Pr(\\text{symptoms}|\\text{disease})\\), wishes infer probability disease given symptoms, .e. \\(\\Pr(\\text{disease}|\\text{symptoms})\\). way “reversing” \\(\\Pr(B \\mid )\\) \\(\\Pr(\\mid B)\\) Bayesian reasoning sometimes called “inverse probability”.Rather using letters risk getting confused, find easier remember Bayes’ theorem written like :\\[\\Pr(\\text{hypothesis} \\mid \\text{data}) = \\frac{ \\Pr(\\text{data} \\mid \\text{hypothesis}) \\; \\Pr(\\text{hypothesis})}{\\Pr(\\text{data})}.\\]hypothesis can parameter probability disease occurs, regression coefficients linking probability risk factors (example, place residence, smoking). Bayes’ theorem tells us obtain probability hypothesis available data.\nrelevant , think : exactly scientific method . want know plausible hypothesis given data collected, perhaps compare several hypotheses one another. point view, Bayesian reasoning aligns scientific reasoning, probably explains Bayesian framework feels natural understanding statistics.might ask Bayesian statistics norm. long time, implementing Bayes’ theorem limited computational difficulties, see next chapter. Fortunately, increases computing power development new algorithms led marked rise Bayesian approach past thirty years.","code":""},{"path":"principes.html","id":"statbayes","chapter":"1 The Bayesian approach","heading":"1.3 What is Bayesian statistics?","text":"Typical statistical problems consist estimating one (several) parameters available data. Let us denote parameter (parameters) generically, say \\(\\text{theta}\\). estimate \\(\\text{theta}\\), probably familiar frequentist approach Bayesian approach. frequentist approach, particular maximum likelihood estimation, assumes parameters fixed unknown. Classical estimators therefore generally point values; instance, estimator probability obtaining face die number times face observed divided number times die rolled. Bayesian approach assumes parameters fixed follow unknown distribution. probability distribution mathematical expression gives probability random variable takes certain values. can discrete (example, Bernoulli distribution, binomial distribution, Poisson distribution) continuous (normal Gaussian distribution).Bayesian approach rests idea start knowledge system even studying . , collect data update prior knowledge based observations. updating process relies Bayes’ theorem. simplified form, taking \\(= \\text{theta}\\) \\(B = \\text{data}\\), Bayes’ theorem makes possible estimate parameter \\(\\text{theta}\\) data follows:\\[\\Pr(\\text{theta} \\mid \\text{data}) = \\frac{\\Pr(\\text{data} \\mid \\text{theta}) \\times \\Pr(\\text{theta})}{\\Pr(\\text{data})}.\\]Let us take moment review term formula.left, \\(\\Pr(\\text{theta} \\mid \\text{data})\\), posterior distribution: probability \\(\\text{theta}\\) given data. represents know \\(\\text{theta}\\) seeing data. basis inference precisely looking : distribution, possibly multivariate several parameters.right, \\(\\Pr(\\text{data} \\mid \\text{theta})\\), likelihood. probability data given \\(\\text{theta}\\). quantity classical frequentist approach. Yes: Bayesian frequentist approaches share component, likelihood, explains results often close. likelihood expresses information contained data, given model parameterized \\(\\text{theta}\\). come back Section 1.5.Next, \\(\\Pr(\\text{theta})\\), prior distribution. quantity represents know \\(\\text{theta}\\) seeing data. prior distribution depend data; words, one use data construct . can vague non-informative know nothing \\(\\text{theta}\\). Often, never really start zero, ideally like prior reflect existing knowledge. discuss priors detail Chapter ??.Finally, denominator \\(\\Pr(\\text{data})\\), sometimes called average likelihood, averaged respect prior, obtained integrating likelihood prior distribution:\n\\({\\Pr(\\text{data}) = \\int{\\Pr(\\text{data} \\mid \\text{theta}) \\times \\Pr(\\text{theta}) \\, d\\text{theta}}}\\).\nquantity normalizes posterior distribution integrates 1. words, since \\(\\int{\\Pr(\\text{theta} \\mid \\text{data}) \\, d\\text{theta}} = 1\\) integral probability density equals 1, \n\\(\\displaystyle \\int{\\frac{\\Pr(\\text{data} \\mid \\text{theta}) \\times \\Pr(\\text{theta})}{\\Pr(\\text{data})} \\, d\\text{theta} } = 1\\).\nsince \\(\\Pr(\\text{data})\\) depend \\(\\text{theta}\\), \n\\(\\Pr(\\text{data}) = \\int{\\Pr(\\text{data} \\mid \\text{theta}) \\times \\Pr(\\text{theta}) \\, d\\text{theta}}\\).\nintegral whose dimension equals number parameters \\(\\text{theta}\\) estimate: two parameters, double integral; three parameters, triple integral; . However, beyond three dimensions, becomes difficult, even impossible, compute integral. one reasons Bayesian approach used earlier, need algorithms estimate posterior distributions, explain Chapter 2. meantime, work relatively simple example posterior distribution explicit form.","code":""},{"path":"principes.html","id":"a-running-example","chapter":"1 The Bayesian approach","heading":"1.4 A running example","text":"Let us take concrete example fix ideas. work coypu (Myocastor coypus) (Figure 1.1), semi-aquatic rodent native South America, introduced Europe fur farming. now considered invasive alien species, damage causes wetlands (bank erosion, destruction vegetation) possible role transmitting leptospirosis humans, potentially severe bacterial infection transmitted water. Thanks high fecundity good adaptation temperate climates, coypu proliferated rapidly.\nFigure 1.1: Photograph coypus (Myocastor coypus) taken Lez watershed near Montpellier, France. Credits: Yann Raulet.\nOne questions interested estimating probability surviving winter, coypus particularly sensitive cold. , equip several individuals GPS tag beginning winter, say \\(n = 57\\). end winter, observe \\(y = 19\\) coypus still alive. goal estimate winter survival probability, denote \\(\\text{theta}\\). data:probably thinking , information, can already estimate survival probability. Intuitively, think proportion individuals survived, .e. \\(19/57\\). wrong. reasonable estimate \\(\\text{theta}\\), winter survival probability. Let us now try formalize intuition, order better understand represents, assumes.mentioned , likelihood central concept found frequentist Bayesian approaches. let us start constructing likelihood. , need make assumptions.First, assume individuals independent, meaning survival one coypu influence survival coypus. strong assumption, especially know female can reproduce two three times per year give birth ten offspring depend early life. , modeling, often better start simple.Second, assume individuals survival probability. , simplification: know, example, juvenile mortality higher adult mortality.two assumptions, number \\(y\\) animals still alive end winter follows binomial distribution, \\(\\text{theta}\\) probability success (survival) \\(n\\) number trials (monitored individuals). write \\(y \\sim \\text{Bin}(n, \\text{theta})\\). binomial distribution fact sum several independent Bernoulli trials, classic heads--tails example. trial—, release GPS-tagged coypu beginning winter—assume probability \\(\\text{theta}\\) success, .e. surviving winter, failure, .e. dying cold. trials independent probability success (assumptions), number successes, number coypus alive end winter, follows binomial distribution (see also Chapter ??). provide examples Bernoulli binomial draws Figure 1.2.\nFigure 1.2: Discrete probability distributions, Bernoulli binomial, illustrated 100 simulations (random draws generated computer). top row, show observed frequency Bernoulli draw different values survival probability \\(\\theta\\). bottom row, show histograms binomial draw 50 trials different values survival probability \\(\\theta\\).\naside, easy get mixed terms used describe Bernoulli binomial distribution (normal distribution): can remember probability number, distribution law, density function represents .","code":"\ny <- 19 # number of individuals that survived the winter\nn <- 57 # number of individuals monitored at the start of winter"},{"path":"principes.html","id":"maxvrais","chapter":"1 The Bayesian approach","heading":"1.5 Maximum likelihood","text":"classical (frequentist) approach, estimate survival probability \\(\\text{theta}\\) using maximum likelihood method. mean practice? means finding value \\(\\text{theta}\\) makes observed data likely. words, since data —observed—look value \\(\\text{theta}\\) maximizes probability dataset generated.justify rather intuitive idea mathematically? Read carefully end previous paragraph. idea looking value gives largest probability amounts maximizing something. exactly? probability data, given certain model parameterized \\(\\text{theta}\\)—words, likelihood, \\(\\Pr(\\text{data}|\\text{theta})\\), saw Section 1.3. Classical estimation therefore relies maximizing likelihood—rather likelihood function, .e. likelihood considered function \\(\\text{theta}\\).case, binomial experiment: follow \\(n\\) coypus winter, probability \\(\\text{theta}\\) surviving. know probability possible outcome (probability mass function). example, probability coypu survives \\((1-\\text{theta})^n\\), \\(n\\) individuals dies probability \\(1-\\text{theta}\\). take, example, survival probability 0.5, \\((1-0.5)^{57} \\approx 0\\). can compute probability R dbinom() function:first argument x = 0 corresponds coypu alive. Conversely, probability survive \\(\\text{theta}^n\\), value. can check R dbinom(x = 57, size = 57, prob = 0.5). exactly one coypu survives, one \\(n\\) survives probability \\(\\text{theta}\\), \\(n-1\\) die probability \\((1-\\text{theta})^{n-1}\\). Since \\(n\\) coypus can one survives, obtain total probability \\(n,\\text{theta},(1-\\text{theta})^{n-1}\\). can compute probability dbinom(x = 1, size = 57, prob = 0.5). generally, probability \\(y\\) individuals survive given \\(\\displaystyle \\binom{n}{y}\\text{theta}^y(1-\\text{theta})^{n-y}\\). consider expression function \\(\\text{theta}\\) (\\(y\\)), obtain likelihood function \\(\\displaystyle \\mathcal{L}(\\text{theta}) = \\binom{n}{y} \\text{theta}^y (1 - \\text{theta})^{n - y}\\). term \\(\\displaystyle \\binom{n}{y}\\) called binomial coefficient read “\\(y\\) \\(n\\)”. corresponds number different ways choose \\(y\\) survivors among \\(n\\) coypus, without regard order.can plot likelihood R Figure 1.3:\nFigure 1.3: Likelihood function winter survival probability coypu, computed \\(y=19\\) survivors \\(n=57\\) individuals monitored GPS. maximum likelihood estimate indicated red dashed line.\ngoal find value \\(\\text{theta}\\) maximizes function. words, look survival value (x-axis Figure 1.3) maximizes likelihood (y-axis). value corresponds maximum likelihood estimator, often denoted \\(\\hat{\\text{theta}}\\). , often convenient work logarithm likelihood (log-likelihood), sums numerically stable easier differentiate products:\\[\n\\ell(\\theta) = \\log \\mathcal{L}(\\theta) = \\log \\binom{n}{y} + y \\log \\theta + (n - y) \\log (1 - \\theta).\n\\]\nfirst term, \\(\\displaystyle \\log \\binom{n}{y}\\), depend \\(\\text{theta}\\), can ignore follows. differentiate log-likelihood respect \\(\\text{theta}\\):\\[\n\\displaystyle \\frac{d\\ell(\\theta)}{d\\theta} = \\frac{y}{\\theta} - \\frac{n - y}{1 - \\theta}.\n\\]look value \\(\\text{theta}\\) makes derivative equal zero:\\[\n\\frac{y}{\\theta} - \\frac{n - y}{1 - \\theta} = 0.\n\\]simplifications, obtain maximum likelihood estimator \\(\\hat{\\text{theta}}\\) :\\[\n\\hat{\\theta} = \\frac{y}{n}.\n\\]result matches initial intuition: maximum likelihood estimator proportion individuals survived, .e. \\(19/57 \\approx 0.333\\). can visualize result Figure 1.3, maximum likelihood estimate indicated red dashed line.practice, models contain multiple parameters—dozens even hundreds—apply analytic method maximize likelihood find maximum likelihood estimators. Instead, use iterative optimization algorithms solve problem us, adjusting step step initial value find one maximizes likelihood. example, R, can obtain exactly result using logistic regression without covariates (see Chapter ??):direct calculation \\(\\hat{\\text{theta}}=y/n\\) result calling glm function consistent: give value.","code":"\ndbinom(x = 0, size = 57, prob = 1 - 0.5)\n#> [1] 6.938894e-18\nmod <- glm(cbind(y, n - y) ~ 1, family = binomial)\ntheta_hat <- plogis(coef(mod))\ntheta_hat\n#> (Intercept) \n#>   0.3333333"},{"path":"principes.html","id":"and-in-the-bayesian-framework","chapter":"1 The Bayesian approach","heading":"1.6 And in the Bayesian framework?","text":"Bayesian approach, start expressing prior knowledge quantity want estimate—, winter survival probability theta. know theta continuous variable 0 1. natural prior distribution case beta distribution. beta distribution defined two parameters, \\(\\) \\(b\\), control shape:\\[\nq(\\theta \\mid , b) = \\frac{1}{\\text{Beta}(, b)}{\\theta^{- 1}} {(1-\\theta)^{b - 1}}\n\\]:\\[\n\\text{Beta}(, b) = \\frac{\\Gamma()\\Gamma(b)}{\\Gamma(+b)}, \\quad \\Gamma(n) = (n-1)!\n\\]can forget equations comfortable . Let us instead visualize distribution Figure 1.4:\nFigure 1.4: Examples beta distributions different values parameters \\(\\) \\(b\\). panel, shaded areas illustrate probability observing value within given interval.\npanel figure shows shape beta distribution given pair parameters \\((, b)\\). Several characteristic behaviors can observed.Beta(1,1) (top left) corresponds uniform distribution 0 1: values theta 0 1 considered equally likely. density constant, means probability observing value 0.1 0.2 observing one 0.8 0.9. probability area rectangle bounded red curve vertical lines 0.1 0.2 (0.8 0.9), .e. red shaded areas. corresponds situation prior knowledge.Beta(2,1) Beta(1,2) represent asymmetric knowledge: former biased toward values close 1, latter toward values close 0. probability observing value 0.1 0.2 smaller observing one 0.8 0.9, vice versa.Beta(2,2) symmetric puts weight central values uniform distribution. probability observing value 0.1 0.2 smaller observing one 0.5 0.6.Beta(10,10) represents knowledge highly concentrated around 0.5: informative prior. probability observing value 0.2 0.3 much smaller observing one 0.5 0.6.Beta(0.8,0.8) illustrates U-shaped (bathtub-shaped) distribution favors extreme values (close 0 1). probabilities observing value 0 0.1 0.9 1 larger observing one 0.45 0.55.examples make possible visualize parameters \\(\\) \\(b\\) influence shape prior. go prior posterior distribution?assume \\(\\theta \\sim \\text{Beta}(, b)\\) observed \\(y = 19\\) survivors among \\(n = 57\\) individuals. likelihood \\(\\displaystyle \\binom{n}{y}\\theta^y(1 - \\theta)^{n - y}\\). now, ignore denominator \\(\\Pr(y)\\) Bayes’ theorem; see next chapter . Thus, posterior proportional product likelihood prior:\n\\(\\Pr(\\theta \\mid y) \\propto \\Pr(y \\mid \\theta) \\times \\Pr(\\theta)\\).\ncase, multiply likelihood prior term term, rearranging terms \\(\\theta\\) \\(1-\\theta\\), obtain:\\[\n\\begin{aligned}\n\\Pr(\\theta \\mid y) &\\propto \\underbrace{\\theta^y (1 - \\theta)^{n - y}}_{\\text{binomial likelihood}} \\times \\underbrace{\\theta^{- 1} (1 - \\theta)^{b - 1}}_{\\text{beta prior}} \\\\\n&\\propto \\underbrace{\\theta^{+ y - 1} (1 - \\theta)^{b + n - y - 1}}_{\\text{yet another beta distribution}}\n\\end{aligned}\n\\]words, obtain beta distribution, updated parameters \\(+ y\\) \\(b + n - y\\). say binomial beta distributions conjugate: use beta distribution prior probability parameter binomial model, resulting posterior distribution also beta distribution. use uniform prior 0 1 (.e. Beta(1,1)), obtain posterior distribution winter survival \n\\(\\text{Beta}(1+19, 1+57-19) = \\text{Beta}(20, 39)\\).\nMoreover, posterior distribution known, greatly facilitates computations interpretation. example, know mean \\(\\text{Beta}(, b)\\) \\(\\displaystyle \\frac{}{+b}\\), .e. \\(\\frac{20}{59} \\approx 0.339\\). can compare value maximum likelihood estimator \\(19/57 \\approx 0.333\\). can also visualize posterior distribution Figure (ref?)(fig:posterior-survie), since know equation beta density:\nFigure 1.5: Distribution priori uniforme (rouge) et distribution posteriori (noire) de la probabilité de survie hivernale du ragondin. Le pointillé bleu correspond à l’estimateur du maximum de vraisemblance.\ngenerally, enough data, Bayesian frequentist estimators tend close. Intuitively, data end “dominating” prior information. Roughly speaking, mode posterior distribution (value density maximal) corresponds exactly maximum likelihood estimator.illustrates link two approaches central role likelihood statistics: fundamental common component Bayesian frequentist approaches.","code":""},{"path":"principes.html","id":"in-summary","chapter":"1 The Bayesian approach","heading":"1.7 In summary","text":"Bayes’ theorem tool updating knowledge.Bayesian statistics relies likelihood prior distribution model parameters.Frequentist statistics provides point estimator, whereas Bayesian statistics estimates distribution parameter.Often, classical Bayesian approaches yield similar estimates.cases, posterior distribution explicit (example, case beta/binomial conjugacy).cases, need use simulations obtain posterior distribution, see Chapter 2.","code":""},{"path":"mcmc.html","id":"mcmc","chapter":"2 MCMC methods","heading":"2 MCMC methods","text":"","code":""},{"path":"mcmc.html","id":"introduction-2","chapter":"2 MCMC methods","heading":"2.1 Introduction","text":"hope lose (much) previous chapter equations. new chapter, go behind scenes Bayesian statistics introducing Markov chain Monte Carlo (MCMC) methods. see simulation techniques become essential implementing Bayesian inference practice. nothing beats practice, get hands little dirty coding , using running example estimating survival probability.","code":""},{"path":"mcmc.html","id":"applying-bayes-theorem","chapter":"2 MCMC methods","heading":"2.2 Applying Bayes’ theorem","text":"Let us return running example coypus; repeat data:Let us apply Bayes’ theorem directly Chapter 1, set aside denominator \\(\\Pr(\\text{data})\\). Let us see whether can handle . saw, denominator given \n\\(\\displaystyle \\Pr(\\text{y}) = \\int{\\Pr(\\text{data} \\mid \\theta) \\Pr(\\theta) \\, d\\theta}\\).\ncompute integral. Let us start writing R function computes product (binomial) likelihood prior (Beta(1,1)), .e. numerator Bayes’ theorem, \\(\\Pr(\\text{data} \\mid \\theta) \\times \\Pr(\\theta)\\):can now write function computes denominator. , use R’s integrate() function, computes integral one-variable function. integrate() function uses quadrature techniques approximate area curve defined function integrate, breaking small pieces summing .obtain numerical approximation posterior distribution winter survival, Figure 2.1:\nFigure 2.1: Numerical approximation posterior distribution winter survival.\ngood numerical approximation? Ideally, like compare approximation true posterior distribution. Conveniently, obtained Chapter 1: beta distribution parameters 20 39. Figure 2.2, can see two curves overlap perfectly.\nFigure 2.2: Comparison exact posterior (brick red) numerical approximation (cream).\nexact posterior distribution (brick red) numerical approximation (cream) winter survival indistinguishable, suggesting numerical approximation satisfactory.example, single parameter estimate: winter survival. means denominator involves one-dimensional integral, fairly easy handle quadrature techniques R’s integrate() function.happens several parameters? example, imagine want fit regression model survival depends explanatory variable, say coypu body mass. effect variable captured regression parameters \\(\\beta_0\\) (intercept) \\(\\beta_1\\) (slope), also residual error standard deviation \\(\\sigma\\) (see Chapter ??). Bayes’ theorem gives joint posterior distribution parameters (.e. three parameters together):\\[ \\displaystyle \\Pr(\\beta_0, \\beta_1, \\sigma \\mid \\text{y}) = \\frac{ \\Pr(\\text{y} \\mid \\beta_0, \\beta_1, \\sigma) \\times \\Pr(\\beta_0, \\beta_1, \\sigma)}{\\displaystyle \\iiint \\Pr(\\text{y} \\mid \\beta_0, \\beta_1, \\sigma) \\Pr(\\beta_0, \\beta_1, \\sigma) \\, d\\beta_0 \\, d\\beta_1 \\, d\\sigma} \\]two major numerical challenges:really want compute triple integral? , classical methods rarely go much beyond two dimensions.often interested marginal distributions parameters (example, \\(\\beta_1\\), effect mass survival), obtained integrating joint posterior distribution parameters (, double integral respect \\(\\beta_0\\) $) — quickly becomes intractable number parameters increases.next section, introduce powerful simulation methods overcome limitations.","code":"\ny <- 19 # number of individuals that survived the winter\nn <- 57 # number of individuals monitored at the start of winter\nnum <- function(theta) dbinom(y, n, theta) * dbeta(theta, 1, 1)\nden <- integrate(num, 0, 1)$value\n# Create a grid of possible values for the survival probability (between 0 and 1)\ngrid <- seq(0, 1, 0.01)\n\n# Compute posterior density values on the grid\n# num(grid) is likelihood * prior, and den is the normalizing constant\nposterior <- data.frame(\n  survival = grid,\n  ratio = num(grid) / den  # normalized posterior density\n)\n\n# Plot the posterior density curve\nposterior %>%\n  ggplot(aes(x = survival, y = ratio)) +\n  geom_line(size = 1.5) +\n  labs(x = \"Survival probability\", y = \"Density\") +\n  theme_minimal()"},{"path":"mcmc.html","id":"mcmc-algorithms","chapter":"2 MCMC methods","heading":"2.3 MCMC algorithms","text":"short, idea Markov chain Monte Carlo (MCMC) methods use simulations approximate posterior distributions given precision drawing large number samples. avoids explicit computation multidimensional integrals arise applying Bayes’ theorem.simulation algorithms consist two parts: Markov chains Monte Carlo. Let us try understand two terms.Monte Carlo mean? Monte Carlo integration simulation technique used compute integrals arbitrary functions \\(f\\) random variable \\(X\\) distribution \\(\\Pr(X)\\), \\(\\displaystyle \\int f(X) \\Pr(X) dX\\). draw values \\(X_1, \\ldots, X_k\\) \\(\\Pr(X)\\), apply function \\(f\\) values, compute mean resulting values, \\(\\displaystyle{\\frac{1}{k}}\\sum_{=1}^k{f(X_i)}\\), approximate integral.use Monte Carlo integration Bayesian context? posterior distribution contains information need parameter(s) want estimate. multiple parameters, often want summarize information computing numerical summaries. simplest summary posterior mean,\n\\(E(\\theta) = \\int \\theta \\Pr(\\theta \\mid \\text{data}) \\, d\\theta\\),\n\\(X\\) \\(\\theta\\) \\(f\\) identity. posterior mean can estimated Monte Carlo integration; example, coypu survival:can verify resulting mean close theoretical expectation beta distribution:Another useful numerical summary credible interval within parameter lies given probability, usually 0.95, .e. 95% credible interval. Determining bounds interval requires computing quantiles, also relies integrals, therefore Monte Carlo integration. 95% credible interval winter survival can obtained :way, difference credible interval Bayesian statistics confidence interval frequentist statistics. 95% confidence interval means repeated experiment large number times (tag coypus GPS record number winter survivors), 95% intervals constructed way contain true parameter value \\(\\theta\\). say probability parameter lies within given interval 95%. 95% credible interval, contrast, means 95% probability parameter lies within interval. interpretation credible interval bit intuitive confidence interval.Now, Markov chain? Markov chain random sequence numbers number depends previous one. One example weather city, Montpellier, south France, sunny day likely followed another sunny day, say probability 0.8, rainy day rarely followed another rainy day, say probability 0.1. dynamics Markov chain captured transition matrix:\\[\n\\begin{array}{c|cc}\n& \\text{Sunny tomorrow} & \\text{Rainy tomorrow} \\\\ \\\\ \\hline\n\\text{Sunny today} & 0.8 & 0.2 \\\\\\\\\n\\text{Rainy today}   & 0.9 & 0.1\n\\end{array}\n\\]Rows indicate today’s weather columns indicate tomorrow’s. cells give probability sunny rainy day tomorrow depending today’s weather (conditional probabilities; see Chapter 1).certain conditions, Markov chain converges unique stationary distribution. weather example, let us iterate chain 20 steps:row matrix converges toward distribution \\((0.82, 0.18)\\) number steps increases. convergence occurs regardless starting state: probability 0.82 sun 0.18 rain.Let us return MCMC methods. central idea can construct Markov chain whose stationary distribution precisely posterior distribution parameters. Keep idea mind: fundamental.combining Monte Carlo Markov chains, MCMC methods allow us generate sample values whose distribution converges posterior distribution (Markov chain) use sample compute posterior numerical summaries (Monte Carlo), mean credible intervals.several ways build Markov chains Bayesian inference. may heard Metropolis–Hastings algorithm Gibbs sampler. can consult https://chi-feng.github.io/mcmc-demo/ interactive gallery MCMC algorithms. , illustrate Metropolis algorithm practical implementation. draw inspiration excellent book Jim Albert (2009). goal able write algorithm scratch, grasp main ideas , , notion simulation.Let us return survival example. illustrate sampling posterior distribution survival. Let us start writing functions likelihood, prior, posterior. work log scale manipulate sums differences rather products ratios, can make numerical calculations unstable:Metropolis algorithm works follows:Choose initial value parameter estimate. starting value, initial point Markov chain.Choose initial value parameter estimate. starting value, initial point Markov chain.decide next step, propose moving away current parameter value—candidate value. add current value draw normal distribution variance—proposal distribution. Metropolis algorithm special case Metropolis–Hastings symmetric proposals.decide next step, propose moving away current parameter value—candidate value. add current value draw normal distribution variance—proposal distribution. Metropolis algorithm special case Metropolis–Hastings symmetric proposals.Compute ratio posterior densities candidate position current position:\n\\(R = \\displaystyle \\frac{\\Pr(\\text{candidate value}|\\text{data})}{\\Pr(\\text{current value}|\\text{data})}\\).\ncompute numerator denominator, simply apply Bayes’ theorem, magic MCMC happens: \\(\\Pr(\\text{data})\\) appears numerator denominator, cancels, longer need compute . replaced computation integral simulations.Compute ratio posterior densities candidate position current position:\n\\(R = \\displaystyle \\frac{\\Pr(\\text{candidate value}|\\text{data})}{\\Pr(\\text{current value}|\\text{data})}\\).\ncompute numerator denominator, simply apply Bayes’ theorem, magic MCMC happens: \\(\\Pr(\\text{data})\\) appears numerator denominator, cancels, longer need compute . replaced computation integral simulations.posterior density candidate position larger current position, .e. candidate value plausible, accept immediately. Otherwise, accept probability \\(R\\), reject probability \\(1 - R\\). example, candidate value ten times less plausible, accept probability 0.1. use uniform random number 0 1 (call \\(X\\)): \\(X < R\\), accept candidate value; otherwise, stay current value. practice, aim acceptance rate 0.2 0.4, can adjusted calibrating proposal variance; helps explore whole parameter space.posterior density candidate position larger current position, .e. candidate value plausible, accept immediately. Otherwise, accept probability \\(R\\), reject probability \\(1 - R\\). example, candidate value ten times less plausible, accept probability 0.1. use uniform random number 0 1 (call \\(X\\)): \\(X < R\\), accept candidate value; otherwise, stay current value. practice, aim acceptance rate 0.2 0.4, can adjusted calibrating proposal variance; helps explore whole parameter space.Repeat steps 2 4 certain number times—iterations.Repeat steps 2 4 certain number times—iterations.Enough theory: let us implement . start initializing:need initialize? running Markov chain, prepare objects store simulated values parameter (, survival probability) well information whether proposal accepted. set.seed(666) ? command sets seed random number generator. ensures simulations reproducible: rerun code, obtain exactly simulated values mine.choose starting value:starting value? Markov chain start somewhere: , arbitrarily choose 0.5 initial value survival probability. constraint value must compatible prior: going pick negative survival probability 15. place value first element theta.post, indicate accept[1] <- 1 first value accepted construction, since starting point.Next, write function propose candidate value current value:function introduces random proposal around current value. work logit scale ensure final proposal (candidate) always remains interval (0,1) (see also Chapter ??). away parameter controls spread proposals: larger , larger jumps; smaller , closer proposals remain current value.implement steps 2 4 algorithm loop (step 5: repeating iterations):loop builds Markov chain iteratively. probability accepting less plausible value proportional likelihood ratio. accept vector can used diagnose acceptance frequency, useful calibrating chain.Let us take look first last simulated values:can now visualize chain’s evolution trace plot, .e. curve showing simulated values theta across iterations (Figure 2.3):\nFigure 2.3: Trace plot simulated values survival probability \\(\\theta\\) across iterations.\ntrace plot tell us? horizontal axis represents iterations (“time” Markov chain). vertical axis shows simulated values survival probability step. figure, see chain sometimes stays value several consecutive iterations. happens candidate value proposed algorithm rejected—chain retains previous (precisely, current) value. times, see jumps new values, corresponding accepted proposals.can wrap algorithm reusable function, making easy run multiple chains:can now use metropolis() run another chain, time starting 0.2:Note often talk “running multiple MCMC chains” diagnose convergence. practice, independent realizations Markov chain—like flipping coin multiple times, except complicated distribution Bernoulli.plot chains together, Figure 2.4:\nFigure 2.4: Trace plot simulated values survival probability \\(\\theta\\) across iterations. Two chains run different initial values, 0.5 blue 0.2 yellow.\nNote obtain exactly results algorithm stochastic. observe parallel evolution two chains started different initial values. two chains quickly meet oscillate around values, indicates good convergence toward desired stationary distribution. key step MCMC convergence diagnostics, cover later chapter. observe convergence longer period, run chain 1,000 iterations. gives smoother trace plot showing chain stability, Figure 2.5:\nFigure 2.5: Trace plot simulated values survival probability \\(\\theta\\) across 1000 iterations.\nlarge number iterations, chain stabilize around stationary distribution. Visually, look dense, homogeneous, well-explored region—like neatly mown lawn (image).stationary distribution reached, can treat simulated values Markov chain sample posterior distribution compute numerical summaries parameters (posterior mean, credible interval).can say reached stationary distribution? convergence, many additional simulations need obtain good approximation posterior distribution parameters? address questions next section.","code":"\n# draw 1000 values from the Beta(20,39) posterior\nsample_from_posterior <- rbeta(1000, 20, 39)\n# compute the mean by Monte Carlo integration\nmean(sample_from_posterior)\n#> [1] 0.3405089\n20/(20+39) # expectation of the Beta(20,39) distribution\n#> [1] 0.3389831\nquantile(sample_from_posterior, probs = c(2.5/100, 97.5/100))\n#>      2.5%     97.5% \n#> 0.2270862 0.4702974\ntemps <- matrix(c(0.8, 0.2, 0.9, 0.1), nrow = 2, byrow = T) # transition matrix\netapes <- 20\nfor (i in 1:etapes){\n  temps <- temps %*% temps # matrix multiplication\n}\nround(temps, 2) # matrix product after 20 steps\n#>      [,1] [,2]\n#> [1,] 0.82 0.18\n#> [2,] 0.82 0.18\n# 19 animals found alive out of 57 captured, marked and released\ny <- 19\nn <- 57\n\n# binomial log-likelihood Bin(n = 57,p)\nloglikelihood <- function(x, p){\n  dbinom(x = x, size = n, prob = p, log = TRUE)\n}\n\n# uniform prior density\nlogprior <- function(p){\n  dunif(x = p, min = 0, max = 1, log = TRUE)\n  # or dbeta(x = p, shape1 = 0, shape2 = 1, log = TRUE)\n}\n\n# posterior density (log scale)\nposterior <- function(x, p){\n  loglikelihood(x, p) + logprior(p)\n}\nsteps <- 100 # number of steps (iterations) of the chain\ntheta.post <- rep(NA, steps) # vector to store simulated values\naccept <- rep(NA, steps) # vector to record accept/reject decisions\nset.seed(666) # for reproducibility\ninits <- 0.5 # chosen starting value for theta\ntheta.post[1] <- inits # record this value as the first position of the chain\naccept[1] <- 1 # the initial value is accepted by default\nmove <- function(x, away = 1){\n  logitx <- log(x / (1 - x)) # logit transform: maps x from (0,1) to (-∞,+∞)\n  logit_candidate <- logitx + rnorm(1, 0, away) # add centered normal noise, sd controlled by away\n  candidate <- plogis(logit_candidate) # inverse transform (logit^-1): returns a value between 0 and 1\n  return(candidate) # return proposed value\n}\nfor (t in 2:steps){ # for each iteration, starting at the 2nd\n\n  # Step 2: propose a new value for theta\n  theta_star <- move(theta.post[t-1])  # candidate drawn from the previous value\n\n  # Step 3: compute the ratio of posterior densities (log scale)\n  pstar <- posterior(y, p = theta_star) # posterior density at candidate\n  pprev <- posterior(y, p = theta.post[t-1]) # posterior density at current value\n  logR <- pstar - pprev # difference on the log scale\n  R <- exp(logR) # back to the natural scale (density ratio)\n\n  # Step 4: accept or reject the proposal\n  X <- runif(1, 0, 1) # random draw between 0 and 1: the acceptance \"roulette\"\n  if (X < R){ # if the proposal is more plausible (or not too much worse)\n    theta.post[t] <- theta_star # accept and store the candidate\n    accept[t] <- 1 # record acceptance\n  } else {\n    theta.post[t] <- theta.post[t-1] # otherwise keep the previous value\n    accept[t] <- 0 # record rejection\n  }\n}\nhead(theta.post)\n#> [1] 0.5000000 0.5000000 0.3021903 0.3021903 0.1853669 0.1853669\ntail(theta.post)\n#> [1] 0.4076667 0.4076667 0.4076667 0.4076667 0.2914464 0.2914464\nmetropolis <- function(steps = 100, inits = 0.5, away = 1){\n\n  theta.post <- rep(NA, steps) # vector to store samples\n  theta.post[1] <- inits # initialize with starting value\n\n  for (t in 2:steps){ # loop over steps (starting at the 2nd)\n\n    theta_star <- move(theta.post[t-1], away) # propose a new value\n\n    # log-ratio of posterior density between candidate and current value\n    logR <- posterior(y, theta_star) -\n            posterior(y, theta.post[t-1])\n    R <- exp(logR) # back to non-log scale\n\n    X <- runif(1, 0, 1) # draw a uniform random number\n    theta.post[t] <- ifelse(X < R, # if draw < acceptance probability...\n                            theta_star, # ... accept proposed value\n                            theta.post[t-1]) # otherwise keep previous\n  }\n\n  return(theta.post) # return simulated sample\n}\ntheta.post2 <- metropolis(steps = 100, inits = 0.2) # start at 0.2"},{"path":"mcmc.html","id":"convergence-diag","chapter":"2 MCMC methods","heading":"2.4 Assessing convergence","text":"applying MCMC method, need determine long takes Markov chain converge target distribution, many additional iterations required convergence obtain reliable Monte Carlo estimates numerical summaries (posterior means, credible intervals).","code":""},{"path":"mcmc.html","id":"burn-in","chapter":"2 MCMC methods","heading":"2.4.1 Burn-in","text":"practice, discard first values Markov chain use values simulated convergence. initial observations discard generally called burn-(warm-) period.simplest way determine length burn-period inspect trace plots. Let us return example look Figure 2.6, trace plot chain starting 0.99:\nFigure 2.6: Trace plot chain starting 0.99. shaded area illustrates possible burn-period.\nchain starts 0.99 stabilizes quickly, values oscillating around 0.3 iteration 100 onward. can choose shaded area burn-period discard first 100 values. safe, one use 250 even 500 iterations burn-, provided cost much computation time, course.Inspecting trace plot single chain useful, generally run multiple chains different initial values check reach stationary distribution. approach formalized Brooks–Gelman–Rubin statistic (BGR), denoted \\(\\hat{R}\\), measures ratio total variability (chains plus within chain) within-chain variability. close spirit \\(F\\) test analysis variance (, one-factor ANOVA factor levels chains). value 1.1 indicates likely convergence.Let us return example: run two Markov chains initial values 0.2 0.8, varying number iterations 100 1000 steps 50, compute BGR statistic using half iterations burn-(Figure 2.7).\nFigure 2.7: Value Brooks–Gelman–Rubin (BGR) statistic function number iterations. value close 1 suggests convergence.\nobtain BGR statistic close 1 300 iterations onward, suggesting burn-300 iterations, nothing indicates convergence problem.important remember value close 1 BGR statistic necessary sufficient condition convergence. words, diagnostic assert certainty chain converged; simply indicates detect obvious sign . advice: always take time look trace plots.","code":""},{"path":"mcmc.html","id":"chain-length","chapter":"2 MCMC methods","heading":"2.4.2 Chain length","text":"chain length needed obtain reliable parameter estimates? Keep mind successive steps Markov chain independent. called autocorrelation. Ideally, want minimize autocorrelation., trace plots can diagnose autocorrelation issues. Returning survival example, Figure 2.8 shows trace plots (3000 iterations) different values proposal normal standard deviation (parameter away) used generate candidate values.\nFigure 2.8: Trace plots different values proposal standard deviation (away). Good mixing observed away = 1. shaded gray area corresponds burn-300 iterations.\nsmall large moves visible left right panels lead strong correlation successive observations Markov chain, whereas standard deviation equal 1 (center) allows efficient exploration parameter space. movement parameter space called mixing. Mixing considered poor chain makes jumps small large, good otherwise.addition trace plots, autocorrelation function (ACF) plots provide convenient way visualize strength autocorrelation given sample. ACF plots show correlation successively sampled values separated increasing number iterations, called lag. Figure 2.9, obtain ACF plots different proposal standard deviations using forecast::ggAcf():\nFigure 2.9: Autocorrelation functions (ACF) different proposal standard deviations. Low autocorrelation sign good mixing. burn-300 iterations applied.\nleft right panels, autocorrelation strong decreases slowly lag, mixing poor. central panel, autocorrelation weak decreases quickly lag, mixing good.Autocorrelation necessarily major problem. Highly correlated observations simply require larger number samples, therefore longer simulations. many iterations need exactly? effective sample size (n.eff) measures useful length chain accounting autocorrelation. recommended check n.eff parameter interest, well relevant combination parameters. general, consider need least \\(\\text{n.eff} \\geq 400\\) independent observations obtain reliable Monte Carlo estimates model parameters. animal survival example, n.eff can computed using effectiveSize() function coda package:expected, n.eff smaller total number MCMC iterations (3000) autocorrelation. proposal standard deviation equals 1 mixing good (n.eff \\(\\geq 400\\)), yielding satisfactory effective sample size.","code":"\n# Generate chains for three proposal standard deviations\nd <- tibble(away = c(0.1, 1, 10)) %>%\n     mutate(accepted_traj = map(away,\n                               metropolis,\n                               steps = n_steps,\n                               inits = 0.1)) %>%\n     unnest(accepted_traj) %>%\n     mutate(proposal_sd = str_c(\"SD = \", away),\n            iter = rep(1:n_steps, times = 3))\n\n# Compute effective sample size\nneff1 <- coda::effectiveSize(d$accepted_traj[d$proposal_sd==\"SD = 0.1\"][-c(1:300)])\nneff2 <- coda::effectiveSize(d$accepted_traj[d$proposal_sd==\"SD = 1\"][-c(1:300)])\nneff3 <- coda::effectiveSize(d$accepted_traj[d$proposal_sd==\"SD = 10\"][-c(1:300)])\ntibble(\"SD\" = c(0.1, 1, 10),\n       \"n.eff\" = round(c(neff1, neff2, neff3)))\n#> # A tibble: 3 × 2\n#>      SD n.eff\n#>   <dbl> <dbl>\n#> 1   0.1    81\n#> 2   1     524\n#> 3  10      77"},{"path":"mcmc.html","id":"what-if-you-have-convergence-problems","chapter":"2 MCMC methods","heading":"2.4.3 What if you have convergence problems?","text":"diagnosing convergence MCMC chain, () often encounter difficulties. section offers practical tips hope useful.mixing poor effective sample size low, may enough increase burn-period /increase number simulations. Using informative priors can also facilitate convergence Markov chains helping MCMC algorithm explore parameter space efficiently (Chapter ??). spirit, choosing better initial values start chain can also help. useful strategy use estimates simpler model MCMC chains already converge.convergence problems persist, often issue model . bug code? typo? error equations? often case programming, best way identify problem reduce model’s complexity start simpler model find wrong.Another piece advice think model first foremost data generator. Simulate data model using realistic parameter values, try recover parameters fitting model simulated data. approach help better understand model works, , much data needed obtain reliable parameter estimates. return technique Chapters ?? ??.","code":""},{"path":"mcmc.html","id":"in-summary-1","chapter":"2 MCMC methods","heading":"2.5 In summary","text":"idea Markov chain Monte Carlo (MCMC) methods simulate values Markov chain whose stationary distribution precisely posterior distribution parameters want estimate.idea Markov chain Monte Carlo (MCMC) methods simulate values Markov chain whose stationary distribution precisely posterior distribution parameters want estimate.practice, run several Markov chains starting dispersed initial values.practice, run several Markov chains starting dispersed initial values.discard first iterations (warm-burn-phase) consider convergence reached chains converge regime.discard first iterations (warm-burn-phase) consider convergence reached chains converge regime.point , run chains long enough compute Monte Carlo estimates numerical summaries (example, posterior means credible intervals) parameters.point , run chains long enough compute Monte Carlo estimates numerical summaries (example, posterior means credible intervals) parameters.course, want build implement MCMC methods hand every new analysis, Chapter ?? see make easier.course, want build implement MCMC methods hand every new analysis, Chapter ?? see make easier.","code":""},{"path":"conclusions.html","id":"conclusions","chapter":"Conclusions","heading":"Conclusions","text":"","code":""},{"path":"conclusions.html","id":"what-we-covered","chapter":"Conclusions","heading":"What we covered","text":"hope book (least little) demystified Bayesian statistics MCMC methods. also hope given tools understand difference frequentist Bayesian approaches, better read “Methods” section papers using Bayesian statistics, gain certain level autonomy conducting Bayesian analyses.Throughout book, covered several essential steps. began exploring motivations using Bayesian approach. introduced Bayes’ theorem discussed interpretation. discovered Markov chain Monte Carlo (MCMC) methods, worked two powerful tools, NIMBLE brms, fit complex models. Particular attention given role prior distributions, whether non-informative informative, well use approaches case studies involving GLM GLMM.","code":""},{"path":"conclusions.html","id":"bayesian-statistics-in-a-nutshell","chapter":"Conclusions","heading":"Bayesian statistics, in a nutshell","text":"Bayesian approach offers many advantages. allows uncertainty quantified coherently using probability, enables explicit integration prior knowledge, makes possible fit complex models via MCMC. addition, Bayesian credible intervals intuitive frequentist confidence intervals.caution nevertheless required. Checking convergence MCMC chains crucial step, sometimes laborious one. choice prior distributions requires careful consideration. Model fit must always evaluated. Finally, computational cost negligible, especially complex models /large datasets.","code":""},{"path":"conclusions.html","id":"a-few-tips","chapter":"Conclusions","heading":"A few tips","text":"finishing, like leave tips inspired experience. tips necessarily specific Bayesian statistics, worth worth.First, take time clearly formulate question. may seem obvious, step essential stay track make right choices, example deciding use subset data answer specific question.Next, think model first, formalize either equations, drawing , words. nature data, therefore, regression framework, family distributions use saw Chapters ?? (normal) ?? (Bernoulli/binomial Poisson)? rush keyboard. Make sure understand , example explaining colleagues.note, remember run simulations. Simulating data model often helps understand better, Chapters ?? ??. excellent way test assumptions diagnose potential issues.Choose R environment comfortable ; illustrated brms NIMBLE (Chapter 2), solutions exist.fitting model, start simple. model parameters constant good baseline. ensures data read formatted correctly, outliers (extra zero, misplaced comma), priors generate unexpected behavior (see Chapter ??). approach particularly important Bayesian statistics ensure good performance convergence MCMC algorithm (Chapter 2), also giving idea time required run analysis. everything looks good, gradually add complexity, random effects example (Chapter ??), reach model structure seems appropriate answer question. likely implies several iterations fitting, comparing, validating models (Chapters ?? ??).practical guidance, recommend reading papers “Ten quick tips get started Bayesian statistics” (Gimenez et al. 2025) “Bayesian workflow” (Andrew Gelman et al. 2020).","code":""},{"path":"conclusions.html","id":"to-conclude","chapter":"Conclusions","heading":"To conclude","text":"Adopt pragmatic approach. choice statistical approach (frequentist Bayesian) depends objectives, whether concern speed, model complexity, type uncertainty want quantify. Discuss options experienced colleagues needed. Bayesian statistics dogma: powerful tool among others toolbox.Thank attention. Feel free write questions like see particular aspect developed new edition book. enjoy exploring Bayesian statistics!","code":""},{"path":"références.html","id":"références","chapter":"Références","heading":"Références","text":"","code":""}]
