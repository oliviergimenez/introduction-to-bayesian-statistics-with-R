[{"path":"index.html","id":"introduction","chapter":"Introduction","heading":"Introduction","text":"Bayesian statistics can found almost everywhere science. example, epidemiology predict spread viruses, ecology understand extinction plant animal species, computer science filter unwanted emails. widespread adoption Bayesian methods past decades largely driven advances computing power. also due nature approach , closely matches learn, reason, accumulate knowledge.book, offer introduction Bayesian statistics. currently reading electronic version book, English version book published Quae March 2026.goals writing book twofold:\n1) synthesize key methodological concepts essential understand, \n2) provide practical tools can apply Bayesian statistics .learn best , use software practice statistics. software R, free open-source environment statistical computing data science.Bayesian analysis specifically, present two practical tools:brms, provides simple familiar syntax similar classical regression modeling R;NIMBLE, requires programming offers great flexibility.Rather adopting formal academic style, chose write book room - video call - explaining Bayesian statistics directly. result, occasionally (sometimes often) use informal language mathematical shortcuts make ideas easier grasp. hope mind.","code":""},{"path":"index.html","id":"why-learn-bayesian-statistics","chapter":"Introduction","heading":"Why learn Bayesian statistics?","text":"Bayesian statistics provides framework analyzing data making decisions uncertainty, much like predicting weather rolling die: know exactly happen, can estimate probability different outcomes.adopt approach? Several reasons may motivate use:natural interpretation probability: Bayesian statistics, probability represents degree belief hypothesis parameter, aligning well intuitively reason uncertainty;Great flexibility: Bayesian framework handles incomplete, heterogeneous, scarce data, well complex models (hierarchical, nonlinear, dynamic, etc.);Integration prior knowledge: previous studies expert knowledge can incorporated transparently formally;Explicit uncertainty quantification: Bayesian inference provides parameter estimates also direct measures uncertainty.","code":""},{"path":"index.html","id":"what-you-will-learn-in-this-book","chapter":"Introduction","heading":"What you will learn in this book","text":"goal guide learning process Bayesian statistics. gathered material consider essential understanding applying approach. end, feel comfortable using Bayesian methods data.objectives :demystify Bayesian statistics Markov chain Monte Carlo (MCMC) methods;understand differences Bayesian frequentist approaches;read interpret “methods” sections scientific articles using Bayesian analysis;implement Bayesian analyses R.Chapter ?? introduces foundations, revisiting key probability concepts presenting core ideas simple example.Chapter 2 takes behind scenes Bayesian inference, explaining MCMC methods guiding coding Bayesian analysis.Chapter ?? introduces two powerful tools Bayesian modeling: NIMBLE brms.Chapter 4 focuses prior distributions—choose , incorporate existing knowledge, avoid common pitfalls.Chapter 5 presents Bayesian linear regression, including model comparison validation, examples using NIMBLE brms.Chapter 6 extends discussion generalized linear models, without random effects, illustrated simulated data.Finally, last chapter summarizes key take-home messages offers practical advice applying Bayesian statistics.","code":""},{"path":"index.html","id":"how-to-read-this-book","chapter":"Introduction","heading":"How to read this book","text":"single “best” way read book. Personally, always find difficult absorb information technical book one pass. may read sequentially dip specific sections needed.chapter, R code provided; hosted https://github.com/oliviergimenez/introduction--bayesian-statistics--R update . Practicing helps better understand check indeed understood. reading electronic version available https://oliviergimenez.github.io/introduction--bayesian-statistics--R, can copy lines code paste R run . save space avoid disrupting reading much, code shown, particular code used produce figures, available https://github.com/oliviergimenez/introduction--bayesian-statistics--R. find () complete R code texts make chapters book (following R Markdown files: index.Rmd, 01-principles.Rmd, 02-mcmcmethods.Rmd, 03-implementation.Rmd, 04-priors.Rmd, 05-regression.Rmd, 06-glms.Rmd 07-conclusions.Rmd) well (ii) R scripts cleaned text allow run code easily (compressed file scriptsR.zip).","code":""},{"path":"index.html","id":"further-reading","chapter":"Introduction","heading":"Further reading","text":"like go , recommend following books, whose list course exhaustive. books source inspiration writing book. hesitated provide references, cite (many) scientific articles, ; books sufficient.Bayesian Methods Ecology (McCarthy 2007). short truly accessible book understand apply Bayesian statistics ecology without getting lost mathematics. book website https://bit.ly/4jSlfQL.Bayesian Methods Ecology (McCarthy 2007). short truly accessible book understand apply Bayesian statistics ecology without getting lost mathematics. book website https://bit.ly/4jSlfQL.Applied Statistical Modelling Ecologists: Practical Guide Bayesian Likelihood Inference Using R, JAGS, NIMBLE, Stan TMB (Kéry Kellner 2010). practical manual learn model main Bayesian tools R (JAGS, NIMBLE, Stan TMB), based concrete ecological examples comparisons results. companion website code https://www.elsevier.com/books--journals/book-companion/9780443137150.Applied Statistical Modelling Ecologists: Practical Guide Bayesian Likelihood Inference Using R, JAGS, NIMBLE, Stan TMB (Kéry Kellner 2010). practical manual learn model main Bayesian tools R (JAGS, NIMBLE, Stan TMB), based concrete ecological examples comparisons results. companion website code https://www.elsevier.com/books--journals/book-companion/9780443137150.Bayes Rules!: Introduction Applied Bayesian Modeling (Johnson, Ott, Dogucu 2022). pedagogical book discover principles applications Bayesian statistics intuitive progressive way. book available online https://www.bayesrulesbook.com/.Bayes Rules!: Introduction Applied Bayesian Modeling (Johnson, Ott, Dogucu 2022). pedagogical book discover principles applications Bayesian statistics intuitive progressive way. book available online https://www.bayesrulesbook.com/.Bayesian Data Analysis: Tutorial R Bugs (Kruschke 2010). thorough visual tutorial guides learning Bayesian statistics step step many practical examples. Everything available https://sites.google.com/site/doingbayesiandataanalysis/.Bayesian Data Analysis: Tutorial R Bugs (Kruschke 2010). thorough visual tutorial guides learning Bayesian statistics step step many practical examples. Everything available https://sites.google.com/site/doingbayesiandataanalysis/.Bayesian Data Analysis (. Gelman et al. 2013). reference book wish acquire solid theoretical applied understanding Bayesian statistics. book website https://sites.stat.columbia.edu/gelman/book/.Bayesian Data Analysis (. Gelman et al. 2013). reference book wish acquire solid theoretical applied understanding Bayesian statistics. book website https://sites.stat.columbia.edu/gelman/book/.Statistical Rethinking: Bayesian Course Examples R Stan (McElreath 2020). captivating book learn build interpret Bayesian models first developing statistical intuition. details https://xcelab.net/rm/, highly recommend video course https://github.com/rmcelreath/stat_rethinking_2024.Statistical Rethinking: Bayesian Course Examples R Stan (McElreath 2020). captivating book learn build interpret Bayesian models first developing statistical intuition. details https://xcelab.net/rm/, highly recommend video course https://github.com/rmcelreath/stat_rethinking_2024.","code":""},{"path":"index.html","id":"how-this-book-was-written","chapter":"Introduction","heading":"How this book was written","text":"book written RStudio (http://www.rstudio.com/ide/) using bookdown package (http://bookdown.org/). website hosted via GitHub Pages (https://pages.github.com/).used R version R-4.5.2_2025-10-31 following packages:","code":""},{"path":"index.html","id":"about-the-author","chapter":"Introduction","heading":"About the author","text":"name Olivier Gimenez (https://oliviergimenez.github.io/). senior scientist CNRS. studying mathematics, completed PhD statistics applied ecology. later obtained habilitation (HDR) ecology evolution returned university study sociology.authored scientific articles (https://oliviergimenez.github.io/publication/papers/) using Bayesian statistics co-written several books (https://oliviergimenez.github.io/publication/books/), also cover Bayesian methods.can find BlueSky (oaggimenez.bsky.social) LinkedIn (olivier-gimenez-545451115/), contact email.","code":""},{"path":"index.html","id":"acknowledgements","chapter":"Introduction","heading":"Acknowledgements","text":"thank employer, French National Centre Scientific Research (CNRS). researcher meaningful valuable profession. However, witnessing gradual deterioration working conditions academia, increased competition, precarity, fewer permanent positions. fortunate work supportive environment Centre Functional Evolutionary Ecology (CEFE), collaboration collective spirit remain strong.interest Bayesian statistics dates back postdoctoral years England Scotland. thank Byron Morgan giving freedom explore field, Ruth King collaborations first experience writing book, Steve Brooks many stimulating discussions.grateful Master’s students taught ten years - unknowingly contributed shaping project. also thank students postdoctoral researchers shared part journey .Thanks people kindly agreed read parts book.Finally, book dedicated Eleni, Gabriel, Mélina.","code":""},{"path":"principes.html","id":"principes","chapter":"1 The Bayesian approach","heading":"1 The Bayesian approach","text":"","code":""},{"path":"principes.html","id":"introduction-1","chapter":"1 The Bayesian approach","heading":"1.1 Introduction","text":"chapter, lay foundations revisiting probability concepts useful later . introduce key ideas Bayesian statistics simple example helps fix ideas, often use throughout book. also draw parallels classical (frequentist) statistics Bayesian statistics.","code":""},{"path":"principes.html","id":"bayes-theorem","chapter":"1 The Bayesian approach","heading":"1.2 Bayes’ theorem","text":"Let us delay get heart matter. Bayesian statistics relies Bayes’ theorem (Bayes’ formula), whose first formulation attributed mathematician Reverend Thomas Bayes. theorem published 1763, two years Bayes’ death, thanks efforts friend Richard Price. also discovered independently Pierre-Simon Laplace.Bayes’ theorem concerns conditional probabilities, can sometimes bit tricky understand. conditional probability event given event B, denoted \\(\\Pr(\\mid B)\\), probability occurs, revised taking account additional information event B occurred. example, imagine one friends rolls (fair) die asks probability result six (). answer 1/6 face die chance appearing. Now, imagine told number obtained even (B) answer. Since three even numbers, one six, can revise answer: \\(\\Pr(\\mid B) = 1/3\\).see additional information (, knowing number even) changes estimate? exactly kind reasoning Bayes’ theorem formalizes generalizes: makes possible compute probability event given another event B occurred. precisely, Bayes’ theorem gives \\(\\Pr(\\mid B)\\) using marginal probabilities \\(\\Pr()\\) \\(\\Pr(B)\\) probability \\(\\Pr(B \\mid )\\):\\[\\Pr(\\mid B) = \\displaystyle{\\frac{ \\Pr(B \\mid ) \\; \\Pr()}{\\Pr(B)}}.\\]talk marginal probability interested probability event “”, without particular condition. example, \\(\\Pr()\\) \\(\\Pr(B)\\) overall chances B, without taking anything else account. say “marginal” , made table possible combinations (instance, die outcomes classified even/odd “six/six”), \\(\\Pr()\\) \\(\\Pr(B)\\) obtained adding cells row column—.e., read margin table.Bayes’ theorem often seen way go effect B back unknown cause , knowing probability effect B given cause . Think, example, situation medical diagnosis needed, unknown disease B symptoms; physician knows risks certain symptoms depending several diseases, .e. \\(\\Pr(\\text{symptoms}|\\text{disease})\\), wishes infer probability disease given symptoms, .e. \\(\\Pr(\\text{disease}|\\text{symptoms})\\). way “reversing” \\(\\Pr(B \\mid )\\) \\(\\Pr(\\mid B)\\) Bayesian reasoning sometimes called “inverse probability”.Rather using letters risk getting confused, find easier remember Bayes’ theorem written like :\\[\\Pr(\\text{hypothesis} \\mid \\text{data}) = \\frac{ \\Pr(\\text{data} \\mid \\text{hypothesis}) \\; \\Pr(\\text{hypothesis})}{\\Pr(\\text{data})}.\\]hypothesis can parameter probability disease occurs, regression coefficients linking probability risk factors (example, place residence, smoking). Bayes’ theorem tells us obtain probability hypothesis available data.\nrelevant , think : exactly scientific method . want know plausible hypothesis given data collected, perhaps compare several hypotheses one another. point view, Bayesian reasoning aligns scientific reasoning, probably explains Bayesian framework feels natural understanding statistics.might ask Bayesian statistics norm. long time, implementing Bayes’ theorem limited computational difficulties, see next chapter. Fortunately, increases computing power development new algorithms led marked rise Bayesian approach past thirty years.","code":""},{"path":"principes.html","id":"statbayes","chapter":"1 The Bayesian approach","heading":"1.3 What is Bayesian statistics?","text":"Typical statistical problems consist estimating one (several) parameters available data. Let us denote parameter (parameters) generically, say \\(\\text{theta}\\). estimate \\(\\text{theta}\\), probably familiar frequentist approach Bayesian approach. frequentist approach, particular maximum likelihood estimation, assumes parameters fixed unknown. Classical estimators therefore generally point values; instance, estimator probability obtaining face die number times face observed divided number times die rolled. Bayesian approach assumes parameters fixed follow unknown distribution. probability distribution mathematical expression gives probability random variable takes certain values. can discrete (example, Bernoulli distribution, binomial distribution, Poisson distribution) continuous (normal Gaussian distribution).Bayesian approach rests idea start knowledge system even studying . , collect data update prior knowledge based observations. updating process relies Bayes’ theorem. simplified form, taking \\(= \\text{theta}\\) \\(B = \\text{data}\\), Bayes’ theorem makes possible estimate parameter \\(\\text{theta}\\) data follows:\\[\\Pr(\\text{theta} \\mid \\text{data}) = \\frac{\\Pr(\\text{data} \\mid \\text{theta}) \\times \\Pr(\\text{theta})}{\\Pr(\\text{data})}.\\]Let us take moment review term formula.left, \\(\\Pr(\\text{theta} \\mid \\text{data})\\), posterior distribution: probability \\(\\text{theta}\\) given data. represents know \\(\\text{theta}\\) seeing data. basis inference precisely looking : distribution, possibly multivariate several parameters.right, \\(\\Pr(\\text{data} \\mid \\text{theta})\\), likelihood. probability data given \\(\\text{theta}\\). quantity classical frequentist approach. Yes: Bayesian frequentist approaches share component, likelihood, explains results often close. likelihood expresses information contained data, given model parameterized \\(\\text{theta}\\). come back Section 1.5.Next, \\(\\Pr(\\text{theta})\\), prior distribution. quantity represents know \\(\\text{theta}\\) seeing data. prior distribution depend data; words, one use data construct . can vague non-informative know nothing \\(\\text{theta}\\). Often, never really start zero, ideally like prior reflect existing knowledge. discuss priors detail Chapter 4.Finally, denominator \\(\\Pr(\\text{data})\\), sometimes called average likelihood, averaged respect prior, obtained integrating likelihood prior distribution:\n\\({\\Pr(\\text{data}) = \\int{\\Pr(\\text{data} \\mid \\text{theta}) \\times \\Pr(\\text{theta}) \\, d\\text{theta}}}\\).\nquantity normalizes posterior distribution integrates 1. words, since \\(\\int{\\Pr(\\text{theta} \\mid \\text{data}) \\, d\\text{theta}} = 1\\) integral probability density equals 1, \n\\(\\displaystyle \\int{\\frac{\\Pr(\\text{data} \\mid \\text{theta}) \\times \\Pr(\\text{theta})}{\\Pr(\\text{data})} \\, d\\text{theta} } = 1\\).\nsince \\(\\Pr(\\text{data})\\) depend \\(\\text{theta}\\), \n\\(\\Pr(\\text{data}) = \\int{\\Pr(\\text{data} \\mid \\text{theta}) \\times \\Pr(\\text{theta}) \\, d\\text{theta}}\\).\nintegral whose dimension equals number parameters \\(\\text{theta}\\) estimate: two parameters, double integral; three parameters, triple integral; . However, beyond three dimensions, becomes difficult, even impossible, compute integral. one reasons Bayesian approach used earlier, need algorithms estimate posterior distributions, explain Chapter 2. meantime, work relatively simple example posterior distribution explicit form.","code":""},{"path":"principes.html","id":"a-running-example","chapter":"1 The Bayesian approach","heading":"1.4 A running example","text":"Let us take concrete example fix ideas. work coypu (Myocastor coypus) (Figure 1.1), semi-aquatic rodent native South America, introduced Europe fur farming. now considered invasive alien species, damage causes wetlands (bank erosion, destruction vegetation) possible role transmitting leptospirosis humans, potentially severe bacterial infection transmitted water. Thanks high fecundity good adaptation temperate climates, coypu proliferated rapidly.\nFigure 1.1: Photograph coypus (Myocastor coypus) taken Lez watershed near Montpellier, France. Credits: Yann Raulet.\nOne questions interested estimating probability surviving winter, coypus particularly sensitive cold. , equip several individuals GPS tag beginning winter, say \\(n = 57\\). end winter, observe \\(y = 19\\) coypus still alive. goal estimate winter survival probability, denote \\(\\text{theta}\\). data:probably thinking , information, can already estimate survival probability. Intuitively, think proportion individuals survived, .e. \\(19/57\\). wrong. reasonable estimate \\(\\text{theta}\\), winter survival probability. Let us now try formalize intuition, order better understand represents, assumes.mentioned , likelihood central concept found frequentist Bayesian approaches. let us start constructing likelihood. , need make assumptions.First, assume individuals independent, meaning survival one coypu influence survival coypus. strong assumption, especially know female can reproduce two three times per year give birth ten offspring depend early life. , modeling, often better start simple.Second, assume individuals survival probability. , simplification: know, example, juvenile mortality higher adult mortality.two assumptions, number \\(y\\) animals still alive end winter follows binomial distribution, \\(\\text{theta}\\) probability success (survival) \\(n\\) number trials (monitored individuals). write \\(y \\sim \\text{Bin}(n, \\text{theta})\\). binomial distribution fact sum several independent Bernoulli trials, classic heads--tails example. trial—, release GPS-tagged coypu beginning winter—assume probability \\(\\text{theta}\\) success, .e. surviving winter, failure, .e. dying cold. trials independent probability success (assumptions), number successes, number coypus alive end winter, follows binomial distribution (see also Chapter 6). provide examples Bernoulli binomial draws Figure 1.2.\nFigure 1.2: Discrete probability distributions, Bernoulli binomial, illustrated 100 simulations (random draws generated computer). top row, show observed frequency Bernoulli draw different values survival probability \\(\\theta\\). bottom row, show histograms binomial draw 50 trials different values survival probability \\(\\theta\\).\naside, easy get mixed terms used describe Bernoulli binomial distribution (normal distribution): can remember probability number, distribution law, density function represents .","code":"\ny <- 19 # number of individuals that survived the winter\nn <- 57 # number of individuals monitored at the start of winter"},{"path":"principes.html","id":"maxvrais","chapter":"1 The Bayesian approach","heading":"1.5 Maximum likelihood","text":"classical (frequentist) approach, estimate survival probability \\(\\text{theta}\\) using maximum likelihood method. mean practice? means finding value \\(\\text{theta}\\) makes observed data likely. words, since data —observed—look value \\(\\text{theta}\\) maximizes probability dataset generated.justify rather intuitive idea mathematically? Read carefully end previous paragraph. idea looking value gives largest probability amounts maximizing something. exactly? probability data, given certain model parameterized \\(\\text{theta}\\)—words, likelihood, \\(\\Pr(\\text{data}|\\text{theta})\\), saw Section 1.3. Classical estimation therefore relies maximizing likelihood—rather likelihood function, .e. likelihood considered function \\(\\text{theta}\\).case, binomial experiment: follow \\(n\\) coypus winter, probability \\(\\text{theta}\\) surviving. know probability possible outcome (probability mass function). example, probability coypu survives \\((1-\\text{theta})^n\\), \\(n\\) individuals dies probability \\(1-\\text{theta}\\). take, example, survival probability 0.5, \\((1-0.5)^{57} \\approx 0\\). can compute probability R dbinom() function:first argument x = 0 corresponds coypu alive. Conversely, probability survive \\(\\text{theta}^n\\), value. can check R dbinom(x = 57, size = 57, prob = 0.5). exactly one coypu survives, one \\(n\\) survives probability \\(\\text{theta}\\), \\(n-1\\) die probability \\((1-\\text{theta})^{n-1}\\). Since \\(n\\) coypus can one survives, obtain total probability \\(n,\\text{theta},(1-\\text{theta})^{n-1}\\). can compute probability dbinom(x = 1, size = 57, prob = 0.5). generally, probability \\(y\\) individuals survive given \\(\\displaystyle \\binom{n}{y}\\text{theta}^y(1-\\text{theta})^{n-y}\\). consider expression function \\(\\text{theta}\\) (\\(y\\)), obtain likelihood function \\(\\displaystyle \\mathcal{L}(\\text{theta}) = \\binom{n}{y} \\text{theta}^y (1 - \\text{theta})^{n - y}\\). term \\(\\displaystyle \\binom{n}{y}\\) called binomial coefficient read “\\(y\\) \\(n\\)”. corresponds number different ways choose \\(y\\) survivors among \\(n\\) coypus, without regard order.can plot likelihood R Figure 1.3:\nFigure 1.3: Likelihood function winter survival probability coypu, computed \\(y=19\\) survivors \\(n=57\\) individuals monitored GPS. maximum likelihood estimate indicated red dashed line.\ngoal find value \\(\\text{theta}\\) maximizes function. words, look survival value (x-axis Figure 1.3) maximizes likelihood (y-axis). value corresponds maximum likelihood estimator, often denoted \\(\\hat{\\text{theta}}\\). , often convenient work logarithm likelihood (log-likelihood), sums numerically stable easier differentiate products:\\[\n\\ell(\\theta) = \\log \\mathcal{L}(\\theta) = \\log \\binom{n}{y} + y \\log \\theta + (n - y) \\log (1 - \\theta).\n\\]\nfirst term, \\(\\displaystyle \\log \\binom{n}{y}\\), depend \\(\\text{theta}\\), can ignore follows. differentiate log-likelihood respect \\(\\text{theta}\\):\\[\n\\displaystyle \\frac{d\\ell(\\theta)}{d\\theta} = \\frac{y}{\\theta} - \\frac{n - y}{1 - \\theta}.\n\\]look value \\(\\text{theta}\\) makes derivative equal zero:\\[\n\\frac{y}{\\theta} - \\frac{n - y}{1 - \\theta} = 0.\n\\]simplifications, obtain maximum likelihood estimator \\(\\hat{\\text{theta}}\\) :\\[\n\\hat{\\theta} = \\frac{y}{n}.\n\\]result matches initial intuition: maximum likelihood estimator proportion individuals survived, .e. \\(19/57 \\approx 0.333\\). can visualize result Figure 1.3, maximum likelihood estimate indicated red dashed line.practice, models contain multiple parameters—dozens even hundreds—apply analytic method maximize likelihood find maximum likelihood estimators. Instead, use iterative optimization algorithms solve problem us, adjusting step step initial value find one maximizes likelihood. example, R, can obtain exactly result using logistic regression without covariates (see Chapter 6):direct calculation \\(\\hat{\\text{theta}}=y/n\\) result calling glm function consistent: give value.","code":"\ndbinom(x = 0, size = 57, prob = 1 - 0.5)\n#> [1] 6.938894e-18\nmod <- glm(cbind(y, n - y) ~ 1, family = binomial)\ntheta_hat <- plogis(coef(mod))\ntheta_hat\n#> (Intercept) \n#>   0.3333333"},{"path":"principes.html","id":"and-in-the-bayesian-framework","chapter":"1 The Bayesian approach","heading":"1.6 And in the Bayesian framework?","text":"Bayesian approach, start expressing prior knowledge quantity want estimate—, winter survival probability theta. know theta continuous variable 0 1. natural prior distribution case beta distribution. beta distribution defined two parameters, \\(\\) \\(b\\), control shape:\\[\nq(\\theta \\mid , b) = \\frac{1}{\\text{Beta}(, b)}{\\theta^{- 1}} {(1-\\theta)^{b - 1}}\n\\]:\\[\n\\text{Beta}(, b) = \\frac{\\Gamma()\\Gamma(b)}{\\Gamma(+b)}, \\quad \\Gamma(n) = (n-1)!\n\\]can forget equations comfortable . Let us instead visualize distribution Figure 1.4:\nFigure 1.4: Examples beta distributions different values parameters \\(\\) \\(b\\). panel, shaded areas illustrate probability observing value within given interval.\npanel figure shows shape beta distribution given pair parameters \\((, b)\\). Several characteristic behaviors can observed.Beta(1,1) (top left) corresponds uniform distribution 0 1: values theta 0 1 considered equally likely. density constant, means probability observing value 0.1 0.2 observing one 0.8 0.9. probability area rectangle bounded red curve vertical lines 0.1 0.2 (0.8 0.9), .e. red shaded areas. corresponds situation prior knowledge.Beta(2,1) Beta(1,2) represent asymmetric knowledge: former biased toward values close 1, latter toward values close 0. probability observing value 0.1 0.2 smaller observing one 0.8 0.9, vice versa.Beta(2,2) symmetric puts weight central values uniform distribution. probability observing value 0.1 0.2 smaller observing one 0.5 0.6.Beta(10,10) represents knowledge highly concentrated around 0.5: informative prior. probability observing value 0.2 0.3 much smaller observing one 0.5 0.6.Beta(0.8,0.8) illustrates U-shaped (bathtub-shaped) distribution favors extreme values (close 0 1). probabilities observing value 0 0.1 0.9 1 larger observing one 0.45 0.55.examples make possible visualize parameters \\(\\) \\(b\\) influence shape prior. go prior posterior distribution?assume \\(\\theta \\sim \\text{Beta}(, b)\\) observed \\(y = 19\\) survivors among \\(n = 57\\) individuals. likelihood \\(\\displaystyle \\binom{n}{y}\\theta^y(1 - \\theta)^{n - y}\\). now, ignore denominator \\(\\Pr(y)\\) Bayes’ theorem; see next chapter . Thus, posterior proportional product likelihood prior:\n\\(\\Pr(\\theta \\mid y) \\propto \\Pr(y \\mid \\theta) \\times \\Pr(\\theta)\\).\ncase, multiply likelihood prior term term, rearranging terms \\(\\theta\\) \\(1-\\theta\\), obtain:\\[\n\\begin{aligned}\n\\Pr(\\theta \\mid y) &\\propto \\underbrace{\\theta^y (1 - \\theta)^{n - y}}_{\\text{binomial likelihood}} \\times \\underbrace{\\theta^{- 1} (1 - \\theta)^{b - 1}}_{\\text{beta prior}} \\\\\n&\\propto \\underbrace{\\theta^{+ y - 1} (1 - \\theta)^{b + n - y - 1}}_{\\text{yet another beta distribution}}\n\\end{aligned}\n\\]words, obtain beta distribution, updated parameters \\(+ y\\) \\(b + n - y\\). say binomial beta distributions conjugate: use beta distribution prior probability parameter binomial model, resulting posterior distribution also beta distribution. use uniform prior 0 1 (.e. Beta(1,1)), obtain posterior distribution winter survival \n\\(\\text{Beta}(1+19, 1+57-19) = \\text{Beta}(20, 39)\\).\nMoreover, posterior distribution known, greatly facilitates computations interpretation. example, know mean \\(\\text{Beta}(, b)\\) \\(\\displaystyle \\frac{}{+b}\\), .e. \\(\\frac{20}{59} \\approx 0.339\\). can compare value maximum likelihood estimator \\(19/57 \\approx 0.333\\). can also visualize posterior distribution Figure (ref?)(fig:posterior-survie), since know equation beta density:\nFigure 1.5: Distribution priori uniforme (rouge) et distribution posteriori (noire) de la probabilité de survie hivernale du ragondin. Le pointillé bleu correspond à l’estimateur du maximum de vraisemblance.\ngenerally, enough data, Bayesian frequentist estimators tend close. Intuitively, data end “dominating” prior information. Roughly speaking, mode posterior distribution (value density maximal) corresponds exactly maximum likelihood estimator.illustrates link two approaches central role likelihood statistics: fundamental common component Bayesian frequentist approaches.","code":""},{"path":"principes.html","id":"in-summary","chapter":"1 The Bayesian approach","heading":"1.7 In summary","text":"Bayes’ theorem tool updating knowledge.Bayesian statistics relies likelihood prior distribution model parameters.Frequentist statistics provides point estimator, whereas Bayesian statistics estimates distribution parameter.Often, classical Bayesian approaches yield similar estimates.cases, posterior distribution explicit (example, case beta/binomial conjugacy).cases, need use simulations obtain posterior distribution, see Chapter 2.","code":""},{"path":"mcmc.html","id":"mcmc","chapter":"2 MCMC methods","heading":"2 MCMC methods","text":"","code":""},{"path":"mcmc.html","id":"introduction-2","chapter":"2 MCMC methods","heading":"2.1 Introduction","text":"hope lose (much) previous chapter equations. new chapter, go behind scenes Bayesian statistics introducing Markov chain Monte Carlo (MCMC) methods. see simulation techniques become essential implementing Bayesian inference practice. nothing beats practice, get hands little dirty coding , using running example estimating survival probability.","code":""},{"path":"mcmc.html","id":"applying-bayes-theorem","chapter":"2 MCMC methods","heading":"2.2 Applying Bayes’ theorem","text":"Let us return running example coypus; repeat data:Let us apply Bayes’ theorem directly Chapter 1, set aside denominator \\(\\Pr(\\text{data})\\). Let us see whether can handle . saw, denominator given \n\\(\\displaystyle \\Pr(\\text{y}) = \\int{\\Pr(\\text{data} \\mid \\theta) \\Pr(\\theta) \\, d\\theta}\\).\ncompute integral. Let us start writing R function computes product (binomial) likelihood prior (Beta(1,1)), .e. numerator Bayes’ theorem, \\(\\Pr(\\text{data} \\mid \\theta) \\times \\Pr(\\theta)\\):can now write function computes denominator. , use R’s integrate() function, computes integral one-variable function. integrate() function uses quadrature techniques approximate area curve defined function integrate, breaking small pieces summing .obtain numerical approximation posterior distribution winter survival, Figure 2.1:\nFigure 2.1: Numerical approximation posterior distribution winter survival.\ngood numerical approximation? Ideally, like compare approximation true posterior distribution. Conveniently, obtained Chapter 1: beta distribution parameters 20 39. Figure 2.2, can see two curves overlap perfectly.\nFigure 2.2: Comparison exact posterior (brick red) numerical approximation (cream).\nexact posterior distribution (brick red) numerical approximation (cream) winter survival indistinguishable, suggesting numerical approximation satisfactory.example, single parameter estimate: winter survival. means denominator involves one-dimensional integral, fairly easy handle quadrature techniques R’s integrate() function.happens several parameters? example, imagine want fit regression model survival depends explanatory variable, say coypu body mass. effect variable captured regression parameters \\(\\beta_0\\) (intercept) \\(\\beta_1\\) (slope), also residual error standard deviation \\(\\sigma\\) (see Chapter 5). Bayes’ theorem gives joint posterior distribution parameters (.e. three parameters together):\\[ \\displaystyle \\Pr(\\beta_0, \\beta_1, \\sigma \\mid \\text{y}) = \\frac{ \\Pr(\\text{y} \\mid \\beta_0, \\beta_1, \\sigma) \\times \\Pr(\\beta_0, \\beta_1, \\sigma)}{\\displaystyle \\iiint \\Pr(\\text{y} \\mid \\beta_0, \\beta_1, \\sigma) \\Pr(\\beta_0, \\beta_1, \\sigma) \\, d\\beta_0 \\, d\\beta_1 \\, d\\sigma} \\]two major numerical challenges:really want compute triple integral? , classical methods rarely go much beyond two dimensions.often interested marginal distributions parameters (example, \\(\\beta_1\\), effect mass survival), obtained integrating joint posterior distribution parameters (, double integral respect \\(\\beta_0\\) $) — quickly becomes intractable number parameters increases.next section, introduce powerful simulation methods overcome limitations.","code":"\ny <- 19 # number of individuals that survived the winter\nn <- 57 # number of individuals monitored at the start of winter\nnum <- function(theta) dbinom(y, n, theta) * dbeta(theta, 1, 1)\nden <- integrate(num, 0, 1)$value\n# Create a grid of possible values for the survival probability (between 0 and 1)\ngrid <- seq(0, 1, 0.01)\n\n# Compute posterior density values on the grid\n# num(grid) is likelihood * prior, and den is the normalizing constant\nposterior <- data.frame(\n  survival = grid,\n  ratio = num(grid) / den  # normalized posterior density\n)\n\n# Plot the posterior density curve\nposterior %>%\n  ggplot(aes(x = survival, y = ratio)) +\n  geom_line(size = 1.5) +\n  labs(x = \"Survival probability\", y = \"Density\") +\n  theme_minimal()"},{"path":"mcmc.html","id":"mcmc-algorithms","chapter":"2 MCMC methods","heading":"2.3 MCMC algorithms","text":"short, idea Markov chain Monte Carlo (MCMC) methods use simulations approximate posterior distributions given precision drawing large number samples. avoids explicit computation multidimensional integrals arise applying Bayes’ theorem.simulation algorithms consist two parts: Markov chains Monte Carlo. Let us try understand two terms.Monte Carlo mean? Monte Carlo integration simulation technique used compute integrals arbitrary functions \\(f\\) random variable \\(X\\) distribution \\(\\Pr(X)\\), \\(\\displaystyle \\int f(X) \\Pr(X) dX\\). draw values \\(X_1, \\ldots, X_k\\) \\(\\Pr(X)\\), apply function \\(f\\) values, compute mean resulting values, \\(\\displaystyle{\\frac{1}{k}}\\sum_{=1}^k{f(X_i)}\\), approximate integral.use Monte Carlo integration Bayesian context? posterior distribution contains information need parameter(s) want estimate. multiple parameters, often want summarize information computing numerical summaries. simplest summary posterior mean,\n\\(E(\\theta) = \\int \\theta \\Pr(\\theta \\mid \\text{data}) \\, d\\theta\\),\n\\(X\\) \\(\\theta\\) \\(f\\) identity. posterior mean can estimated Monte Carlo integration; example, coypu survival:can verify resulting mean close theoretical expectation beta distribution:Another useful numerical summary credible interval within parameter lies given probability, usually 0.95, .e. 95% credible interval. Determining bounds interval requires computing quantiles, also relies integrals, therefore Monte Carlo integration. 95% credible interval winter survival can obtained :way, difference credible interval Bayesian statistics confidence interval frequentist statistics. 95% confidence interval means repeated experiment large number times (tag coypus GPS record number winter survivors), 95% intervals constructed way contain true parameter value \\(\\theta\\). say probability parameter lies within given interval 95%. 95% credible interval, contrast, means 95% probability parameter lies within interval. interpretation credible interval bit intuitive confidence interval.Now, Markov chain? Markov chain random sequence numbers number depends previous one. One example weather city, Montpellier, south France, sunny day likely followed another sunny day, say probability 0.8, rainy day rarely followed another rainy day, say probability 0.1. dynamics Markov chain captured transition matrix:\\[\n\\begin{array}{c|cc}\n& \\text{Sunny tomorrow} & \\text{Rainy tomorrow} \\\\ \\\\ \\hline\n\\text{Sunny today} & 0.8 & 0.2 \\\\\\\\\n\\text{Rainy today}   & 0.9 & 0.1\n\\end{array}\n\\]Rows indicate today’s weather columns indicate tomorrow’s. cells give probability sunny rainy day tomorrow depending today’s weather (conditional probabilities; see Chapter 1).certain conditions, Markov chain converges unique stationary distribution. weather example, let us iterate chain 20 steps:row matrix converges toward distribution \\((0.82, 0.18)\\) number steps increases. convergence occurs regardless starting state: probability 0.82 sun 0.18 rain.Let us return MCMC methods. central idea can construct Markov chain whose stationary distribution precisely posterior distribution parameters. Keep idea mind: fundamental.combining Monte Carlo Markov chains, MCMC methods allow us generate sample values whose distribution converges posterior distribution (Markov chain) use sample compute posterior numerical summaries (Monte Carlo), mean credible intervals.several ways build Markov chains Bayesian inference. may heard Metropolis–Hastings algorithm Gibbs sampler. can consult https://chi-feng.github.io/mcmc-demo/ interactive gallery MCMC algorithms. , illustrate Metropolis algorithm practical implementation. draw inspiration excellent book Jim Albert (2009). goal able write algorithm scratch, grasp main ideas , , notion simulation.Let us return survival example. illustrate sampling posterior distribution survival. Let us start writing functions likelihood, prior, posterior. work log scale manipulate sums differences rather products ratios, can make numerical calculations unstable:Metropolis algorithm works follows:Choose initial value parameter estimate. starting value, initial point Markov chain.Choose initial value parameter estimate. starting value, initial point Markov chain.decide next step, propose moving away current parameter value—candidate value. add current value draw normal distribution variance—proposal distribution. Metropolis algorithm special case Metropolis–Hastings symmetric proposals.decide next step, propose moving away current parameter value—candidate value. add current value draw normal distribution variance—proposal distribution. Metropolis algorithm special case Metropolis–Hastings symmetric proposals.Compute ratio posterior densities candidate position current position:\n\\(R = \\displaystyle \\frac{\\Pr(\\text{candidate value}|\\text{data})}{\\Pr(\\text{current value}|\\text{data})}\\).\ncompute numerator denominator, simply apply Bayes’ theorem, magic MCMC happens: \\(\\Pr(\\text{data})\\) appears numerator denominator, cancels, longer need compute . replaced computation integral simulations.Compute ratio posterior densities candidate position current position:\n\\(R = \\displaystyle \\frac{\\Pr(\\text{candidate value}|\\text{data})}{\\Pr(\\text{current value}|\\text{data})}\\).\ncompute numerator denominator, simply apply Bayes’ theorem, magic MCMC happens: \\(\\Pr(\\text{data})\\) appears numerator denominator, cancels, longer need compute . replaced computation integral simulations.posterior density candidate position larger current position, .e. candidate value plausible, accept immediately. Otherwise, accept probability \\(R\\), reject probability \\(1 - R\\). example, candidate value ten times less plausible, accept probability 0.1. use uniform random number 0 1 (call \\(X\\)): \\(X < R\\), accept candidate value; otherwise, stay current value. practice, aim acceptance rate 0.2 0.4, can adjusted calibrating proposal variance; helps explore whole parameter space.posterior density candidate position larger current position, .e. candidate value plausible, accept immediately. Otherwise, accept probability \\(R\\), reject probability \\(1 - R\\). example, candidate value ten times less plausible, accept probability 0.1. use uniform random number 0 1 (call \\(X\\)): \\(X < R\\), accept candidate value; otherwise, stay current value. practice, aim acceptance rate 0.2 0.4, can adjusted calibrating proposal variance; helps explore whole parameter space.Repeat steps 2 4 certain number times—iterations.Repeat steps 2 4 certain number times—iterations.Enough theory: let us implement . start initializing:need initialize? running Markov chain, prepare objects store simulated values parameter (, survival probability) well information whether proposal accepted. set.seed(666) ? command sets seed random number generator. ensures simulations reproducible: rerun code, obtain exactly simulated values mine.choose starting value:starting value? Markov chain start somewhere: , arbitrarily choose 0.5 initial value survival probability. constraint value must compatible prior: going pick negative survival probability 15. place value first element theta.post, indicate accept[1] <- 1 first value accepted construction, since starting point.Next, write function propose candidate value current value:function introduces random proposal around current value. work logit scale ensure final proposal (candidate) always remains interval (0,1) (see also Chapter 6). away parameter controls spread proposals: larger , larger jumps; smaller , closer proposals remain current value.implement steps 2 4 algorithm loop (step 5: repeating iterations):loop builds Markov chain iteratively. probability accepting less plausible value proportional likelihood ratio. accept vector can used diagnose acceptance frequency, useful calibrating chain.Let us take look first last simulated values:can now visualize chain’s evolution trace plot, .e. curve showing simulated values theta across iterations (Figure 2.3):\nFigure 2.3: Trace plot simulated values survival probability \\(\\theta\\) across iterations.\ntrace plot tell us? horizontal axis represents iterations (“time” Markov chain). vertical axis shows simulated values survival probability step. figure, see chain sometimes stays value several consecutive iterations. happens candidate value proposed algorithm rejected—chain retains previous (precisely, current) value. times, see jumps new values, corresponding accepted proposals.can wrap algorithm reusable function, making easy run multiple chains:can now use metropolis() run another chain, time starting 0.2:Note often talk “running multiple MCMC chains” diagnose convergence. practice, independent realizations Markov chain—like flipping coin multiple times, except complicated distribution Bernoulli.plot chains together, Figure 2.4:\nFigure 2.4: Trace plot simulated values survival probability \\(\\theta\\) across iterations. Two chains run different initial values, 0.5 blue 0.2 yellow.\nNote obtain exactly results algorithm stochastic. observe parallel evolution two chains started different initial values. two chains quickly meet oscillate around values, indicates good convergence toward desired stationary distribution. key step MCMC convergence diagnostics, cover later chapter. observe convergence longer period, run chain 1,000 iterations. gives smoother trace plot showing chain stability, Figure 2.5:\nFigure 2.5: Trace plot simulated values survival probability \\(\\theta\\) across 1000 iterations.\nlarge number iterations, chain stabilize around stationary distribution. Visually, look dense, homogeneous, well-explored region—like neatly mown lawn (image).stationary distribution reached, can treat simulated values Markov chain sample posterior distribution compute numerical summaries parameters (posterior mean, credible interval).can say reached stationary distribution? convergence, many additional simulations need obtain good approximation posterior distribution parameters? address questions next section.","code":"\n# draw 1000 values from the Beta(20,39) posterior\nsample_from_posterior <- rbeta(1000, 20, 39)\n# compute the mean by Monte Carlo integration\nmean(sample_from_posterior)\n#> [1] 0.3405089\n20/(20+39) # expectation of the Beta(20,39) distribution\n#> [1] 0.3389831\nquantile(sample_from_posterior, probs = c(2.5/100, 97.5/100))\n#>      2.5%     97.5% \n#> 0.2270862 0.4702974\ntemps <- matrix(c(0.8, 0.2, 0.9, 0.1), nrow = 2, byrow = T) # transition matrix\netapes <- 20\nfor (i in 1:etapes){\n  temps <- temps %*% temps # matrix multiplication\n}\nround(temps, 2) # matrix product after 20 steps\n#>      [,1] [,2]\n#> [1,] 0.82 0.18\n#> [2,] 0.82 0.18\n# 19 animals found alive out of 57 captured, marked and released\ny <- 19\nn <- 57\n\n# binomial log-likelihood Bin(n = 57,p)\nloglikelihood <- function(x, p){\n  dbinom(x = x, size = n, prob = p, log = TRUE)\n}\n\n# uniform prior density\nlogprior <- function(p){\n  dunif(x = p, min = 0, max = 1, log = TRUE)\n  # or dbeta(x = p, shape1 = 0, shape2 = 1, log = TRUE)\n}\n\n# posterior density (log scale)\nposterior <- function(x, p){\n  loglikelihood(x, p) + logprior(p)\n}\nsteps <- 100 # number of steps (iterations) of the chain\ntheta.post <- rep(NA, steps) # vector to store simulated values\naccept <- rep(NA, steps) # vector to record accept/reject decisions\nset.seed(666) # for reproducibility\ninits <- 0.5 # chosen starting value for theta\ntheta.post[1] <- inits # record this value as the first position of the chain\naccept[1] <- 1 # the initial value is accepted by default\nmove <- function(x, away = 1){\n  logitx <- log(x / (1 - x)) # logit transform: maps x from (0,1) to (-∞,+∞)\n  logit_candidate <- logitx + rnorm(1, 0, away) # add centered normal noise, sd controlled by away\n  candidate <- plogis(logit_candidate) # inverse transform (logit^-1): returns a value between 0 and 1\n  return(candidate) # return proposed value\n}\nfor (t in 2:steps){ # for each iteration, starting at the 2nd\n\n  # Step 2: propose a new value for theta\n  theta_star <- move(theta.post[t-1])  # candidate drawn from the previous value\n\n  # Step 3: compute the ratio of posterior densities (log scale)\n  pstar <- posterior(y, p = theta_star) # posterior density at candidate\n  pprev <- posterior(y, p = theta.post[t-1]) # posterior density at current value\n  logR <- pstar - pprev # difference on the log scale\n  R <- exp(logR) # back to the natural scale (density ratio)\n\n  # Step 4: accept or reject the proposal\n  X <- runif(1, 0, 1) # random draw between 0 and 1: the acceptance \"roulette\"\n  if (X < R){ # if the proposal is more plausible (or not too much worse)\n    theta.post[t] <- theta_star # accept and store the candidate\n    accept[t] <- 1 # record acceptance\n  } else {\n    theta.post[t] <- theta.post[t-1] # otherwise keep the previous value\n    accept[t] <- 0 # record rejection\n  }\n}\nhead(theta.post)\n#> [1] 0.5000000 0.5000000 0.3021903 0.3021903 0.1853669 0.1853669\ntail(theta.post)\n#> [1] 0.4076667 0.4076667 0.4076667 0.4076667 0.2914464 0.2914464\nmetropolis <- function(steps = 100, inits = 0.5, away = 1){\n\n  theta.post <- rep(NA, steps) # vector to store samples\n  theta.post[1] <- inits # initialize with starting value\n\n  for (t in 2:steps){ # loop over steps (starting at the 2nd)\n\n    theta_star <- move(theta.post[t-1], away) # propose a new value\n\n    # log-ratio of posterior density between candidate and current value\n    logR <- posterior(y, theta_star) -\n            posterior(y, theta.post[t-1])\n    R <- exp(logR) # back to non-log scale\n\n    X <- runif(1, 0, 1) # draw a uniform random number\n    theta.post[t] <- ifelse(X < R, # if draw < acceptance probability...\n                            theta_star, # ... accept proposed value\n                            theta.post[t-1]) # otherwise keep previous\n  }\n\n  return(theta.post) # return simulated sample\n}\ntheta.post2 <- metropolis(steps = 100, inits = 0.2) # start at 0.2"},{"path":"mcmc.html","id":"convergence-diag","chapter":"2 MCMC methods","heading":"2.4 Assessing convergence","text":"applying MCMC method, need determine long takes Markov chain converge target distribution, many additional iterations required convergence obtain reliable Monte Carlo estimates numerical summaries (posterior means, credible intervals).","code":""},{"path":"mcmc.html","id":"burn-in","chapter":"2 MCMC methods","heading":"2.4.1 Burn-in","text":"practice, discard first values Markov chain use values simulated convergence. initial observations discard generally called burn-(warm-) period.simplest way determine length burn-period inspect trace plots. Let us return example look Figure 2.6, trace plot chain starting 0.99:\nFigure 2.6: Trace plot chain starting 0.99. shaded area illustrates possible burn-period.\nchain starts 0.99 stabilizes quickly, values oscillating around 0.3 iteration 100 onward. can choose shaded area burn-period discard first 100 values. safe, one use 250 even 500 iterations burn-, provided cost much computation time, course.Inspecting trace plot single chain useful, generally run multiple chains different initial values check reach stationary distribution. approach formalized Brooks–Gelman–Rubin statistic (BGR), denoted \\(\\hat{R}\\), measures ratio total variability (chains plus within chain) within-chain variability. close spirit \\(F\\) test analysis variance (, one-factor ANOVA factor levels chains). value 1.1 indicates likely convergence.Let us return example: run two Markov chains initial values 0.2 0.8, varying number iterations 100 1000 steps 50, compute BGR statistic using half iterations burn-(Figure 2.7).\nFigure 2.7: Value Brooks–Gelman–Rubin (BGR) statistic function number iterations. value close 1 suggests convergence.\nobtain BGR statistic close 1 300 iterations onward, suggesting burn-300 iterations, nothing indicates convergence problem.important remember value close 1 BGR statistic necessary sufficient condition convergence. words, diagnostic assert certainty chain converged; simply indicates detect obvious sign . advice: always take time look trace plots.","code":""},{"path":"mcmc.html","id":"chain-length","chapter":"2 MCMC methods","heading":"2.4.2 Chain length","text":"chain length needed obtain reliable parameter estimates? Keep mind successive steps Markov chain independent. called autocorrelation. Ideally, want minimize autocorrelation., trace plots can diagnose autocorrelation issues. Returning survival example, Figure 2.8 shows trace plots (3000 iterations) different values proposal normal standard deviation (parameter away) used generate candidate values.\nFigure 2.8: Trace plots different values proposal standard deviation (away). Good mixing observed away = 1. shaded gray area corresponds burn-300 iterations.\nsmall large moves visible left right panels lead strong correlation successive observations Markov chain, whereas standard deviation equal 1 (center) allows efficient exploration parameter space. movement parameter space called mixing. Mixing considered poor chain makes jumps small large, good otherwise.addition trace plots, autocorrelation function (ACF) plots provide convenient way visualize strength autocorrelation given sample. ACF plots show correlation successively sampled values separated increasing number iterations, called lag. Figure 2.9, obtain ACF plots different proposal standard deviations using forecast::ggAcf():\nFigure 2.9: Autocorrelation functions (ACF) different proposal standard deviations. Low autocorrelation sign good mixing. burn-300 iterations applied.\nleft right panels, autocorrelation strong decreases slowly lag, mixing poor. central panel, autocorrelation weak decreases quickly lag, mixing good.Autocorrelation necessarily major problem. Highly correlated observations simply require larger number samples, therefore longer simulations. many iterations need exactly? effective sample size (n.eff) measures useful length chain accounting autocorrelation. recommended check n.eff parameter interest, well relevant combination parameters. general, consider need least \\(\\text{n.eff} \\geq 400\\) independent observations obtain reliable Monte Carlo estimates model parameters. animal survival example, n.eff can computed using effectiveSize() function coda package:expected, n.eff smaller total number MCMC iterations (3000) autocorrelation. proposal standard deviation equals 1 mixing good (n.eff \\(\\geq 400\\)), yielding satisfactory effective sample size.","code":"\n# Generate chains for three proposal standard deviations\nd <- tibble(away = c(0.1, 1, 10)) %>%\n     mutate(accepted_traj = map(away,\n                               metropolis,\n                               steps = n_steps,\n                               inits = 0.1)) %>%\n     unnest(accepted_traj) %>%\n     mutate(proposal_sd = str_c(\"SD = \", away),\n            iter = rep(1:n_steps, times = 3))\n\n# Compute effective sample size\nneff1 <- coda::effectiveSize(d$accepted_traj[d$proposal_sd==\"SD = 0.1\"][-c(1:300)])\nneff2 <- coda::effectiveSize(d$accepted_traj[d$proposal_sd==\"SD = 1\"][-c(1:300)])\nneff3 <- coda::effectiveSize(d$accepted_traj[d$proposal_sd==\"SD = 10\"][-c(1:300)])\ntibble(\"SD\" = c(0.1, 1, 10),\n       \"n.eff\" = round(c(neff1, neff2, neff3)))\n#> # A tibble: 3 × 2\n#>      SD n.eff\n#>   <dbl> <dbl>\n#> 1   0.1    81\n#> 2   1     524\n#> 3  10      77"},{"path":"mcmc.html","id":"what-if-you-have-convergence-problems","chapter":"2 MCMC methods","heading":"2.4.3 What if you have convergence problems?","text":"diagnosing convergence MCMC chain, () often encounter difficulties. section offers practical tips hope useful.mixing poor effective sample size low, may enough increase burn-period /increase number simulations. Using informative priors can also facilitate convergence Markov chains helping MCMC algorithm explore parameter space efficiently (Chapter 4). spirit, choosing better initial values start chain can also help. useful strategy use estimates simpler model MCMC chains already converge.convergence problems persist, often issue model . bug code? typo? error equations? often case programming, best way identify problem reduce model’s complexity start simpler model find wrong.Another piece advice think model first foremost data generator. Simulate data model using realistic parameter values, try recover parameters fitting model simulated data. approach help better understand model works, , much data needed obtain reliable parameter estimates. return technique Chapters 5 6.","code":""},{"path":"mcmc.html","id":"in-summary-1","chapter":"2 MCMC methods","heading":"2.5 In summary","text":"idea Markov chain Monte Carlo (MCMC) methods simulate values Markov chain whose stationary distribution precisely posterior distribution parameters want estimate.idea Markov chain Monte Carlo (MCMC) methods simulate values Markov chain whose stationary distribution precisely posterior distribution parameters want estimate.practice, run several Markov chains starting dispersed initial values.practice, run several Markov chains starting dispersed initial values.discard first iterations (warm-burn-phase) consider convergence reached chains converge regime.discard first iterations (warm-burn-phase) consider convergence reached chains converge regime.point , run chains long enough compute Monte Carlo estimates numerical summaries (example, posterior means credible intervals) parameters.point , run chains long enough compute Monte Carlo estimates numerical summaries (example, posterior means credible intervals) parameters.course, want build implement MCMC methods hand every new analysis, Chapter 3 see make easier.course, want build implement MCMC methods hand every new analysis, Chapter 3 see make easier.","code":""},{"path":"logiciels.html","id":"logiciels","chapter":"3 Practical implementation","heading":"3 Practical implementation","text":"","code":""},{"path":"logiciels.html","id":"introduction-3","chapter":"3 Practical implementation","heading":"3.1 Introduction","text":"chapter, explore two practical tools performing Bayesian statistics minimal effort: NIMBLE brms. NIMBLE brms two R packages implement MCMC algorithms . practice, need specify likelihood priors Bayes’ theorem applied automatically. Thanks syntax close R, packages make step relatively straightforward, even complex models.","code":""},{"path":"logiciels.html","id":"nimble","chapter":"3 Practical implementation","heading":"3.2 NIMBLE","text":"NIMBLE stands Numerical Inference statistical Models using Bayesian Likelihood Estimation. originality NIMBLE separates model-building step model-fitting step, allows great flexibility modeling. package developed team scientists continuously improve capabilities based community feedback. NIMBLE community active https://groups.google.com/g/nimble-users, forum developers respond questions quickly helpfully.use NIMBLE, can follow steps:Build model (likelihood priors).Read data.Specify parameters want make inferences.Provide initial values parameters (per chain).Define MCMC settings: number chains, burn-, number post-burn-iterations.Assess convergence.Interpret results.first, don’t forget load package (install NIMBLE, see https://r-nimble.org/download):Let’s return running example coypu survival. First step: define binomial likelihood uniform prior survival probability \\(\\theta\\) using nimbleCode() function:can check model object indeed contains code:code, y n known, \\(\\theta\\) needs estimated. line y ~ dbinom(theta, n) indicates number survivors follows binomial distribution. prior beta distribution parameters 1 1 (dbeta()), .e. uniform distribution 0 1 (dunif()). Standard distributions available NIMBLE (dnorm, dpois, dmultinom, etc.). Note order lines matter: NIMBLE uses declarative language (specify , ).second step, enter data list:NIMBLE distinguishes data (known values left ~) constants (e.g. loop indices). Declaring values constants can improve computational efficiency, although always intuitive. Fortunately, NIMBLE largely handles automatically may suggest moving objects constants improves performance. ignore distinction , use later Chapter 6.third step tell NIMBLE parameters want monitor. , interested survival probability \\(\\theta\\):general, model contains many quantities, informative need monitored. full control tracked therefore useful.fourth step consists specifying initial values model parameters. minimum, must provide initial values quantities appear left side ~ code supplied data.ensure MCMC algorithm properly explores posterior distribution, run multiple chains different initial values. can specify initial values chain (three chains) list, placed inside another list:Alternatively, can write R function generates random initial values:prefer using functions code compact automatically adapts number chains. use function generate initial values, always good practice set random seed beforehand can reproduce results:Fifth final step: need tell NIMBLE number chains (n.chains), burn-length (n.burnin), total number iterations (n.iter):NIMBLE, specify total number iterations, number posterior samples per chain equal n.iter - n.burnin.side note, determine length warm-period (burn-), can run NIMBLE n.burnin <- 0 hundred thousand iterations inspect parameter trace decide many iterations needed reach convergence.NIMBLE also allows discard samples burn-phase, called thinning. default, thinning = 1 (samples removed), meaning simulations used summarize posterior distributions.now ingredients run model, .e. generate samples posterior distribution parameters via MCMC simulations. use nimbleMCMC() function :NIMBLE performs several internal steps detail . nimbleMCMC() function accepts useful arguments. example, setSeed lets fix random seed inside MCMC call, ensuring obtain exactly chains run—useful reproducibility debugging. can also request summary output summary = TRUE, retrieve MCMC samples coda::mcmc() format samplesAsCodaMCMC = TRUE. Finally, can remove progress bar progressBar = FALSE find depressing long simulations. See ?nimbleMCMC details.Let’s take look results, starting examining mcmc.output object contains:R object mcmc.output list three elements, one MCMC chain. Let’s look, example, first chain:element list matrix. rows correspond 1700 samples posterior distribution \\(\\theta\\) (corresponds n.iter - n.burnin iterations). columns represent parameters monitor, theta., can compute posterior mean \\(\\theta\\):95% credible interval:Let us now visualize posterior distribution \\(\\theta\\) histogram:\nFigure 3.1: Histogram posterior distribution survival probability (\\(\\theta\\)).\nconvenient ways perform Bayesian inferences. use R package MCMCvis summarize visualize MCMC output, can also use ggmcmc, bayesplot, basicMCMCplots.Let’s load MCMCvis:obtain common numerical summaries, use MCMCsummary():can also draw caterpillar plot MCMCplot() visualize posterior distributions:\nFigure 3.2: Caterpillar plot posterior distribution survival probability (\\(\\theta\\)).\npoint represents posterior median, thick bar 50% credible interval, thin bar 95% credible interval.can plot MCMC chain (trace plot) associated posterior density MCMCtrace():\nFigure 3.3: Trace plot posterior density survival probability (\\(\\theta\\)).\nplots used assess chain convergence detect potential estimation issues (see Chapter 2). can also add diagnostics discussed earlier:\nFigure 3.4: Trace plot posterior density survival probability (\\(\\theta\\)) convergence diagnostics.\nmajor advantage MCMC methods provide posterior distribution function parameters applying function draws posterior distributions parameters. example, suppose want compute life expectancy coypus, given \\(\\lambda = -1/\\log(\\theta)\\).example, simply combine theta samples three chains:compute corresponding life expectancy:thus obtain 5100 simulated values posterior distribution \\(\\lambda\\), whose first values :can extract usual summaries:Life expectancy approximately one year. can also visualize posterior distribution life expectancy:\nFigure 3.5: Histogram posterior distribution life expectancy.\nalso compute life expectancy inserting directly NIMBLE model line lambda <- -1/log(theta) adding lambda monitored outputs. approach presented particularly useful large models /large datasets, reduces memory usage.Now can get started. convenience, steps summarized . workflow provided nimbleMCMC() allows build models perform Bayesian inference:section, introduced bare minimum get started NIMBLE. NIMBLE much simple MCMC engine: programming environment gives full control model construction parameter estimation. can write functions distributions, choose MCMC methods , even code algorithms. See manual https://r-nimble.org/html_manual/cha-welcome-nimble.html details.","code":"\nlibrary(nimble)\nmodel <- nimbleCode({\n  # likelihood\n  y ~ dbinom(theta, n)\n  # prior\n  theta ~ dbeta(1, 1) # or dunif(0,1)\n})\nmodel\n#> {\n#>     y ~ dbinom(theta, n)\n#>     theta ~ dbeta(1, 1)\n#> }\ndat <- list(n = 57, y = 19)\npar <- c(\"theta\")\ninit1 <- list(theta = 0.1)\ninit2 <- list(theta = 0.5)\ninit3 <- list(theta = 0.9)\ninits <- list(init1, init2, init3)\ninits\n#> [[1]]\n#> [[1]]$theta\n#> [1] 0.1\n#> \n#> \n#> [[2]]\n#> [[2]]$theta\n#> [1] 0.5\n#> \n#> \n#> [[3]]\n#> [[3]]$theta\n#> [1] 0.9\ninits <- function() list(theta = runif(1,0,1))\ninits()\n#> $theta\n#> [1] 0.3109711\nseed <- 666\nset.seed(seed)\nn.iter <- 2000\nn.burnin <- 300\nn.chains <- 3\nmcmc.output <- nimbleMCMC(code = model, # model\n                          data = dat, # data\n                          inits = inits, # initial values\n                          monitors = par, # parameters to monitor\n                          niter = n.iter, # total number of iterations\n                          nburnin = n.burnin, # burn-in iterations\n                          nchains = n.chains) # number of chains\n#> |-------------|-------------|-------------|-------------|\n#> |-------------------------------------------------------|\n#> |-------------|-------------|-------------|-------------|\n#> |-------------------------------------------------------|\n#> |-------------|-------------|-------------|-------------|\n#> |-------------------------------------------------------|\nstr(mcmc.output)\n#> List of 3\n#>  $ chain1: num [1:1700, 1] 0.407 0.201 0.451 0.273 0.254 ...\n#>   ..- attr(*, \"dimnames\")=List of 2\n#>   .. ..$ : NULL\n#>   .. ..$ : chr \"theta\"\n#>  $ chain2: num [1:1700, 1] 0.507 0.382 0.256 0.365 0.177 ...\n#>   ..- attr(*, \"dimnames\")=List of 2\n#>   .. ..$ : NULL\n#>   .. ..$ : chr \"theta\"\n#>  $ chain3: num [1:1700, 1] 0.317 0.244 0.317 0.362 0.357 ...\n#>   ..- attr(*, \"dimnames\")=List of 2\n#>   .. ..$ : NULL\n#>   .. ..$ : chr \"theta\"\ndim(mcmc.output$chain1)\n#> [1] 1700    1\nhead(mcmc.output$chain1)\n#>          theta\n#> [1,] 0.4070527\n#> [2,] 0.2005720\n#> [3,] 0.4513129\n#> [4,] 0.2725412\n#> [5,] 0.2539956\n#> [6,] 0.4019970\nmean(mcmc.output$chain1[,\"theta\"])\n#> [1] 0.3391349\nquantile(mcmc.output$chain1[,\"theta\"], probs = c(2.5, 97.5)/100)\n#>      2.5%     97.5% \n#> 0.2308179 0.4541410\nmcmc.output$chain1[,\"theta\"] %>%\n  as_tibble() %>%\n  ggplot() +\n  geom_histogram(aes(x = value), color = \"white\") +\n  labs(x = \"Survival probability\")\nlibrary(MCMCvis)\nMCMCsummary(object = mcmc.output, round = 2)\n#>       mean   sd 2.5%  50% 97.5% Rhat n.eff\n#> theta 0.34 0.06 0.22 0.34  0.46    1  4831\nMCMCplot(object = mcmc.output, params = 'theta')\nMCMCtrace(object = mcmc.output,\n          pdf = FALSE,\n          ind = TRUE,\n          params = \"theta\")\nMCMCtrace(object = mcmc.output,\n          pdf = FALSE,\n          ind = TRUE,\n          Rhat = TRUE,\n          n.eff = TRUE,\n          params = \"theta\")\ntheta_samples <- c(mcmc.output$chain1[,\"theta\"],\n                   mcmc.output$chain2[,\"theta\"],\n                   mcmc.output$chain3[,\"theta\"])\nlambda <- -1/log(theta_samples)\nhead(lambda)\n#> [1] 1.1125791 0.6224394 1.2569220 0.7692513 0.7296935 1.0973206\nmean(lambda)\n#> [1] 0.9372371\nquantile(lambda, probs = c(2.5, 97.5)/100)\n#>      2.5%     97.5% \n#> 0.6691676 1.2999116\nlambda %>%\n  as_tibble() %>%\n  ggplot() +\n  geom_histogram(aes(x = value), color = \"white\") +\n  labs(x = \"Life expectancy\")\nmodel <- nimbleCode({\n  y ~ dbinom(theta, n)\n  theta ~ dbeta(1, 1)\n  lambda <- -1/log(theta)\n})\ndat <- list(n = 57, y = 19)\npar <- c(\"theta\", \"lambda\")\ninits <- function() list(theta = runif(1,0,1))\nn.iter <- 5000\nn.burnin <- 1000\nn.chains <- 3\nmcmc.output <- nimbleMCMC(code = model,\n                          data = dat,\n                          inits = inits,\n                          monitors = par,\n                          niter = n.iter,\n                          nburnin = n.burnin,\n                          nchains = n.chains)\nMCMCsummary(object = mcmc.output, round = 2)\nMCMCplot(object = mcmc.output)\nMCMCtrace(object = mcmc.output, pdf = FALSE, ind = TRUE)"},{"path":"logiciels.html","id":"brms","chapter":"3 Practical implementation","heading":"3.3 brms","text":"brms stands Bayesian Regression Models using Stan. package makes possible formulate estimate regression models (see next section Chapters 5 6) intuitive way thanks syntax close lme4 package (R reference mixed models), relying Stan, reference software Bayesian statistics. package constant development; see https://paul-buerkner.github.io/brms/. can get help via https://discourse.mc-stan.org/.use brms, start preparing data:Without forgetting load brms:likelihood binomial running example. brms, can express simply:syntax relatively simple requires explanations. argument y | trials(n) ~ 1 makes possible specify model \\(y\\) successes among \\(n\\) trials, estimate intercept, 1 ~. intercept ? directly survival \\(\\theta\\)? use family = binomial(\"logit\") next line specify brms response variable follows binomial distribution. words, generalized linear model (see Chapter 6) \\(\\text{logit}(\\theta) = \\beta\\) estimate \\(\\beta\\), intercept. arguments iter = 2000, warmup = 300, chains = 3 tell brms use 300 iterations adaptation (burn-), following 1700 inference, 3 chains.Let’s take look results:command displays summary table posterior estimates parameter model. find :Estimate posterior mean.Est.Error standard deviation posterior distribution.l-95% CI u-95% CI bounds 95% credible interval.convergence diagnostic Rhat.Bulk_ESS effective sample size (Tail_ESS another measure effective sample size use ).posterior mean -0.7 far proportion coypus survived winter (\\(19/57 \\approx 0.33\\)). always R implementation generalized linear models (see Chapter 6), parameter estimates given scale link function. , estimated intercept expressed logit scale. convert survival probability (0 1), first extract values generated posterior distribution intercept \\(\\beta\\) function brms::as_draws_matrix():apply inverse logistic function plogis() values obtain whole bunch simulated values posterior distribution survival \\(\\theta\\):thus obtain direct estimate posterior mean survival probability, along 95% credible interval:directly function posterior::summarise_draws():visualize posterior distribution survival probability, just need use (Figure 3.6):\nFigure 3.6: Histogram posterior distribution survival probability (\\(\\theta\\)).\nbrms, can assess convergence MCMC chains (Figure 3.7):\nFigure 3.7: Histogram posterior distribution trace plot survival probability logit scale (b). histogram, x-axis represents possible values intercept (logit scale) y-axis frequency simulated values. trace plot, x-axis corresponds MCMC iteration number y-axis simulated values intercept (logit scale).\ngraph displays trace plots (right) well posterior densities (left).side note, determine length warm-period (burn-), enough run brms warmup = 0 hundred thousand iterations inspect parameter trace decide number iterations needed reach convergence.major advantage MCMC methods allow obtaining posterior distribution function parameters applying function values drawn posterior distributions parameters. Note estimate intercept \\(\\beta\\) therefore already used idea obtain posterior distribution survival probability applying inverse logit function. another example, suppose like compute life expectancy coypus, given \\(\\lambda = -1/\\log(\\theta)\\):Life expectancy approximately one year. can also visualize posterior distribution life expectancy (Figure 3.8):\nFigure 3.8: Histogram posterior distribution life expectancy. x-axis represents different possible values life expectancy. vertical axis indicates number simulated draws (Count) value.\nwhole bunch parameters set default brms; important aware . concerns priors particular. brms, default priors often non-informative weakly informative, always good examine explicitly. following command displays summary priors used already fitted model:brms package uses weakly informative prior Student distribution 3 degrees freedom, centered 0, standard deviation 2.5. 3 degrees freedom give distribution heavier tails normal, provides robustness extreme values. center 0 reflects absence strong prior value intercept. width 2.5 allows reasonably wide variation intercept without completely non-informative.cases, relevant define prior, example reflect knowledge literature constrain estimation (informative prior). , propose normal prior centered 0 standard deviation 1.5 intercept; come back Chapter 4:can use model specification:can check results close obtained default prior:","code":"\ndat <- data.frame(y = 19, n = 57)\nlibrary(brms)\nbayes.brms <- brm(\n  y | trials(n) ~ 1, # the number of successes is a function of an intercept\n  family = binomial(\"logit\"), # binomial family with logit link function\n  data = dat, # data used\n  chains = 3, # number of MCMC chains\n  iter = 2000, # total number of iterations per chain\n  warmup = 300, # number of burn-in iterations\n  thin = 1 # no thinning (each iteration is kept)\n)\nsummary(bayes.brms)\n#>  Family: binomial \n#>   Links: mu = logit \n#> Formula: y | trials(n) ~ 1 \n#>    Data: dat (Number of observations: 1) \n#>   Draws: 3 chains, each with iter = 2000; warmup = 300; thin = 1;\n#>          total post-warmup draws = 5100\n#> \n#> Regression Coefficients:\n#>           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> Intercept    -0.70      0.28    -1.28    -0.17 1.00     1732     2305\n#> \n#> Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n#> and Tail_ESS are effective sample size measures, and Rhat is the potential\n#> scale reduction factor on split chains (at convergence, Rhat = 1).\ndraws_fit <- as_draws_matrix(bayes.brms)\nbeta <- draws_fit[,'Intercept'] # selects the intercept column\ntheta <- plogis(beta)  # logit -> [0,1] conversion\nmean(theta)\n#> [1] 0.3354256\nquantile(theta, probas = c(2.5,97.5)/100)\n#>        0%       25%       50%       75%      100% \n#> 0.1555931 0.2932298 0.3331265 0.3770575 0.5527164\nsummarise_draws(theta)\n#> # A tibble: 1 × 10\n#>   variable   mean median     sd    mad    q5   q95  rhat ess_bulk ess_tail\n#>   <chr>     <dbl>  <dbl>  <dbl>  <dbl> <dbl> <dbl> <dbl>    <dbl>    <dbl>\n#> 1 Intercept 0.335  0.333 0.0617 0.0619 0.235 0.440  1.00    1732.    2305.\ndraws_fit %>%\n  ggplot(aes(x = theta)) +\n  geom_histogram(color = \"white\", fill = \"steelblue\", bins = 30) +\n  labs(x = \"Survival probability\", y = \"Frequency\")\nplot(bayes.brms)\nbeta <- draws_fit[,'Intercept'] # selects the intercept column\ntheta <- plogis(beta)  # logit -> [0,1] conversion\nlambda <- -1 / log(theta) # transforms survival into life expectancy\nsummarize_draws(lambda) # summary of draws: mean, median, intervals\n#> # A tibble: 1 × 10\n#>   variable   mean median    sd   mad    q5   q95  rhat ess_bulk ess_tail\n#>   <chr>     <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>    <dbl>    <dbl>\n#> 1 Intercept 0.928  0.910 0.161 0.153 0.691  1.22  1.00    1732.    2305.\nlambda %>%\n  as_tibble() %>%\n  ggplot() +\n  geom_histogram(aes(x = Intercept), color = \"white\") +\n  labs(x = \"Life expectancy\")\nprior_summary(bayes.brms)\n#> Intercept ~ student_t(3, 0, 2.5)\nnlprior <- prior(normal(0, 1.5), class = \"Intercept\")\nbayes.brms <- brm(y | trials(n) ~ 1,\n                  family = binomial(\"logit\"),\n                  data = dat,\n                  prior = nlprior, # our own priors\n                  chains = 3,\n                  iter = 2000,\n                  warmup = 300,\n                  thin = 1)\nsummary(bayes.brms)\n#>  Family: binomial \n#>   Links: mu = logit \n#> Formula: y | trials(n) ~ 1 \n#>    Data: dat (Number of observations: 1) \n#>   Draws: 3 chains, each with iter = 2000; warmup = 300; thin = 1;\n#>          total post-warmup draws = 5100\n#> \n#> Regression Coefficients:\n#>           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> Intercept    -0.69      0.27    -1.24    -0.18 1.00     1664     2306\n#> \n#> Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n#> and Tail_ESS are effective sample size measures, and Rhat is the potential\n#> scale reduction factor on split chains (at convergence, Rhat = 1)."},{"path":"logiciels.html","id":"summary","chapter":"3 Practical implementation","heading":"3.4 Summary","text":"NIMBLE makes possible model simple situations complex models, great flexibility.NIMBLE makes possible model simple situations complex models, great flexibility.syntax based R, makes easier get started know language.syntax based R, makes easier get started know language.offers full control model algorithms, assumes comfortable programming.offers full control model algorithms, assumes comfortable programming.Conversely, brms makes possible take advantage MCMC methods without write model (likelihood particular).Conversely, brms makes possible take advantage MCMC methods without write model (likelihood particular).syntax simple close lme4, makes particularly suitable generalized linear models (mixed ; see Chapter 6).syntax simple close lme4, makes particularly suitable generalized linear models (mixed ; see Chapter 6).return, brms relies pre-programmed components (model families, etc.), important pay attention default choices, especially regarding prior distributions.return, brms relies pre-programmed components (model families, etc.), important pay attention default choices, especially regarding prior distributions.chapter thus offers first concrete approach implementing Bayesian models, moving richer models, mixed models.chapter thus offers first concrete approach implementing Bayesian models, moving richer models, mixed models.","code":""},{"path":"prior.html","id":"prior","chapter":"4 Prior distributions","heading":"4 Prior distributions","text":"","code":""},{"path":"prior.html","id":"introduction-4","chapter":"4 Prior distributions","heading":"4.1 Introduction","text":"chapter, explore fundamental aspect Bayesian statistics: role prior distributions, priors. see priors interact data via Bayes’ theorem produce posterior distribution, influence varies depending much information data provide. also learn incorporate relevant external information expert knowledge previous studies, critically assess prior choices using simulations.","code":""},{"path":"prior.html","id":"roleprior","chapter":"4 Prior distributions","heading":"4.2 The role of the prior","text":"Bayesian statistics, prior plays essential role: expresses knowledge, uncertainties, , conversely, lack information parameters model. Choosing priors well therefore key step Bayesian analysis. use prior?incorporate existing knowledge: often information previous studies, meta-analyses, expert opinion. prior makes possible formalize include prior knowledge, rather ignoring acting starting nothing. see example Section 4.4.incorporate existing knowledge: often information previous studies, meta-analyses, expert opinion. prior makes possible formalize include prior knowledge, rather ignoring acting starting nothing. see example Section 4.4.deal lack data: data scarce informative, frequentist methods can fail estimate certain parameters correctly (boundary estimates probability, random-effect variance estimated zero). situations, well-chosen prior can help stabilize inference providing complementary information.deal lack data: data scarce informative, frequentist methods can fail estimate certain parameters correctly (boundary estimates probability, random-effect variance estimated zero). situations, well-chosen prior can help stabilize inference providing complementary information.constrain complex models: mixed models, presence parameters difficult estimate, priors make possible bound solution space plausible values avoid aberrant estimates. example, mixed model (see Chapter 6) estimate variance groups levels effect, absence prior can lead unrealistic values numerical instabilities. weakly informative prior can help situation.constrain complex models: mixed models, presence parameters difficult estimate, priors make possible bound solution space plausible values avoid aberrant estimates. example, mixed model (see Chapter 6) estimate variance groups levels effect, absence prior can lead unrealistic values numerical instabilities. weakly informative prior can help situation.prevent overfitting: models many explanatory variables, priors play regularization role penalizing unimportant effects. example, regression includes many covariates, prior form \\(N(0,1.5^2)\\) prevents model assigning overly strong effects weakly informative variables, thereby reducing risk overfitting.prevent overfitting: models many explanatory variables, priors play regularization role penalizing unimportant effects. example, regression includes many covariates, prior form \\(N(0,1.5^2)\\) prevents model assigning overly strong effects weakly informative variables, thereby reducing risk overfitting.choice prior depends directly context scientific question.non-informative prior aims express lack knowledge: often used one want introduce strong assumptions. practice, translates wide uniform distributions. beware: even seemingly vague prior can informative transformed model scale, see Section 4.5.non-informative prior aims express lack knowledge: often used one want introduce strong assumptions. practice, translates wide uniform distributions. beware: even seemingly vague prior can informative transformed model scale, see Section 4.5.informative prior reflects credible knowledge external dataset analyzed: may come literature synthesis, past experience, expert opinion. advantage reduce uncertainty parameters, especially little data. see example Section 4.4.informative prior reflects credible knowledge external dataset analyzed: may come literature synthesis, past experience, expert opinion. advantage reduce uncertainty parameters, especially little data. see example Section 4.4.weakly informative prior somewhat compromise non-informative informative priors. idea rule values clearly aberrant incompatible know phenomenon studied, still leaving enough freedom model learn data. type prior used notably brms. see example Chapter 6.weakly informative prior somewhat compromise non-informative informative priors. idea rule values clearly aberrant incompatible know phenomenon studied, still leaving enough freedom model learn data. type prior used notably brms. see example Chapter 6.practice, cautious strategy start weakly informative prior, centered normal distribution moderate variance, test informative (vague) alternatives examine impact posterior results. idea sensitivity analysis developed Section 4.3.","code":""},{"path":"prior.html","id":"sensibilite","chapter":"4 Prior distributions","heading":"4.3 Sensitivity to the prior","text":"Let us return running example coypu survival. Let us examine different choices priors influence posterior distribution survival probability. Figure 4.1, three increasingly informative priors (columns), two sample sizes (rows).\nFigure 4.1: Combined effect prior sample size posterior distribution binomial likelihood. Columns: three beta priors Beta(1,1), Beta(5,5) Beta(20,1). Rows: small (n = 6, y = 2) large (n = 57, y = 19) sample (factor 10). red line represents prior, black line posterior distribution.\nlittle data (top row), effect prior visible: posterior distribution survival remains close prior, especially \\(\\text{Beta}(20,1)\\) pulls estimate toward high values. data (bottom row), posterior distribution dominated likelihood: concentrates around observed proportion, except prior \\(\\text{Beta}(20,1)\\) posterior distribution centered 0.5. thus observe fundamental principle Bayesian inference: numerous informative data , less prior influences results.can formalize observations made Figure 4.1. Recall likelihood \\(\\text{Bin}(n,\\theta)\\) \\(y\\) successes, prior \\(\\text{Beta}(,b)\\) distribution, posterior distribution also beta (conjugacy), precisely \\(\\text{Beta}(+y,\\;b+n-y)\\). Now, mean \\(\\text{Beta}(,b)\\) \\(\\displaystyle \\frac{}{+b}\\), therefore mean posterior distribution \\(\\text{Beta}(+y,\\;b+n-y)\\) \\(\\displaystyle \\frac{+y}{+b+n}\\), can rewritten weighted average mean prior distribution \\(\\mu_{prior} = \\displaystyle \\frac{}{+b}\\) observed proportion \\(y/n\\), none maximum likelihood estimator \\(\\hat{\\theta}\\), weight \\(w = \\displaystyle \\frac{n}{+b+n}\\). Note: weight statistical sense term, weighting factor, sense “kilograms coypu”. words, mean posterior distribution \\((1-w)\\mu_{prior} + w \\hat{\\theta}\\). Thus, sample size \\(n\\) large, \\(w\\) tends 1, posterior mean approaches maximum likelihood estimator. Conversely, small sample informative prior (sum \\(+b\\) large; see Figure 1.4), \\(w\\) small, prior pulls estimate. short, data limited, rely prior; rich, let likelihood speak.conclusion, always good idea carry kind sensitivity analysis. comparing results obtained different priors (non-informative, weakly informative, informative), can ensure conclusions depend excessively prior choices. , panic: simply means little information parameter question, must extra cautious think carefully prior used. return later.","code":""},{"path":"prior.html","id":"informativeprior","chapter":"4 Prior distributions","heading":"4.4 How to incorporate prior information?","text":"","code":""},{"path":"prior.html","id":"meta-analysis","chapter":"4 Prior distributions","heading":"4.4.1 Meta-analysis","text":"Let us go back running example estimating survival probability, making slightly complex account common issue studying animal populations: imperfect detection individuals. Indeed, depending behavior field conditions, animal may well alive present, detected time sampling. correct bias, capture–recapture protocols often used, rely individual identification animals, via ring, coat pattern, genetic profile, etc.individual can thus detected (1) (0), code example 101 means: seen first year, missed second, seen third. simplest model, assume constant survival probability \\(\\theta\\) constant detection probability \\(p\\). likelihood history 101 therefore: \\(\\Pr(101)=\\theta\\,(1-p)\\,\\theta\\,p\\). obtain full likelihood, perform calculation individual assume share \\(\\theta\\) \\(p\\), independent.take break coypus, let us look White-throated Dipper (Cinclus cinclus), bird studied 40 years Gilbert Marzolin, mathematics teacher passionate ornithology chance work. capture–recapture data 7 years (1981–1987) 200 birds.start non-informative prior survival probability, say \\(\\text{Beta}(1,1)\\). model . alternative prior, can draw accumulated knowledge similar species. passerines, instance, relationship body mass survival probability: average, heavier birds live longer. allometric relationship quantified McCarthy (2007) via linear regression (see Chapter 5), based survival mass data 27 European passerine species. Using regression passerines specific case dipper, knowing dipper weighs average 59.8 grams, can predict annual survival probability. model thus provides estimate 0.57 standard error 0.075. values allow us define informative prior, form normal distribution centered 0.57 variance \\(0.075^2\\). model B.thus obtain following results dipper:rich dataset (7 years), information contained likelihood dominates; informative prior adds almost information, two models produce similar results.Now imagine limited data. happens first three years, example? redo analysis, results now:time, informative prior makes real difference. width interval reduced nearly 50%, bringing mean estimate back toward realistic value passerine. also note posterior estimate model B 3 years data close obtained 7 years (Figure 4.2).\nFigure 4.2: Comparison posterior estimates dipper survival according type prior study duration. point represents posterior mean, 95% credible interval. grey line indicates survival value meta-analysis passerines (0.57).\nexample shows information literature (allometric mass–survival relationship obtained via meta-analysis) can used build relevant informative prior, capable substantially improving precision estimates, especially data limited. approach offers low-cost alternative lengthening field protocols, provided course (relatively simple) question remains estimation single survival.","code":""},{"path":"prior.html","id":"moment-matching-method","chapter":"4 Prior distributions","heading":"4.4.2 Moment-matching method","text":"dipper example, used normal distribution informative prior parameter happens probability. However, normal distribution can take negative values values greater 1, desirable probability. example, informative prior \\(N(0.57, 0.075^2)\\) average 0 1 small variance, little chance goes wrong. can see simulating values R command summary(rnorm(n = 100, mean = 0.57, sd = 0.075)). Still, satisfying.good news can construct appropriate informative prior probability using ‑called “moment-matching” method. moment-matching method consists choosing parameters prior distribution matching moments (often mean variance) represent prior information (seeing data).prior information available form mean \\(\\mu\\) standard deviation \\(\\sigma\\), can transform moments parameters \\(,b\\) beta distribution. reminder, mean variance beta distribution parameters \\(\\) \\(b\\) \\(\\mu=\\dfrac{}{+b}\\) \\(\\sigma^2=\\dfrac{ab}{(+b)^2(+b+1)}\\). inverting relationships, obtain: \\(=\\displaystyle \\Bigl(\\frac{1-\\mu}{\\sigma^2}-\\frac{1}{\\mu}\\Bigr)\\mu^2\\) \\(b=\\displaystyle \\Bigl(\\frac{1}{\\mu}-1\\Bigr)\\). example, \\(\\mu=0.57\\) \\(\\sigma=0.075\\), can deduce \\(= 24.3\\) \\(b = 18.3\\) lines code:can check beta distribution indeed mean standard deviation given meta-analysis:can therefore adopt prior \\(\\text{Beta}(=24.3,\\,b=18.3)\\) incorporate mean information variability obtained allometric survival–mass relationship.moment-matching method apply probabilities. can also used construct prior real-valued parameter, example effect coypu body mass survival (see Chapter 5). Suppose expert says: “80% sure parameter \\(\\theta\\) lies –0.15 0.25.” sentence defines 80% credible interval: \\(\\Pr(\\theta \\[-0.15,0.25]) = 0.80\\). seek normal prior \\(\\theta \\sim N(\\mu,\\sigma^2)\\) reflects exactly information.can start mean \\(\\mu\\). interval symmetric, can directly deduce mean \\(\\mu\\) prior midpoint interval: \\(\\displaystyle{\\mu = \\frac{-0.15+0.25}{2}}=0.05\\).Now let us move standard deviation \\(\\sigma\\). expert states 80% values \\(\\theta\\) –0.15 0.25. normal distribution, proportion can written \\(\\Pr(\\mu - z\\,\\sigma \\leq \\theta \\leq \\mu + z \\, \\sigma) = 0.80\\). means 80% mass distribution contained interval centered \\(\\mu\\) width \\(2z\\sigma\\). level 80%, value \\(z\\) 1.2816 (obtained via qnorm(0.90), 0.90 upper quantile \\(1−\\alpha/2 = 1-20/2\\) \\((1−\\alpha)\\% = 80\\%\\) thus \\(\\alpha = 0.20\\)). Finally, obtain \\(\\sigma = \\displaystyle \\frac{0.25-(-0.15)}{2 \\times 1.2816} \\approx 0.156\\). calculation R:conclude desired informative prior \\(N(\\mu=0.05,\\sigma=0.156)\\). can check everything went well:Visually, Figure 4.3 shows density normal distribution mean \\(\\mu=0.05\\) standard deviation \\(\\sigma=0.156\\). light-blue interval corresponds central 80% credible interval, , interval [−0.15; 0.25] contains 80% probability mass. grey dotted lines indicate bounds interval, black dashed line marks position mean. see , thanks symmetry normal distribution, interval centered around mean, 10% mass lies side outside interval.\nFigure 4.3: Normal distribution mean 0.05 standard deviation 0.156. shaded interval corresponds 80% credible interval, –0.15 0.25.\n","code":"\n# desired mean and standard deviation for the beta distribution\nmu <- 0.57 # mean probability\nsigma <- 0.075 # standard deviation on that probability\n# inverse formulas to obtain the parameters a and b of a beta distribution\na <- ((1 - mu) / (sigma^2) - 1 / mu) * mu^2\nb <- a * (1 / mu - 1)\n# display a and b rounded\nc(a = round(a, 1), b = round(b, 1))\n#>    a    b \n#> 24.3 18.3\n# generate 10,000 values from a Beta distribution with parameters a = 24.3 and b = 18.3\nech_prior <- rbeta(n = 10000, shape1 = 24.3, shape2 = 18.3)\n# empirical mean of the draws (should be close to 0.57)\nmean(ech_prior)\n#> [1] 0.5685004\n# empirical standard deviation of the draws (should be close to 0.075)\nsd(ech_prior)\n#> [1] 0.07496597\n# lower and upper bounds given by the expert\na <- -0.15\nb <-  0.25\n\n# stated confidence level\nlevel <- 0.80\nalpha <- 1 - level\n\n# z value corresponding to an 80% credible interval\nz <- qnorm(1 - alpha / 2)  # ≈ 1.2816\n\n# mean = center of the interval\nmu <- (a + b) / 2\n\n# standard deviation deduced from the interval width\nsigma <- (b - a) / (2 * z)\n\nmu\n#> [1] 0.05\nsigma\n#> [1] 0.1560608\nmu    <- 0.05\nsigma <- 0.1560608\npnorm(c(-0.15, 0.25), mean = mu, sd = sigma)\n#> [1] 0.09999996 0.90000004\n#> 0.10 0.90    # OK: 10% on the left, 90% on the right → 80% in the center"},{"path":"prior.html","id":"surprise","chapter":"4 Prior distributions","heading":"4.5 Beware of so-called non-informative priors","text":"Bayesian statistics, often use non-informative priors. careful: appearances can misleading, especially working parameters defined transformed scales, logit log generalized linear models (Chapter 6). Let us take common example model probability \\(\\theta\\) logit scale via parameter \\(\\beta\\) \\(\\text{logit}(\\theta) = \\beta\\).practice, can use simulations check priors bring unpleasant surprises transformation; call prior predictive checks. happens even fitting model, :simulate values prior \\(\\beta\\) logit scale;apply inverse logit transformation obtain \\(\\theta\\);inspect induced prior distribution \\(\\theta\\) judge whether seems realistic.first choice take prior normal distribution large variance, example \\(\\beta \\sim N(0, 10^2)\\). Steps 1 2 obtained via:problem transformation inverse logit function, simulated values—thus probability \\(\\theta\\)—close 0 1 see Figure 4.4 (left panel), implicitly favors extreme values. go non-informative prior logit scale informative prior (without meaning ) natural scale probability.Another choice take \\(\\beta \\sim N(0, 1.5^2)\\). first two steps simulation can summarized :induced distribution \\(\\theta\\) uniform, covering mainly range values 0.05 0.95 can see Figure 4.4 (right panel), better reflects lack information \\(\\theta\\). second choice right one; speak weakly informative priors.\nFigure 4.4: Comparison two priors obtained probability \\(\\theta = \\text{logit}^{-1}(\\beta)\\) transformation inverse logit function \\(\\beta \\sim N(0, 10^2)\\) \\(\\beta \\sim N(0, 1.5^2)\\). x-axis represents different possible values probability \\(\\theta\\) obtained transformation inverse logit. y-axis indicates frequency simulated draws value.\nalso invariant priors, , priors whose shape accounts scale parameter. Jeffreys’ prior example: maximizes information brought data, remaining invariant reparameterization. example, probability \\(\\theta\\), Jeffreys’ prior \\(\\text{Beta}(0.5, 0.5)\\). prior less flat uniform \\(\\text{Beta}(1, 1)\\). often used one wants objective approach, without introducing subjective information. practice, however, Jeffreys’ prior difficult compute, prefer simulation-based approach ensure transformed parameters reasonable priors.","code":"\nlogit_prior <- rnorm(n = 1000, mean = 0, sd = 10) # simulation\nprior <- plogis(logit_prior) # transformation\nlogit_prior2 <- rnorm(n = 1000, mean = 0, sd = 1.5)\nprior2 <- plogis(logit_prior2)"},{"path":"prior.html","id":"summary-1","chapter":"4 Prior distributions","heading":"4.6 Summary","text":"richer data , less prior influences posterior estimate.richer data , less prior influences posterior estimate.hesitate take time visualize priors natural scale parameters using simulations.hesitate take time visualize priors natural scale parameters using simulations.Moment-matching methods offer practical way transform encode knowledge parameters distributions can serve priors (beta normal, example).Moment-matching methods offer practical way transform encode knowledge parameters distributions can serve priors (beta normal, example).use type prior?use type prior?","code":""},{"path":"lms.html","id":"lms","chapter":"5 La régression","heading":"5 La régression","text":"","code":""},{"path":"lms.html","id":"introduction-5","chapter":"5 La régression","heading":"5.1 Introduction","text":"Ce chapitre présente l’application de la statistique bayésienne à la régression linéaire. prendra un exemple qui nous permettra d’aller un peu plus loin que notre exemple fil rouge sur la survie. Ce sera l’occasion d’aborder comment et pourquoi utiliser un modèle pour simuler des données. Nous en profiterons pour illustrer la comparaison et la validation des modèles. Nous utiliserons NIMBLE et brms et comparerons avec l’approche fréquentiste.","code":""},{"path":"lms.html","id":"la-régression-linéaire","chapter":"5 La régression","heading":"5.2 La régression linéaire","text":"","code":""},{"path":"lms.html","id":"le-modèle","chapter":"5 La régression","heading":"5.2.1 Le modèle","text":"Pour changer un peu, je vous propose d’utiliser NIMBLE et brms sur un exemple différent de celui de l’estimation de la survie. Attardons-nous sur la régression linéaire.Commençons par poser les bases de notre modèle linéaire. \\(n\\) mesures d’une variable réponse \\(y_i\\) avec \\(\\) qui varie de 1 à \\(n\\). Pensez par exemple à la masse (en kilogrammes) de nos ragondins dans l’exemple fil rouge. associe chaque mesure à une variable explicative \\(x_i\\), par exemple la température extérieure moyenne en hiver (en degrés Celsius) pour nos ragondins. cherche à étudier l’effet de la température sur la masse. Le plus simple est de supposer une relation linéaire entre les deux, utilise donc un modèle de régression linéaire. Le modèle comporte une ordonnée à l’origine (ou intercept) \\(\\beta_0\\), et une pente \\(\\beta_1\\) qui décrit l’effet de \\(x_i\\) sur \\(y_i\\), ou de la température sur la masse des ragondins. aussi besoin d’un paramètre pour décrire la variabilité résiduelle représentée par un paramètre de variance \\(\\sigma^2\\), qui capte la part de variation dans les \\(y_i\\) non expliquée par les \\(x_i\\). Vous avez probablement déjà rencontré ce modèle sous la forme : \\(y_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i\\) où les erreurs \\(\\varepsilon_i\\) sont supposées indépendantes et distribuées selon une loi normale de moyenne 0 et de variance \\(\\sigma^2\\).L’intercept \\(\\beta_0\\) nous donne la masse quand la température est de 0 degré (\\(x_i = 0\\)). Le paramètre \\(\\beta_1\\) nous renseigne sur le changement dans la variable réponse pour une augmentation d’une unité (ici 1 degré Celsius) de la variable explicative (d’où le terme “pente” pour désigner ce paramètre). En général, conseille (fortement) de centrer (soustraire la moyenne) et réduire (diviser par l’écart-type) les valeurs de la variable explicative pour des questions numériques et d’interprétation. Numérique d’abord car cela permet aux algorithmes, qu’ils soient fréquentistes ou bayésiens, de ne pas se perdre dans des recoins de l’espace du paramètre. Interprétation ensuite, car interprète alors l’intercept \\(\\beta_0\\) comme la valeur de la variable réponse pour une valeur moyenne de la variable explicative.Dans cette section, plutôt que d’analyser de “vraies” données, nous allons, à partir des paramètres \\(\\beta_0\\), \\(\\beta_1\\) et \\(\\sigma\\), simuler des données artificielles, comme si elles provenaient d’un vrai processus sous-jacent.","code":""},{"path":"lms.html","id":"simuler-des-données","chapter":"5 La régression","heading":"5.2.2 Simuler des données","text":"Qu’est-ce que j’entends par simuler des données ? L’analyse et la simulation des données sont deux faces d’un même modèle. Dans l’analyse, utilise les données pour estimer les paramètres d’un modèle. Dans la simulation, fixe les paramètres et utilise le modèle pour générer des données. Une raison d’utiliser les simulations est que cette gymnastique va nous obliger à bien comprendre le modèle ; si je n’arrive pas à simuler des données à partir d’un modèle, c’est que je n’ai pas complètement compris comment il marchait. Il y des tas d’autres bonnes raisons pour utiliser les simulations. Comme la vérité (les paramètres et le modèle) est connue, peut vérifier que le modèle est bien codé. peut évaluer le biais et la précision des estimations de nos paramètres, évaluer les effets de ne pas respecter les hypothèses du modèle, planifier un protocole de récolte de données ou encore évaluer la puissance d’un test statistique. Bref, c’est une technique très utile à avoir dans votre boîte à outils !Revenons à notre exemple. Pour simuler des données selon le modèle de régression linéaire, commence par fixer nos paramètres : \\(\\beta_0 = 0.1\\), \\(\\beta_1 = 1\\) et \\(\\sigma^2 = 0.5\\) :Puis simule \\(n = 100\\) valeurs \\(x_i\\) de notre variable explicative selon une loi normale de moyenne 0 et d’écart-type 1, autrement dit \\(N(0,1)\\) :Enfin, simule les valeurs de la variable réponse, en ajoutant une erreur normale epsilon à la relation linéaire beta0 + beta1 * x :\nFigure 5.1: Données simulées (n = 100) selon le modèle \\(y_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i\\), avec \\(\\beta_0 = 0.1\\), \\(\\beta_1 = 1\\) et \\(\\sigma = 1\\). La droite rouge correspond à la droite de régression.\n","code":"\nbeta0 <- 0.1 # valeur vraie de l'intercept\nbeta1 <- 1 # valeur vraie du coefficient de x\nsigma <- 0.5 # écart-type des erreurs\nset.seed(666) # pour rendre la simulation reproductible\nn <- 100 # nombre d'observations\nx <- rnorm(n = n, mean = 0, sd = 1) # covariable x simulée selon une loi normale standard\nepsilon <- rnorm(n, mean = 0, sd = sigma) # génère les erreurs normales\ny <- beta0 + beta1 * x + epsilon # ajoute les erreurs à la relation linéaire\ndata <- data.frame(y = y, x = x)"},{"path":"lms.html","id":"lajustement-avec-brms","chapter":"5 La régression","heading":"5.2.3 L’ajustement avec brms","text":"Dans cette section, utilise brms pour ajuster le modèle de régression linéaire aux données qu’vient de générer. Si tout se passe bien, les paramètres estimés devraient être proches des valeurs utilisées pour générer les données. Je vais relativement vite ici puisqu’couvert les différentes étapes au Chapitre 3. La syntaxe est très proche de celle qu’utiliserait pour ajuster le modèle par maximum de vraisemblance avec la fonction lm() dans R :Jetons un coup d’oeil aux résumés numériques et aux diagnostics de convergence :Par défaut, brms utilisé quatre chaînes qui ont tourné pendant 2000 itérations chacune avec 1000 itérations utilisées comme burn-, soit au total 4000 itérations pour l’inférence posteriori. Dans les sorties, Intercept, x et sigma correspondent respectivement aux paramètres \\(\\beta_0\\), \\(\\beta_1\\) et \\(\\sigma\\) du modèle. Le \\(\\hat{R}\\) pour les 3 paramètres vaut 1, et les tailles d’échantillon efficaces sont satisfaisantes. Les intervalles de crédibilité contiennent la vraie valeur du paramètre utilisée pour simuler les données.vérifie que le mixing est bon (Figure 5.2) :\nFigure 5.2: Histogrammes des distributions posteriori (colonne de gauche) et traces (colonne de droite) des paramètres de la régression linéaire. Dans les histogrammes, l’axe des abscisses représente les valeurs possibles du paramètre estimé (intercept, pente ou écart-type) et l’axe des ordonnées correspond à leur fréquence dans l’échantillon posteriori. Dans les trace plots, l’axe des abscisses indique le numéro d’itération du MCMC, tandis que l’axe des ordonnées représente la valeur simulée du paramètre à chaque itération.\n","code":"\nlm.brms <- brm(y ~ x, # formule : y en fonction de x\n               data = data, # jeu de données\n               family = gaussian) # distribution normale\nsummary(lm.brms)\n#>  Family: gaussian \n#>   Links: mu = identity; sigma = identity \n#> Formula: y ~ x \n#>    Data: data (Number of observations: 100) \n#>   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#>          total post-warmup draws = 4000\n#> \n#> Regression Coefficients:\n#>           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> Intercept     0.06      0.06    -0.05     0.17 1.00     4366     3028\n#> x             1.10      0.06     0.99     1.21 1.00     4188     3147\n#> \n#> Further Distributional Parameters:\n#>       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> sigma     0.57      0.04     0.49     0.65 1.00     4090     3050\n#> \n#> Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n#> and Tail_ESS are effective sample size measures, and Rhat is the potential\n#> scale reduction factor on split chains (at convergence, Rhat = 1).\nplot(lm.brms)"},{"path":"lms.html","id":"weakly-informative-priors","chapter":"5 La régression","heading":"5.2.4 Des priors faiblement informatifs","text":"Plutôt que d’utiliser les priors par défaut de brms, choisissons d’autres priors. Nous allons utiliser des priors faiblement informatifs, et plus spécifiquement une normale avec moyenne 0 et écart-type 1.5 ou \\(N(0,1.5)\\) pour les paramètres de régression \\(\\beta_0\\) et \\(\\beta_1\\). déjà parlé des priors faiblement informatifs au Chapitre 4. L’idée est proche de celle des priors vagues ou non-informatifs, dans le sens où l’s’efforce de refléter via les priors faiblement informatifs le fait qu’n’pas vraiment d’information sur les paramètres du modèle. La différence est que les priors non-informatifs peuvent induire des valeurs aberrantes comme l’vu au Chapitre 4. C’est encore le cas ici. Prenez par exemple des \\(N(0,100)\\) pour les paramètres de la relation linéaire qui lie la masse des ragondins à la température, et simulez tout un tas de valeurs dans ces priors, puis formez la relation linéaire :\nFigure 5.3: Simulation de droites de régression issues des distributions priori. Chaque ligne correspond à un tirage des paramètres : intercept et pente ~ N(0, 100).\n\nFigure 5.4: Simulation de droites de régression issues des distributions priori. Chaque ligne correspond à un tirage des paramètres : intercept et pente ~ N(0, 1.5).\nobtient des valeurs plus raisonnables pour la masse des ragondins qui dépassent rarement 10 kilogrammes. toujours des valeurs négatives, mais moindres, l’algorithme MCMC devrait s’en sortir. Il y aussi un avantage numérique à utiliser des priors faiblement informatifs, ils aident les méthodes MCMC à ne pas se perdre dans l’espace de toutes les valeurs possibles pour les paramètres à estimer, et leur permettent de se focaliser sur les valeurs réalistes de ces paramètres. En faisant ça, vous avez peut-être l’impression qu’utilise les données pour construire les priors, alors qu’dit que le prior devait refléter l’information disponible avant de voir les données. C’est l’occasion de préciser un peu ce point. L’important est surtout que le prior représente l’information indépendante des données qui sont utilisées dans la vraisemblance.s’est jusqu’ici concentrés sur les paramètres de régression, l’intercept \\(\\beta_0\\) et la pente \\(\\beta_1\\). Mais qu’en est-il de l’écart-type, \\(\\sigma\\) ? Ce paramètre est tout aussi important : il reflète à quel point les observations s’écartent de la tendance moyenne décrite par la droite de régression.Une option souvent envisagée est de lui attribuer une loi uniforme, par exemple \\(\\sigma \\sim U(0, B)\\), avec une borne inférieure naturelle (0, puisque \\(\\sigma\\) est toujours positive), mais une borne supérieure \\(B\\) difficile à choisir. Quelle valeur maximale donner à un écart-type ? Dans certains cas, une valeur apparemment raisonnable peut se révéler trop large. Par exemple, si l’modélise des tailles humaines et que l’fixe \\(\\sigma \\sim U(0, 50)\\) (en cm), cela revient à supposer que 95% des tailles sont réparties sur une plage de 100 cm autour de la moyenne – ce qui est très improbable.Une alternative plus souple et plus réaliste consiste à utiliser une loi exponentielle \\(\\sigma \\sim \\exp(\\lambda)\\) où \\(\\lambda > 0\\) est un paramètre de taux. Cette loi est définie uniquement pour des valeurs positives, ce qui est cohérent avec la nature de \\(\\sigma\\), et elle favorise les petites valeurs d’écart-type tout en laissant la possibilité à \\(\\sigma\\) d’être plus grande si les données le justifient.Par défaut, prend souvent \\(\\lambda = 1\\). Avec \\(\\lambda = 1\\), la moyenne et l’écart-type de cette loi sont tous deux égaux à \\(1\\), ce qui induit une loi priori modeste mais non restrictive (Figure 5.5).\nFigure 5.5: Comparaison entre deux lois priori pour l’écart-type \\(\\sigma\\) : une loi uniforme \\(\\text{U}(0,5)\\), qui donne la même densité entre 0 et 5, et une loi exponentielle \\(\\text{Exp}(1)\\), qui favorise les petites valeurs tout en conservant une queue plus lourde.\npeut formaliser ce modèle comme suit :\n\\[\\begin{align}\ny_i &\\sim \\text{Normale}(\\mu_i, \\sigma^2) &\\text{[vraisemblance]}\\\\\n\\mu_i &= \\beta_0 + \\beta_1 \\; x_i &\\text{[relation linéaire]}\\\\\n\\beta_0, \\beta_1 &\\sim \\text{Normale}(0, 1.5) &\\text{[prior sur les paramètres]} \\\\\n\\sigma &\\sim \\text{Exp}(1) &\\text{[prior sur les paramètres]} \\\\\n\\end{align}\\]Spécifions ces priors :Puis refaisons l’ajustement avec brms :vérifie que les résumés numériques obtenus sont proches de ceux obtenus avec les priors par défaut, et surtout des valeurs utilisées pour simuler les données :Ici, les deux modèles donnent quasiment la même chose, ce qui n’rien de surprenant car les données sont suffisamment informatives pour qu’elles “prennent le dessus sur” le prior. L’intérêt des priors faiblement informatifs ne se voit pas tant dans ce petit exemple que dans d’autres situations : ils évitent les valeurs aberrantes, stabilisent les calculs MCMC et restent utiles quand moins de données ou des modèles plus complexes.","code":"\n\n# nombre de droites à simuler\nn_lines <- 100\n\n# tirages des intercepts et pentes selon les priors\nintercepts <- rnorm(n_lines, mean = 0, sd = 100)\nslopes <- rnorm(n_lines, mean = 0, sd = 100)\n\n# création d'un data frame\nlines_df <- data.frame()\nfor (i in 1:n_lines) {\n  y_vals <- intercepts[i] + slopes[i] * x\n  temp_df <- data.frame(x = x, y = y_vals, line = as.factor(i))\n  lines_df <- rbind(lines_df, temp_df)\n}\n\n# tracé avec ggplot2\nggplot(lines_df, aes(x = x, y = y, group = line)) +\n  geom_line(alpha = 0.3) +\n  theme_minimal() +\n  labs(x = \"x\", y = \"y\")\nmyprior <- c(\n  prior(normal(0, 1.5), class = b), # prior sur le coefficient de x\n  prior(normal(0, 1.5), class = Intercept), # prior sur l'intercept\n  prior(exponential(1), class = sigma) # prior sur l'écart-type de l'erreur\n)\nlm.brms <- brm(y ~ x, \n               data = data, \n               family = gaussian, \n               prior = myprior)\nsummary(lm.brms)\n#>  Family: gaussian \n#>   Links: mu = identity; sigma = identity \n#> Formula: y ~ x \n#>    Data: data (Number of observations: 100) \n#>   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#>          total post-warmup draws = 4000\n#> \n#> Regression Coefficients:\n#>           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> Intercept     0.06      0.06    -0.05     0.18 1.00     3562     2765\n#> x             1.10      0.06     0.99     1.21 1.00     3870     2731\n#> \n#> Further Distributional Parameters:\n#>       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> sigma     0.57      0.04     0.49     0.66 1.00     3540     2633\n#> \n#> Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n#> and Tail_ESS are effective sample size measures, and Rhat is the potential\n#> scale reduction factor on split chains (at convergence, Rhat = 1)."},{"path":"lms.html","id":"lajustement-avec-nimble","chapter":"5 La régression","heading":"5.2.5 L’ajustement avec NIMBLE","text":"commence par écrire le modèle :Dans ce bloc de code, commence par spécifier des priors sur les trois paramètres du modèle : un prior normal centré en 0 avec un écart-type de 1.5 pour l’intercept \\(\\beta_0\\) et pour la pente \\(\\beta_1\\), ainsi qu’un prior exponentiel pour l’écart-type \\(\\sigma\\) des erreurs. La partie suivante est une boucle (1:n) qui définit la vraisemblance. spécifie la vraisemblance observation par observation, NIMBLE en déduit automatiquement le produit des vraisemblances sur tous les individus, ce qui correspond à la vraisemblance du jeu de données. Pour chaque observation \\(\\), une distribution normale centrée en beta0 + beta1 * x[], avec un écart-type sigma. retrouve la relation \\(y_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i\\) où \\(\\varepsilon_i \\sim N(0,\\sigma^2)\\) qui est strictement équivalente à \\(y_i \\sim N(\\beta_0 + \\beta_1 x_i,\\sigma^2)\\).Les étapes suivantes consistent à mettre les données dans une liste, spécifier les valeurs initiales, et préciser les paramètres pour lesquels souhaite des sorties :alors tous les ingrédients pour lancer NIMBLE :Inspectons les résultats :retrouve des résumés numériques proches de ceux obtenus avec brms, et proches des vraies valeurs des paramètres utilisés pour simuler les données.Concernant la convergence, peut inspecter les trace plots :Tout va bien. Le mélange est correct, les diagnostics de convergence sont au vert.","code":"\nmodel <- nimbleCode({\n  # les priors\n  beta0 ~ dnorm(0, sd = 1.5) # prior normal sur l'intercept\n  beta1 ~ dnorm(0, sd = 1.5) # prior normal sur le coefficient\n  sigma ~ dexp(1) # prior exponentiel sur l'écart-type\n  # la vraisemblance\n  for(i in 1:n) {\n    y[i] ~ dnorm(beta0 + beta1 * x[i], sd = sigma) # equiv de yi = beta0 + beta1 * xi + epsiloni\n  }\n})\ndat <- list(x = x, y = y, n = n) # données\ninits <- list(list(beta0 = -0.5, beta1 = -0.5, sigma = 0.1), # valeurs initiales chaine 1\n              list(beta0 = 0, beta1 = 0, sigma = 1), # valeurs initiales chaine 2\n              list(beta0 = 0.5, beta1 = 0.5, sigma = 0.5)) # valeurs initiales chaine 3\npar <- c(\"beta0\", \"beta1\", \"sigma\")\nlm.nimble <- nimbleMCMC(\n  code = model,\n  data = dat,\n  inits = inits,\n  monitors = par,\n  niter = 2000,\n  nburnin = 1000,\n  nchains = 3\n)\nMCMCsummary(lm.nimble, round = 2)\n#>       mean   sd  2.5%  50% 97.5% Rhat n.eff\n#> beta0 0.06 0.06 -0.05 0.06  0.17 1.00  3000\n#> beta1 1.10 0.06  0.99 1.10  1.21 1.00  3000\n#> sigma 0.57 0.04  0.49 0.56  0.65 1.01   772\nMCMCtrace(object = lm.nimble,\n          pdf = FALSE,\n          ind = TRUE,\n          Rhat = TRUE,\n          n.eff = TRUE)"},{"path":"lms.html","id":"lajustement-par-maximum-de-vraisemblance","chapter":"5 La régression","heading":"5.2.6 L’ajustement par maximum de vraisemblance","text":"Et pour finir, peut comparer avec l’ajustement par maximum de vraisemblance qu’obtient simplement avec la commande lm(y ~ x, data = data), tout est dans la Figure 5.6 :\nFigure 5.6: Comparaison des estimations des paramètres du modèle (intercept ou ordonnée à l’origine et pente) selon les différentes méthodes (brms, lm et NIMBLE). Les points donnent les moyennes posteriori pour brms et NIMBLE, et l’estimation du maximum de vraisemblance pour lm. donne également les intervalles de crédibilité (pour brms et NIMBLE) et de confiance (pour lm) à 95%. La ligne en tirets noirs indique la vraie valeur utilisée pour simuler les données.\nLes moyennes posteriori obtenues avec NIMBLE et brms sont proches des estimations par maximum de vraisemblance pour l’incercept et la pente, dans une moindre mesure. Les intervalles de crédibilité obtenus avec NIMBLE et brms et l’intervalle de confiance obtenu par maximum de vraisemblance englobent tous les vraies valeurs des paramètres qui ont servi à simuler les données. Gardez à l’esprit qu’il s’agit d’une seule simulation, il faudrait répéter l’exercice un grand nombre de fois pour évaluer formellement la distance entre les vraies valeurs et les estimations des paramètres (le biais).","code":""},{"path":"lms.html","id":"lévaluation-des-modèles","chapter":"5 La régression","heading":"5.3 L’évaluation des modèles","text":"La qualité de l’ajustement d’un modèle aux données est essentielle pour évaluer la confiance que l’peut accorder aux estimations des paramètres. Les tests de qualité d’ajustement (ou goodness--fit en anglais) sont bien établis en statistique fréquentiste, et beaucoup d’entre eux peuvent aussi être utilisés dans des modèles bayésiens simples. C’est le cas par exemple de l’analyse des résidus.Dans le cas d’une régression linéaire, il y plusieurs hypothèses sur lesquelles repose le modèle. Ce sont les hypothèses d’indépendance, de normalité, de linéarité et d’homoscédasticité (\\(\\sigma\\) ne varie pas avec la variable explicative). peut en général évaluer les deux premières avec le contexte. Concernant les deux autres, peut visualiser l’ajustement en superposant la droite de régression estimée au nuage de points observés. Avec le package brms, cela donne la Figure 5.7 :\nFigure 5.7: Ajustement du modèle linéaire par brms. La droite bleue est la régression estimée, obtenue en fixant l’ordonnée à l’origine et la pente à leur moyenne posteriori, entourée de son intervalle de crédibilité à 95 %.\nAvec NIMBLE, c’est la Figure 5.8 :\nFigure 5.8: Ajustement du modèle linéaire par NIMBLE. La droite bleue est la régression estimée, obtenue en fixant l’ordonnée à l’origine et la pente à leur moyenne posteriori, entourée de son intervalle de crédibilité à 95 %.\nLes méthodes bayésiennes sont souvent utilisées pour des modèles plus complexes que la régression linéaire (comme les modèles mixtes, voir Chapitre 6), pour lesquels il n’existe pas de tests de qualité d’ajustement standards “clé en main”. Dans ces situations, utilise couramment ce qu’appelle des posterior predictive checks. L’idée est de simuler de nouveaux jeux de données à partir de la distribution posteriori des paramètres du modèle, puis de les comparer aux données observées. Plus les données simulées ressemblent aux données réelles, plus cela suggère que le modèle s’ajuste bien. Cette comparaison peut se faire de manière visuelle ou à l’aide d’une Bayesian p-value qui quantifie l’écart entre données simulées et observées.Dans brms, il suffit de faire :\nFigure 5.9: Posterior predictive checks réalisés avec brms. La courbe noire correspond aux données observées, les courbes bleues aux données simulées selon le modèle. L’axe des abscisses représente les valeurs possibles de la variable réponse simulée ou observée. L’axe des ordonnées indique leur densité estimée.\nLa fonction pp_check() génère des graphiques de posterior predictive checks (Figure 5.9). Elle compare les données observées à des données simulées à partir du modèle ajusté. Si le modèle est bien ajusté aux données, alors devrait pouvoir l’utiliser pour générer des données qui ressemblent aux données observées. Par conséquent, si les courbes simulées recouvrent bien les observations, cela indique que le modèle capte correctement la structure des données. Dans le cas contraire, cela peut suggérer un problème de spécification du modèle, par exemple un lien ou une famille de distribution inadaptée (voir Chapitre 6).Il n’y pas de fonction dédiée dans NIMBLE donc il va falloir simuler des données selon le modèle avec les paramètres estimés. pourrait le faire à la main comme avec l’espérance de vie, mais le plus simple est d’inclure une ligne supplémentaire dans le code NIMBLE :C’est la ligne y_sim[] ~ dnorm(beta0 + beta1 * x[], sd = sigma) que j’ai ajoutée pour simuler selon le modèle ajusté. Les données et les valeurs initiales ne changent pas, il nous faut juste ajouter y_sim à la liste des paramètres qu’veut retrouver dans les sorties :Puis relance NIMBLE :fusionne alors les 3 chaînes, puis sélectionne uniquement les colonnes correspondant à y_sim :fait ensuite 10 tirages, comme par défaut dans brms, puis met les résultats en forme :Enfin, obtient le graphe des posterior predictive checks dans la Figure 5.10 :\nFigure 5.10: Posterior predictive checks réalisés avec NIMBLE. La courbe noire correspond aux données observées, les courbes bleues aux données simulées selon le modèle. L’axe des abscisses représente les valeurs possibles de la variable réponse simulée ou observée. L’axe des ordonnées indique leur densité estimée.\npeut également calculer une Bayesian p-value (ou p-valeur bayésienne) qui représente la proportion de jeux de données simulés sous le modèle pour lesquels la statistique choisie (ici la moyenne) est aussi grande ou plus grande que celle observée. Une valeur proche de 0 ou de 1 peut indiquer un mauvais ajustement du modèle pour cette statistique particulière, tandis qu’une valeur proche de 0.5 suggère un bon ajustement. Cette Bayesian p-value s’obtient comme suit :Avec brms, peut aussi obtenir cette Bayesian p-value :","code":"\n# extrait les valeurs tirées dans les distributions a posteriori des paramètres\npost <- as_draws_df(lm.brms)\n\n# crée une grille de x pour tracer l'intervalle de crédibilité\ngrille_x <- tibble(x = seq(min(data$x), max(data$x), length.out = 100))\n\n# pour chaque x, simule des valeurs de y à partir des échantillons\npred <- post %>%\n  select(b_Intercept, b_x) %>%\n  expand_grid(grille_x) %>%\n  mutate(y = b_Intercept + b_x * x) %>%\n  group_by(x) %>%\n  summarise(\n    mean = mean(y),\n    lower = quantile(y, 0.025),\n    upper = quantile(y, 0.975),\n    .groups = \"drop\"\n  )\n\n# extrait les moyennes a posteriori des paramètres\nintercept <- summary(lm.brms)$fixed[1,1]\nslope <- summary(lm.brms)$fixed[2,1]\n\n# tracé\nggplot(data, aes(x = x, y = y)) +\n  geom_point(alpha = 0.6) +\n  geom_ribbon(data = pred, aes(x = x, ymin = lower, ymax = upper), fill = \"blue\", alpha = 0.2, inherit.aes = FALSE) +\n  geom_line(data = pred, aes(x = x, y = mean), color = \"blue\", size = 1.2) +\n  labs(x = \"x\", y = \"y\") +\n  coord_cartesian(xlim = range(grille_x$x)) +\n  theme_minimal()\n# données simulées\nx <- data$x\ny <- data$y\n\n# tirages postérieurs\nposterior <- rbind(lm.nimble$chain1, lm.nimble$chain2, lm.nimble$chain3)\nbeta0 <- posterior[,'beta0']\nbeta1 <- posterior[,'beta1']\n\n# grille d'abscisses\nx_seq <- seq(min(data$x), max(data$x), length.out = 100)\n\n# calcul des prédictions pour chaque x\npred_matrix <- sapply(x_seq, function(xi) beta0 + beta1 * xi)\n\n# résumé (moyenne et intervalle)\npred_df <- tibble(\n  x = x_seq,\n  y_mean = colMeans(pred_matrix),\n  y_lower = apply(pred_matrix, 2, quantile, probs = 0.025),\n  y_upper = apply(pred_matrix, 2, quantile, probs = 0.975)\n)\n\n# données et vraie relation\ntrue_df <- tibble(x = x_seq, y_true = 0.1 + 1 * x_seq)\n\n# tracé\nggplot() +\n  geom_point(data = data, aes(x = x, y = y), alpha = 0.6) +\n  geom_ribbon(data = pred_df, aes(x = x, ymin = y_lower, ymax = y_upper), fill = \"blue\", alpha = 0.2) +\n  geom_line(data = pred_df, aes(x = x, y = y_mean), color = \"blue\", size = 1.2) +\n # geom_line(data = true_df, aes(x = x, y = y_true), color = \"red\", size = 1.2) +\n  labs(x = \"x\", y = \"y\") +\n  theme_minimal()\npp_check(lm.brms)\nmodel <- nimbleCode({\n  beta0 ~ dnorm(0, sd = 1.5) # prior normal sur l'intercept\n  beta1 ~ dnorm(0, sd = 1.5) # prior normal sur le coefficient\n  sigma ~ dexp(1) # prior exponentiel sur l'écart-type\n  for(i in 1:n) {\n    y[i] ~ dnorm(beta0 + beta1 * x[i], sd = sigma) # modèle pour les données observées\n    y_sim[i] ~ dnorm(beta0 + beta1 * x[i], sd = sigma) # modèle pour les données simulées\n  }\n})\npar <- c(\"beta0\", \"beta1\", \"sigma\", \"y_sim\")\nlm.nimble <- nimbleMCMC(\n  code = model,\n  data = dat,\n  inits = inits,\n  monitors = par,\n  niter = 2000,\n  nburnin = 1000,\n  nchains = 3\n)\n#> |-------------|-------------|-------------|-------------|\n#> |-------------------------------------------------------|\n#> |-------------|-------------|-------------|-------------|\n#> |-------------------------------------------------------|\n#> |-------------|-------------|-------------|-------------|\n#> |-------------------------------------------------------|\n# fusion des trois chaînes MCMC obtenues avec NIMBLE\ny_sim_mcmc <- rbind(lm.nimble$chain1, lm.nimble$chain2, lm.nimble$chain3)\n# sélection des colonnes correspondant aux simulations de y (les y_sim[i])\ny_sim_cols <- grep(\"^y_sim\\\\[\", colnames(y_sim_mcmc))\n# extraction de la matrice des valeurs simulées pour y\ny_sim_matrix <- y_sim_mcmc[, y_sim_cols]\n# fixe la graine pour reproductibilité\nset.seed(123)\n# sélectionne au hasard 10 tirages parmi les simulations (comme le fait brms par défaut)\nsim_indices <- sample(1:nrow(y_sim_matrix), 10)\n# mise en forme des simulations \nsimulations_df <- data.frame(\n  y_sim = as.vector(t(y_sim_matrix[sim_indices, ])), # valeurs simulées\n  Replicate = rep(1:length(sim_indices), each = n), # identifiant du tirage (1 à 10)\n  Observation = rep(1:n, times = length(sim_indices)) # identifiant de l'observation (1 à n)\n)\nggplot() +\n  geom_density(aes(x = y_sim, group = Replicate), color = \"lightblue\", alpha = 0.2, data = simulations_df) +\n  geom_density(aes(x = y), color = \"black\", alpha = 0.5, size = 1.2, data = data.frame(y = y)) +\n  labs(x = \"\",\n       y = \"\") +\n  theme_minimal(base_size = 14)\n# Statistique de test observée : ici la moyenne des y observés\nT_obs <- mean(y)\n\n# Statistique de test sur les données simulées\nT_sim <- apply(y_sim_matrix, 1, mean)\n\n# Valeur-p bayésienne : proportion des simulations où T_sim est plus extrême que T_obs\nbayes_pval <- mean(T_sim >= T_obs)\n\n# Affichage du résultat\nbayes_pval\n#> [1] 0.512\n# Extraire les simulations de y_rep\ny_rep <- posterior_predict(lm.brms)\n\n# Calculer la statistique de test sur les données simulées (moyenne ici)\nT_sim <- rowMeans(y_rep)\n\n# Calculer la statistique observée\nT_obs <- mean(lm.brms$data$y)\n\n# Calculer la Bayesian p-value\nbayes_pval <- mean(T_sim >= T_obs)\n\n# Afficher le résultat\nbayes_pval\n#> [1] 0.49075"},{"path":"lms.html","id":"la-comparaison-de-modèles","chapter":"5 La régression","heading":"5.4 La comparaison de modèles","text":"Comme l’vu dans le Chapitre 1, la statistique bayésienne permet de comparer plusieurs hypothèses entre elles, et de savoir à quel point une hypothèse est plausible à partir des données que nous avons collectées.Il est essentiel, avant de comparer des modèles, de se demander quel est l’objectif de l’analyse : s’agit-il de mieux comprendre un phénomène (approche explicative), ou plutôt de faire des prédictions (approche prédictive) ?Une stratégie consiste à construire un modèle unique incluant les variables jugées pertinentes, puis à l’ajuster, l’examiner, le tester, et l’améliorer progressivement. Cette approche vise moins à identifier le meilleur modèle qu’à explorer différentes variantes pour mieux comprendre le système étudié.Pour évaluer la capacité prédictive d’un modèle, peut s’appuyer sur des données déjà utilisées pour l’ajustement (prédiction interne) ou, de manière plus fiable, sur de nouvelles données (prédiction externe). Cette dernière approche nécessite toutefois de diviser les données en un jeu d’apprentissage et un jeu de test. À défaut, il est possible d’estimer les performances prédictives sur les données d’apprentissage elles-mêmes à l’aide d’outils comme le WAIC ou le LOO-CV.Le WAIC (Watanabe-Akaike Information Criterion) et le LOO-CV (Leave-One-cross-validation) permettent de comparer des modèles en estimant leur capacité à prédire de nouvelles données. Ils combinent l’ajustement aux données observées avec une pénalisation de la complexité du modèle. Une valeur de WAIC ou de LOO-CV plus faible indique un meilleur modèle. Le WAIC est basé sur une approximation théorique, tandis que le LOO-CV repose sur une validation croisée. Le LOO-CV est généralement plus précis, surtout pour les modèles complexes ou les jeux de données de taille limitée, mais il est aussi plus coûteux en calcul. En pratique, lorsque les modèles sont bien spécifiés et que l’échantillon est grand, WAIC et LOO-CV donnent souvent des résultats très proches pour un même modèle.Je reviens à l’exemple de la régression linéaire. aimerait tester l’hypothèse que la variable \\(x\\) explique bien une part importante de la variation dans \\(y\\). Cela revient à comparer les modèles avec et sans cette variable.Dans brms, ajuste ces deux modèles avec des priors faiblement informatifs :La fonction waic() permet d’extraire le WAIC, où le modèle avec la plus petite valeur est préféré. Si le modèle avec \\(x\\) est bien le bon (c’est ce qu’attend puisque c’est comme ça que les données ont été simulées), devrait voir qu’il est nettement meilleur que celui sans covariable :Ouf, c’est bien le cas. La fonction loo() permet de calculer le LOO-CV (une approximation en fait) :Dans cette sortie R, elpd_diff donne l’écart de LOO-CV entre chaque modèle et celui qui la plus grande valeur. Ainsi, le meilleur modèle est sur la première ligne avec un elpd_diff égal à zéro ; ici, c’est le modèle avec la covariable. arrive donc à la même conclusion qu’avec le WAIC.peut obtenir les valeurs de WAIC avec NIMBLE également. Pour ce faire il suffit d’ajouter WAIC = TRUE dans l’appel à la fonction nimbleMCMC:arrive à la même conclusion qu’avec brms. noter que NIMBLE ne fournit pas directement une fonction loo() comme brms, même si pourrait estimer le LOO-CV à la main.","code":"# Modèle avec covariable\nfit1 <- brm(y ~ x, data = data, family = gaussian(),\n            prior = c(\n              prior(normal(0, 1.5), class = Intercept),\n              prior(normal(0, 1.5), class = b),\n              prior(exponential(1), class = sigma)\n            ))\n\n# Modèle sans covariable\nfit0 <- brm(y ~ 1, data = data, family = gaussian(),\n            prior = c(\n              prior(normal(0, 1.5), class = Intercept),\n              prior(exponential(1), class = sigma))\n# Calcul du WAIC pour chaque modèle\nwaic1 <- waic(fit1)\nwaic0 <- waic(fit0)\n\n# Comparaison\nwaic1$estimates['waic',]\n#>  Estimate        SE \n#> 172.50456  13.13435\nwaic0$estimates['waic',]\n#>  Estimate        SE \n#> 333.97491  17.23233\n# Leave-one-out cross-validation\nloo1 <- loo(fit1)\nloo0 <- loo(fit0)\n\n# Comparaison\nloo_compare(loo0, loo1)\n#>      elpd_diff se_diff\n#> fit1   0.0       0.0  \n#> fit0 -80.7       9.1\n# Code du modèle avec covariable\nmodel_avec <- nimbleCode({\n  # les priors\n  beta0 ~ dnorm(0, sd = 1.5) # prior normal sur l'intercept\n  beta1 ~ dnorm(0, sd = 1.5) # prior normal sur le coefficient\n  sigma ~ dexp(1) # prior exponentiel sur l'écart-type\n  # la vraisemblance\n  for(i in 1:n) {\n    y[i] ~ dnorm(beta0 + beta1 * x[i], sd = sigma) # equiv de yi = beta0 + beta1 * xi + epsiloni\n  }\n})\n\n# Code du modèle sans covariable\nmodel_sans <- nimbleCode({\n  # les priors\n  beta0 ~ dnorm(0, sd = 1.5) # prior normal sur l'intercept\n  sigma ~ dexp(1) # prior exponentiel sur l'écart-type\n  # la vraisemblance\n  for(i in 1:n) {\n    y[i] ~ dnorm(beta0, sd = sigma) # equiv de yi = beta0 + beta1 * xi + epsiloni\n  }\n})\n\n# Données, valeurs initiales\ndat <- list(x = x, y = y, n = n) # données\ninits_avec <- list(list(beta0 = -0.5, beta1 = -0.5, sigma = 0.1), # valeurs initiales chaine 1\n                   list(beta0 = 0, beta1 = 0, sigma = 1), # valeurs initiales chaine 2\n                   list(beta0 = 0.5, beta1 = 0.5, sigma = 0.5)) # valeurs initiales chaine 3\ninits_sans <- list(list(beta0 = -0.5, sigma = 0.1), # valeurs initiales chaine 1\n                   list(beta0 = 0, sigma = 1), # valeurs initiales chaine 2\n                   list(beta0 = 0.5, sigma = 0.5)) # valeurs initiales chaine 3\n\n# Modèle avec covariable\nlm.avec <- nimbleMCMC(\n  code = model_avec,\n  data = dat,\n  inits = inits_avec,\n  niter = 2000,\n  nburnin = 1000,\n  nchains = 3,\n  WAIC = TRUE)\n#> |-------------|-------------|-------------|-------------|\n#> |-------------------------------------------------------|\n#> |-------------|-------------|-------------|-------------|\n#> |-------------------------------------------------------|\n#> |-------------|-------------|-------------|-------------|\n#> |-------------------------------------------------------|\n\n# Modèle sans covariable\nlm.sans <- nimbleMCMC(\n  code = model_sans,\n  data = dat,\n  inits = inits_sans,\n  niter = 2000,\n  nburnin = 1000,\n  nchains = 3,\n  WAIC = TRUE)\n#> |-------------|-------------|-------------|-------------|\n#> |-------------------------------------------------------|\n#> |-------------|-------------|-------------|-------------|\n#> |-------------------------------------------------------|\n#> |-------------|-------------|-------------|-------------|\n#> |-------------------------------------------------------|\n#>   [Warning] There are 1 individual pWAIC values that are greater than 0.4. This may indicate that the WAIC estimate is unstable (Vehtari et al., 2017), at least in cases without grouping of data nodes or multivariate data nodes.\n\n# Calcul du WAIC pour chaque modèle\nlm.avec$WAIC$WAIC\n#> [1] 172.4424\nlm.sans$WAIC$WAIC\n#> [1] 333.3443"},{"path":"lms.html","id":"en-résumé","chapter":"5 La régression","heading":"5.5 En résumé","text":"La régression linéaire permet de modéliser la relation entre une variable réponse continue et une ou plusieurs variables explicatives, en tenant compte d’une variabilité résiduelle.La régression linéaire permet de modéliser la relation entre une variable réponse continue et une ou plusieurs variables explicatives, en tenant compte d’une variabilité résiduelle.Simuler des données à partir d’un modèle est un excellent moyen de comprendre son fonctionnement et de tester son code.Simuler des données à partir d’un modèle est un excellent moyen de comprendre son fonctionnement et de tester son code.Les lois priori faiblement informatives (comme \\(N(0, 1.5)\\) pour les coefficients ou \\(\\text{Exp}(1)\\) pour \\(\\sigma\\)) aident à encadrer les valeurs réalistes tout en laissant au modèle la liberté d’apprendre des données.Les lois priori faiblement informatives (comme \\(N(0, 1.5)\\) pour les coefficients ou \\(\\text{Exp}(1)\\) pour \\(\\sigma\\)) aident à encadrer les valeurs réalistes tout en laissant au modèle la liberté d’apprendre des données.La validation et la comparaison des modèles peuvent se faire à l’aide de posterior predictive checks et de critères comme le WAIC. Ces outils permettent d’évaluer la qualité du modèle au regard des données, et d’arbitrer entre plusieurs modèles concurrents.La validation et la comparaison des modèles peuvent se faire à l’aide de posterior predictive checks et de critères comme le WAIC. Ces outils permettent d’évaluer la qualité du modèle au regard des données, et d’arbitrer entre plusieurs modèles concurrents.","code":""},{"path":"glms.html","id":"glms","chapter":"6 Modèles linéaires généralisés, et généralisés mixtes","heading":"6 Modèles linéaires généralisés, et généralisés mixtes","text":"","code":""},{"path":"glms.html","id":"introduction-6","chapter":"6 Modèles linéaires généralisés, et généralisés mixtes","heading":"6.1 Introduction","text":"Ce chapitre présente l’application de la statistique bayésienne à des extensions du modèle linéaire vu au chapitre précédent, les modèles linéaires généralisés (GLM) et les modèles linéaires généralisés mixtes (GLMM). commencera par un GLM qui nous permettra de revisiter notre exemple fil rouge sur la survie des ragondins et les données binaires. Nous utiliserons ensuite un GLMM pour analyser des données de comptage. Nous utiliserons ensuite un GLMM pour analyser des données de comptage. Nous utiliserons NIMBLE et brms et comparerons avec l’approche fréquentiste.","code":""},{"path":"glms.html","id":"modèles-linéaires-généralisés-glms","chapter":"6 Modèles linéaires généralisés, et généralisés mixtes","heading":"6.2 Modèles linéaires généralisés (GLMs)","text":"Dans le Chapitre 5, introduit la régression linéaire \\(y_i \\sim N(\\mu_i,\\sigma^2)\\) avec \\(\\mu_i = \\beta_0 + \\beta_1 x_i\\) où modélise la moyenne \\(\\mu\\) de la variable réponse \\(y\\) en fonction d’une variable explicative \\(x\\). Ce modèle dit linéaire est bien adapté à une variable réponse continue. Mais que se passe-t-il lorsque la variable réponse est discrète ? Revenons à notre exemple sur le ragondin dans lequel étudie le nombre d’animaux qui survivent. Si l’applique la régression linéaire sur ces données, va obtenir un nombre décimal de ragondins, ce qui est un peu embêtant pour un effectif par définition discret. De plus, si l’introduit une variable explicative \\(x_i\\) comme la masse pour expliquer les variations dans le nombre de ragondins qui survivent, peut se retrouver avec une probabilité de survie négative, ou plus grande que un. Pourquoi ? Et bien car rien n’oblige le modèle linéaire à ne considérer que des valeurs positives et plus petites que un.vu au Chapitre 1 la solution. note \\(z_i = 1\\) quand le ragondin \\(\\) survécu, et \\(z_i = 0\\) sinon, et suppose que l’événement de survie est comme une expérience de pile ou face avec une probabilité \\(\\theta\\), autrement dit chaque \\(z_i\\) suit une Bernoulli de paramètre \\(\\theta\\). Si l’suppose que les individus sont indépendants et la même distribution, alors le nombre total de ragondins qui survivent à l’hiver \\(\\displaystyle\\sum_{=1}^n{z_i} = y\\) suit une binomiale \\(y \\sim \\text{Bin}(n, \\theta)\\) avec \\(\\theta\\) la probabilité de survie.aussi vu aux Chapitres 2 et 3 qu’pouvait utiliser la fonction logit pour forcer un paramètre à être bien estimé entre 0 et 1. Il s’agit d’écrire que \\(\\text{logit}(\\theta_i) = \\beta_0 + \\beta_1 x_i\\), comme expliqué dans la Figure 6.1.\nFigure 6.1: À gauche : la fonction logit transforme une probabilité p en une valeur continue non bornée logit(p) qui vit entre moins l’infini et plus l’infini. À droite : la fonction logit inverse transforme une combinaison linéaire de prédicteurs (valeur linéaire sur la figure) en probabilité qui vit entre 0 et 1. La fonction logit est utilisée dans la régression logistique (GLM avec distribution binomiale) pour transformer une probabilité (entre 0 et 1) en une variable continue définie sur l’ensemble des réels. Puis, la fonction logit inverse permet ensuite de revenir à l’échelle des probabilités.\nPour formaliser un peu, :\n\\[\\begin{align}\nz_i &\\sim \\text{Bernoulli}(\\theta_i) &\\text{[vraisemblance]}\\\\\n\\text{logit}(\\theta_i) &= \\beta_0 + \\beta_1 \\; x_i &\\text{[relation linéaire]}\\\\\n\\theta_i &= \\text{logit}^{-1}(\\beta_0 + \\beta_1 \\; x_i) = \\dfrac {e^{\\beta_0 + \\beta_1 \\; x_i}} {1+e^{\\beta_0 + \\beta_1 \\; x_i}} &\\text{[relation transformée]}\\\\\n  \\beta_0, \\beta_1 &\\sim \\text{Normale}(0, 1.5) &\\text{[prior sur les paramètres]} \\\\\n\\end{align}\\]Pour illustrer tout ça, peut reprendre les données ragondins auxquelles ajoute des données de masse des individus, et pour ce faire, recrée les données brutes, c’est-à-dire les \\(z_i\\) :peut maintenant ajuster les deux modèles avec brms par exemple (obtiendrait la même chose avec NIMBLE), la régression linéaire et la régression logistique :Au passage, l’interprétation des coefficients de la régression logistique n’est pas facile. introduit souvent la notion de rapport des chances pour y aider, mais personnellement, ça ne parle pas plus que ça. Je reviens toujours à une représentation graphique de la relation entre la probabilité de succès (la survie ici) et les variables explicatives (la masse ici), comme dans la Figure 6.3. observe ici une tendance positive, mais elle est due uniquement au hasard de la simulation (puisque les données ont été générées sans effet de la masse). Une autre façon intuitive de s’en sortir est d’utiliser la règle du 4 proposée par Andrew Gelman et ses collègues. L’astuce consiste à diviser la pente de la régression logistique par 4. Cela donne une estimation approximative du changement de probabilité attendu pour une variation d’une unité de la variable explicative, au point où la courbe est la plus pentue. Si la pente est estimée à 0.23 par exemple, alors la pente maximale de la courbe logistique (autour du point d’inflexion, là où elle change de forme) est approximativement de 0.23/4 = 0.06. Cela signifie qu’une augmentation d’une unité de la variable explicative (ici, la masse du ragondin augmente de 1kg) augmente la probabilité de survie d’environ 6% au point où la pente est la plus forte (passe d’une probabilité de survie de 0.5 à 0.53), comme illustré dans la Figure 6.2 :\nFigure 6.2: Illustration de la règle du 4 de Gelman. Ici, approxime l’effet de la masse du ragondin sur la probabilité de survie (la courbe logistique en noir) autour du point d’inflexion par une droite dont la pente est donnée par le coefficient estimé divisé par 4 (la droite en tirets rouge).\nMais je m’égare, revenons au problème de la régression linéaire appliquée à des données binaires. Comme peut le voir dans la Figure 6.3, la régression linéaire consiste à faire passer une droite sans borne dans les données binaires, ce qui peut conduire à des survies plus grandes que 1 (et/ou plus petites que 0 même si ça n’est pas le cas ici). La régression logistique, en revanche, contraint naturellement les prédictions entre 0 et 1 grâce à la transformation logit, ce qui en fait un choix adapté aux variables de type succès/échec. Au passage, j’ai utilisé la formulation Bernoulli pour introduire une variable explicative mesurée à l’échelle de l’individu, mais si ça n’est pas nécessaire, peut repasser à la formulation groupée avec la binomiale comme dans les chapitres précédents.\nFigure 6.3: Comparaison entre une régression linéaire et une régression logistique ajustées sur des données binaires. La régression linéaire (en bleu) produit des prédictions plus grandes que 1 (embêtant pour une probabilité de survie), tandis que la régression logistique (en rouge) garantit une estimation de probabilité valide.\n","code":"\n# Nombre total de ragondins suivis, survivants\nn <- 57\ny <- 19\n\n# Créer les données individuelles (0 = mort, 1 = vivant)\nz <- c(rep(1, y), rep(0, n - y))\n\n# Ajouter une covariable continue (ex : masse)\nset.seed(123)\nmasse <- rnorm(n, mean = 5, sd = 1)  # masse simulée en kg\n\ndf_bern <- data.frame(survie = z, masse = masse)\n# Ajustement de la régression linéaire\nfit_lm <- brm(survie ~ masse, \n              data = df_bern, \n              family = gaussian())\n\n# Ajustement de la régression logistique\nfit_logit <- brm(survie ~ masse, \n                 data = df_bern, \n                 family = bernoulli())"},{"path":"glms.html","id":"modèles-linéaires-généralisés-mixtes-glmms","chapter":"6 Modèles linéaires généralisés, et généralisés mixtes","heading":"6.3 Modèles linéaires généralisés mixtes (GLMMs)","text":"","code":""},{"path":"glms.html","id":"introduction-7","chapter":"6 Modèles linéaires généralisés, et généralisés mixtes","heading":"6.3.1 Introduction","text":"Souvent, les données sont récoltées ou mesurées avec une certaine structure, elles sont hiérarchisées ou groupées, par exemple la relation entre la survie de ragondins et leur masse dans différentes populations de différents bassins-versants. Il est alors pertinent de modéliser cette structure dans les données. Cela permet de mieux expliquer la variabilité dans la survie moyenne qui n’est pas expliquée par la masse, et donc d’obtenir de meilleures estimations. Pour ce faire, introduit les modèles linéaires généralisés mixtes (GLMM) qui combinent des effets fixes comme dans les GLM, représentant l’effet moyen d’une variable explicative (la masse dans l’exemple des ragondins), et des effets aléatoires représentant la variabilité entre groupes ou niveaux hiérarchiques.Qu’est-ce qu’un effet aléatoire ? Un effet est aléatoire lorsqu’il représente une sélection aléatoire d’unités dans une population plus vaste, par exemple des sites d’échantillonnage ou des individus ; si l’devait refaire l’expérience, peu importe les sites ou les individus, l’important est de pouvoir généraliser l’interprétation des effets. En ce sens, le sexe des ragondins par exemple ne peut pas être considéré comme un effet aléatoire ; si refait l’expérience, la variable sexe toujours les deux mêmes modalités mâle et femelle. Au contraire, considérer les sites d’une aire d’étude de nos ragondins comme un effet fixe permet seulement de dire des choses sur ces sites précis, sans possibilité de généraliser à la « population » de sites, ou à l’aire d’étude.Au passage, vous verrez les termes modèles hiérarchiques, multi-niveaux ou à effets aléatoires utilisés pour désigner un GLMM dans la littérature scientifique. Parfois il s’agit de la même chose, parfois il s’agit de GLMM un peu modifiés. Pour éviter les confusions, souvenez-vous que les GLMM sont utilisés pour analyser des données qui viennent avec une structure en groupes.","code":""},{"path":"glms.html","id":"exemple","chapter":"6 Modèles linéaires généralisés, et généralisés mixtes","heading":"6.3.2 Exemple","text":"Pour illustrer concrètement un GLMM, imaginez la situation où l’cherche à estimer l’abondance de ragondins dans le bassin-versant du Lez, à Montpellier, où le Lez est un fleuve qui traverse la ville. répartit dix transects sur la zone d’étude. Sur chaque transect, compte le nombre de ragondins présents à dix points espacés régulièrement. s’intéresse à la réponse du nombre de ragondins (comptages) en fonction de la température. Les mesures sont bien hiérarchisées, fait 1 mesure du nombre de ragondins sur chacun des 10 points que contient chacun des 10 transects. Le protocole est illustré dans la Figure 6.4 et s’inspire du livre de mon collègue Jason Matthiopoulos (Matthiopoulos 2011).\nFigure 6.4: Schéma des données sur les ragondins selon un protocole d’échantillonnage avec 10 points dans 10 transects. L’aire d’étude est en noir. En haut le nombre de ragondins, et en bas la température.\npartir de ce protocole, simulons des données avec le script suivant. va corser le tout en supposant que sur nos dix transects, eu des soucis d’échantillonnage sur trois d’entre eux pour lesquels n’pu faire que deux ou trois points :\nFigure 6.5: Relation entre le nombre de ragondins et la température par transect, avec plusieurs points de comptage (10 pour tous, sauf les transects 4, 5 et 8 pour lesquels 3, 2 et 3 points) par transect.\n","code":"\nset.seed(123) # pour la reproductibilité\ntransects <- 10 # nombre total de transects\nnb_points <- c(10, 10, 10, 3, 2, 10, 10, 3, 10, 10) # nombre de points par transect\ndata <- NULL # objet qui stockera les données simulées\nfor (tr in 1:transects){\n  ref <- rnorm(1, 0, .3) # effet aléatoire du transect (N(0,0.3²))\n  # température simulée le long du transect :\n  # point de départ aléatoire entre 18 et 22 °C puis légère pente par segment\n  t <- runif(1, 18, 22) + runif(1, -0.2, 0.2) * 1:10\n  # intensité attendue (échelle log) : relation linéaire avec la température\n  ans <- exp(ref + 0.2 * t)\n  # comptage Poisson de ragondins pour chaque point\n  an <- rpois(nb_points[tr], ans)\n  # empile les 10 points du transect courant\n  data <- rbind(data, cbind(rep(tr, nb_points[tr]), t[1:nb_points[tr]], an))\n}\n# on met tout dans un data.frame\nsim_simple <- data.frame(\n  Transect    = data[, 1],\n  Temperature = data[, 2],\n  Ragondins    = data[, 3]\n)\nhead(sim_simple)\n#>   Transect Temperature Ragondins\n#> 1        1    19.78911        54\n#> 2        1    19.94232        46\n#> 3        1    20.09553        47\n#> 4        1    20.24874        60\n#> 5        1    20.40194        53\n#> 6        1    20.55515        42"},{"path":"glms.html","id":"lapproche-glm","chapter":"6 Modèles linéaires généralisés, et généralisés mixtes","heading":"6.3.3 L’approche GLM","text":"souhaite analyser ces données. n’pas à faire à des données binaires ici comme dans le début de ce chapitre, mais des données de comptage. Pour modéliser ce type de données, utilise une distribution de Poisson avec une fonction de lien logarithmique \\(\\log(\\theta_i) = \\beta_0 + \\beta_1 \\text{temp}_{}\\) où \\(\\text{temp}_{}\\) est la température :\\[\\begin{align}\n   \\text{y}_i &\\sim \\text{Poisson(}\\theta_i) &\\text{[vraisemblance]}\\\\\n  \\text{log}(\\theta_i) &= \\beta_{0} + \\beta_1 \\; \\text{temp}_{} &\\text{[relation linéaire]} \\\\\n  \\theta_i &= e^{\\beta_0 + \\beta_1 \\; \\text{temp}_{}} &\\text{[relation transformée]} \\\\\n  \\beta_0, \\beta_1 &\\sim \\text{Normale}(0, 1.5) &\\text{[prior sur les paramètres]} \\\\\n\\end{align}\\]Cette distribution est relativement facile à manipuler, puisqu’entre autres, elle un seul paramètre \\(\\theta\\) qui donne le taux d’apparition de l’événement modélisé, et qu’en moyenne, le nombre attendu de ragondins ici devrait être égal à ce paramètre.Dans ce GLM avec distribution de Poisson, les coefficients \\(\\beta_0\\) et \\(\\beta_1\\) s’interprètent sur l’échelle logarithmique. Plus précisément, une variation d’une unité de température entraîne une multiplication du nombre moyen de ragondins par \\(\\exp(\\beta_1)\\). Par exemple, si \\(\\beta_1 = 0.3\\), alors une augmentation d’un degré correspond à une hausse attendue d’environ \\(35\\%\\) du nombre moyen de ragondins, puisque \\(\\exp(0.3) \\approx 1.35\\). peut aussi visualiser graphiquement la relation entre le nombre de ragondins et la température, comme dans les Figures 6.8 et 6.10 à venir.Dans un premier modèle, oublions la structure en groupes/niveaux dans les données, ici les transects. fait passer une seule droite dans le nuage de points, c’est le modèle avec “complete pooling” ou regroupement complet :Les résultats sont les suivants :\nFigure 6.6: Vérification de l’adéquation du modèle avec complete pooling ou regroupement complet. L’axe des abscisses représente les valeurs possibles de la variable réponse simulée ou observée. L’axe des ordonnées indique leur densité estimée. Les distributions simulées (en bleu) sont comparées aux données observées (en noir). Le mauvais recouvrement indique une mauvaise adéquation du modèle aux données.\nPour prendre en compte la structuration des données, peut ajuster un autre modèle dans lequel le transect est traité comme un effet fixe. Autrement dit, ajuste une droite séparée pour chaque transect, avec son propre intercept, mais avec la même pente :Les résultats sont les suivants :Ici j’ai indiqué à brms de considérer le transect comme une variable catégorielle, un facteur, c’est le .factor(Transect) dans l’appel à la fonction brm(). Par défaut, le premier niveau du facteur (ici le transect 1) est utilisé comme niveau de référence. Cela signifie que l’intercept \\(\\beta_0\\) estimé dans le modèle correspond au transect 1, et que les coefficients associés aux autres transects représentent les écarts (sur l’échelle log) par rapport à ce transect 1. Par exemple, estime \\(\\beta_0\\) à 3.9, c’est l’intercept pour le transect 1. estime aussi le décalage entre le transect 1 et le transect 2 à 0.04. Alors l’intercept pour le transect 2 est donné par 3.94. Ce calcul peut être répété pour chaque transect pour obtenir les intercepts spécifiques, que l’peut ensuite transformer via l’exponentielle pour retrouver le nombre moyen attendu de ragondins (sur l’échelle d’origine) pour une température moyenne (qui vaut 0 ici puisqu’standardisé la variable température) :estime bien un intercept pour chaque transect, donc 10 intercepts, et la pente, c’est-à-dire l’effet de la température, est la même pour tous les transects. Notez aussi que les valeurs obtenues Nombre ici sont des moyennes attendues issues du modèle de Poisson. Ce sont donc des valeurs continues, décimales, bien que les données observées soient des comptages entiers. C’est une caractéristique des modèles de Poisson : la variable à prédire est discrète, mais le modèle s’appuie sur une moyenne continue pour modéliser sa distribution.\nFigure 6.7: Vérification de l’adéquation du modèle avec pooling ou pas de regroupement. L’axe des abscisses représente les valeurs possibles de la variable réponse simulée ou observée. L’axe des ordonnées indique leur densité estimée. Les distributions simulées (en bleu) sont comparées aux données observées (en noir).\nCe modèle “pooling” fait mieux que le modèle “complete pooling”, comme peut le voir dans la Figure 6.8, mais il reste insatisfaisant. L’approche “pooling” consiste à ajuster un modèle indépendant pour chaque transect, sans partager d’information entre ces groupes. Cela pose deux problèmes : d’une part, ne peut pas généraliser les résultats obtenus à d’autres transects que ceux observés ; d’autre part, ignore des informations potentiellement utiles en supposant que chaque transect n’rien à apprendre des autres. Cette stratégie devient particulièrement inefficace lorsque chaque groupe comporte peu d’observations.\nFigure 6.8: Comparaison entre les modèles complete pooling (noir) et pooling (rouge) pour prédire le nombre de ragondins en fonction de la température, par transect. Le modèle pooling ajuste une courbe indépendante pour chaque transect, tandis que le complete pooling suppose une relation commune.\n","code":"\n# on n'oublie pas de standardiser la covariable température\nsim_simple$Temp <- scale(sim_simple$Temperature)\n\n# modèle avec complete pooling \nfit_complete <- brm(Ragondins ~ Temp,\n                    data = sim_simple, # données simulées\n                    family = poisson(\"log\")) # distribution de Poisson, lien log\nsummary(fit_complete)\n#>  Family: poisson \n#>   Links: mu = log \n#> Formula: Ragondins ~ Temp \n#>    Data: sim_simple (Number of observations: 78) \n#>   Draws: 2 chains, each with iter = 5000; warmup = 1000; thin = 1;\n#>          total post-warmup draws = 8000\n#> \n#> Regression Coefficients:\n#>           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> Intercept     4.13      0.01     4.11     4.16 1.00     5374     5177\n#> Temp          0.10      0.01     0.07     0.13 1.00     5936     5368\n#> \n#> Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n#> and Tail_ESS are effective sample size measures, and Rhat is the potential\n#> scale reduction factor on split chains (at convergence, Rhat = 1).\n# modèle avec no pooling / pas de regroupement (effet fixe transect)\nfit_nopool <- brm(Ragondins ~ Temp + as.factor(Transect),\n                    data = sim_simple, # données simulées\n                    family = poisson(\"log\")) # distribution de Poisson, lien log\nsummary(fit_nopool)\n#>  Family: poisson \n#>   Links: mu = log \n#> Formula: Ragondins ~ Temp + as.factor(Transect) \n#>    Data: sim_simple (Number of observations: 78) \n#>   Draws: 2 chains, each with iter = 5000; warmup = 1000; thin = 1;\n#>          total post-warmup draws = 8000\n#> \n#> Regression Coefficients:\n#>                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> Intercept               3.90      0.05     3.81     3.99 1.00     3659     4650\n#> Temp                    0.20      0.06     0.08     0.32 1.00     2684     3611\n#> as.factorTransect2      0.04      0.12    -0.21     0.28 1.00     3001     3973\n#> as.factorTransect3     -0.12      0.07    -0.26     0.03 1.00     4207     5527\n#> as.factorTransect4      0.05      0.11    -0.16     0.26 1.00     3737     4859\n#> as.factorTransect5      0.09      0.10    -0.12     0.29 1.00     5687     5484\n#> as.factorTransect6      0.49      0.10     0.29     0.68 1.00     3009     4224\n#> as.factorTransect7      0.19      0.09     0.02     0.37 1.00     3322     4124\n#> as.factorTransect8      0.08      0.09    -0.09     0.26 1.00     5512     5480\n#> as.factorTransect9      0.28      0.08     0.13     0.43 1.00     3452     4601\n#> as.factorTransect10     0.64      0.06     0.53     0.77 1.00     3729     4715\n#> \n#> Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n#> and Tail_ESS are effective sample size measures, and Rhat is the potential\n#> scale reduction factor on split chains (at convergence, Rhat = 1).\n# extraire l'intercept (référence = Transect 1)\nbeta0 <- fixef(fit_nopool)[\"Intercept\", \"Estimate\"]\n\n# tous les coefficients du modèle\ncoefs <- fixef(fit_nopool)\n\n# effets associés aux autres transects\ncoefs_transects <- coefs[grep(\"as.factor\", rownames(coefs)), \"Estimate\"]\n\n# calcul des intercepts par transect\nintercepts_log <- c(\n  Transect1 = beta0,\n  beta0 + coefs_transects\n)\n\n# calcul des nombres moyens attendus de ragondins sur l’échelle d’origine\nnombres <- exp(intercepts_log)\n\n# le tableau qui résume\ndf_intercepts <- data.frame(\n  Transect = names(intercepts_log),\n  Intercept_log = round(intercepts_log, 2),\n  Nombre = round(nombres, 2)\n)\n\n# affichage\ndf_intercepts\n#>                                Transect Intercept_log Nombre\n#> Transect1                     Transect1          3.90  49.60\n#> as.factorTransect2   as.factorTransect2          3.94  51.48\n#> as.factorTransect3   as.factorTransect3          3.79  44.15\n#> as.factorTransect4   as.factorTransect4          3.95  51.94\n#> as.factorTransect5   as.factorTransect5          3.99  54.02\n#> as.factorTransect6   as.factorTransect6          4.39  80.75\n#> as.factorTransect7   as.factorTransect7          4.10  60.22\n#> as.factorTransect8   as.factorTransect8          3.98  53.74\n#> as.factorTransect9   as.factorTransect9          4.19  65.76\n#> as.factorTransect10 as.factorTransect10          4.55  94.53"},{"path":"glms.html","id":"lapproche-glmm","chapter":"6 Modèles linéaires généralisés, et généralisés mixtes","heading":"6.3.4 L’approche GLMM","text":"Revenons à notre objectif : évaluer l’effet de la température sur l’abondance des ragondins, tout en prenant en compte la structure hiérarchique des données (segments imbriqués dans des transects). Jusqu’ici, les modèles complete pooling et pooling représentaient deux extrêmes : soit supposait que tous les transects partageaient exactement la même relation température–abondance, soit estimait une relation totalement indépendante pour chacun d’eux (via un intercept spécifique à chaque transect). Les modèles linéaires généralisés mixtes (GLMM), ou partial pooling, permettent un compromis plus réaliste.construit un GLMM dans lequel autorise chaque transect à avoir un intercept propre - c’est-à-dire une abondance moyenne spécifique - mais suppose que ces intercepts ne sont pas totalement indépendants. les considère plutôt comme des variations aléatoires autour d’un intercept moyen \\(\\beta_0\\), issues d’une même distribution normale. Cela revient à dire que nos transects \\(\\beta_{0j}\\) (où \\(j\\) varie de 1 à 10) sont tirés d’une population plus large de transects possibles, dans laquelle l’abondance moyenne varie d’un transect à l’autre. modélise cette variabilité spatiale à l’aide d’un effet aléatoire, noté ici \\(\\beta_{0j} \\sim N(\\beta_0,\\sigma)\\), où \\(\\sigma\\) est la variation entre transects.Autrement dit, chaque intercept par transect \\(\\beta_{0j}\\) peut s’écrire comme une déviation \\(b_j\\) autour de l’intercept global \\(\\beta_{0j} = \\beta_0 + b_j\\) avec \\(b_{j} \\sim N(0,\\sigma)\\) où \\(\\beta_0\\) représente l’intercept moyen (pour un transect “typique”) et \\(\\sigma\\) quantifie la variabilité entre transects. Par exemple, si l’intercept moyen est \\(\\beta_0 = 2\\), mais que le transect 4 un intercept de \\(\\beta_{04} = 3\\), dira que cet effet spécifique \\(b_4 = 1\\) correspond à une abondance plus élevée que la moyenne.Cette modélisation hiérarchique permet de capturer l’hétérogénéité spatiale tout en partageant l’information entre groupes, ce qui est particulièrement utile lorsque certains transects comportent peu d’observations. peut aussi voir le modèle partial pooling (3 paramètres estimés dans l’exemple ragondin : \\(\\beta_0, \\beta_1, \\sigma\\)) comme un compromis entre le modèle complete pooling (2 paramètres estimés dans l’exemple ragondin : \\(\\beta_0, \\beta_1\\)) et le modèle pooling (11 paramètres estimés dans l’exemple ragondin : 10 intercept et 1 pente \\(\\beta_1\\)).Si formalise un peu ça, le GLMM correspondant s’écrit :\\[\\begin{align}\n   \\text{y}_i &\\sim \\text{Poisson(}\\theta_i) &\\text{[vraisemblance]}\\\\\n  \\text{log}(\\theta_i) &= \\beta_{0j} + \\beta_1 \\; \\text{temp}_{} &\\text{[relation linéaire]} \\\\\n  \\beta_{0j} &\\sim \\text{Normale}(\\beta_0, \\sigma) &\\text{[effet aléatoire]} \\\\\n  \\beta_0 &\\sim \\text{Normale}(0, 1.5) &\\text{[prior sur l'intercept moyen]} \\\\\n  \\sigma &\\sim \\text{Exp}(1) &\\text{[prior pour l'erreur standard de l'effet aléatoire]} \\\\\n  \\beta_1 &\\sim \\text{Normale}(0, 1.5) &\\text{[prior pour la pente]} \\\\\n\\end{align}\\]","code":""},{"path":"glms.html","id":"ajustement-du-modèle-avec-brms","chapter":"6 Modèles linéaires généralisés, et généralisés mixtes","heading":"6.3.4.1 Ajustement du modèle avec brms","text":"ajuste d’abord le GLMM avec partial pooling avec brms :Dans la syntaxe, l’effet aléatoire sur l’intercept est spécifié avec (1 | Transect), où le 1 signifie qu’travaille sur l’intercept, et qu’il y un intercept par (c’est le |) transect. Si voulait ajouter un effet aléatoire sur la pente, écrirait (1 + Temp | Transect).Les résultats sont :Ce résumé fournit les estimations posteriori des effets fixes ainsi que des écarts-types des effets aléatoires. La ligne sd(Intercept) donne l’estimation de \\(\\sigma\\), proche du 0.3 utilisé pour simuler les données (l’intervalle de crédibilité contient la vraie valeur). Les lignes Intercept et Temp donnent les estimations de \\(\\beta_0\\) et \\(\\beta_1\\) sur l’échelle log. verra un peu plus tard comment vérifier que ces estimations sont proches des valeurs utilisées pour simuler les données.peut aussi jeter un coup d’oeil aux densités et traces des paramètres (Figure 6.9) :\nFigure 6.9: Vérification de la convergence des chaînes MCMC pour le modèle avec partial pooling. Dans les histogrammes (colonne de gauche), l’axe des abscisses représente les valeurs possibles du paramètre estimé (intercept, pente ou écart-type) et l’axe des ordonnées correspond à leur fréquence dans l’échantillon posteriori. Dans les trace plots (colonne de droite), l’axe des abscisses indique le numéro d’itération du MCMC, tandis que l’axe des ordonnées représente la valeur simulée du paramètre à chaque itération.\n\nFigure 6.10: Comparaison entre les modèles complete pooling (noir), pooling (rouge) et partial pooling (bleu) pour prédire le nombre de ragondins en fonction de la température, par transect. Le modèle pooling ajuste une courbe indépendante pour chaque transect, le complete pooling suppose une relation commune, tandis que le partial pooling fournit un compromis grâce à l’effet aléatoire transect.\nvoit que l’ajustement fourni par le partial pooling est très similaire au pooling, et bien meilleur que le complete pooling. Il y une petite différence pour les transects avec peu de points d’échantillonnage, les transects 4, 5 et 8, pour lesquels le partial pooling se rapproche du complete pooling. En l’absence de plus d’information (de données) pour ces transects, il est plutôt raisonnable que les estimations se rapprochent de la moyenne donnée par le modèle avec complete pooling plutôt que vers des valeurs extrêmes, atypiques. Rappelez-vous que dans un GLMM, les niveaux de l’effet aléatoire sont caractéristiques d’une population avec une moyenne commune. C’est ce partage d’information entre les transects avec 10 points d’échantillonnage et ceux avec 2 ou 3 points, parle de “borrowing strength” qui permet d’atténuer, de tamponner, parle de “shrinkage”, la tendance à sur-ajuster du modèle avec pooling ou à effet fixe, et en ce sens parle parfois de “regularization”.\nFigure 6.11: Vérification de l’adéquation du modèle avec partial pooling ou regroupement partiel. L’axe des abscisses représente les valeurs possibles de la variable réponse simulée ou observée. L’axe des ordonnées indique leur densité estimée. Les distributions simulées (en bleu) sont comparées aux données observées (en noir).\nLorsqu’ajuste un modèle sur une variable standardisée, comme ici la température centrée-réduite, les coefficients estimés (\\(\\beta_0, \\beta_1\\)) s’interprètent sur cette échelle modifiée : \\(\\beta_1\\) représente l’effet d’un écart-type de température, et \\(\\beta_0\\) correspond à la valeur attendue quand la température standardisée est 0, c’est-à-dire à la température moyenne. souvent envie d’exprimer les effets sur des unités compréhensibles, ici les degrés celsius, plutôt qu’en écart-type de température, qui est plus abstrait. Pour revenir à une interprétation sur l’échelle réelle (en degré celsius donc), les coefficients estimés sur la température centrée-réduite peuvent être transformés pour revenir à l’échelle réelle à l’aide des formules suivantes :\\[\n\\beta_1^{\\text{réel}} = \\frac{\\beta_1^{\\text{standardisé}}}{\\text{écart-type de la température}}\n\\]\\[\n\\beta_0^{\\text{réel}} = \\beta_0^{\\text{standardisé}} - \\beta_1^{\\text{standardisé}} \\times \\frac{\\text{moyenne de la température}}{\\text{écart-type de la température}}\n\\]Dans R, vous pouvez utiliser le code suivant :peut alors visualiser les coefficients sur l’échelle originale et comparer à la valeur utilisée pour simuler les données comme dans les Figures 6.12 et 6.13 :\nFigure 6.12: Distribution posteriori de l’intercept moyen (échelle réelle). La ligne rouge indique la vraie valeur (0).\n\nFigure 6.13: Distribution posteriori de l’effet de la température (échelle réelle). La ligne rouge indique la vraie valeur (0.2).\nretrouve les paramètres ayant servi à simuler les données (en rouge). Il ne s’agit que d’une seule simulation, c’est donc normal qu’en moyenne n’obtienne pas exactement la même chose (c’est-à-dire que le trait rouge ne coïncide pas plus à la plus grande valeur de l’histogramme), c’est seulement en répétant l’expérience de simulations un grand nombre de fois que cela se produirait.En bonus, comparons les modèles avec et sans effet de la température. Cela permet de tester la pertinence de la température comme variable explicative :calcule le WAIC pour chaque modèle, et les compare :En conclusion, le modèle incluant la température offre un meilleur ajustement aux données selon le critère WAIC. Et fort heureusement puisqu’simulé selon ce modèle !","code":"\n# modèle avec partial pooling (effet aléatoire transect)\nfit_partial <- brm(Ragondins ~ Temp + (1 | Transect), # relation nombre de ragondins vs température avec effet aléatoire transect sur l'intercept\n                    data = sim_simple, # données simulées\n                    family = poisson(\"log\")) # distribution de Poisson, lien log\nsummary(fit_partial)\n#>  Family: poisson \n#>   Links: mu = log \n#> Formula: Ragondins ~ Temp + (1 | Transect) \n#>    Data: sim_simple (Number of observations: 78) \n#>   Draws: 2 chains, each with iter = 5000; warmup = 1000; thin = 1;\n#>          total post-warmup draws = 8000\n#> \n#> Multilevel Hyperparameters:\n#> ~Transect (Number of levels: 10) \n#>               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> sd(Intercept)     0.27      0.08     0.16     0.47 1.00     2119     3183\n#> \n#> Regression Coefficients:\n#>           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> Intercept     4.09      0.09     3.92     4.27 1.00     2087     2747\n#> Temp          0.17      0.05     0.06     0.27 1.00     3559     4119\n#> \n#> Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n#> and Tail_ESS are effective sample size measures, and Rhat is the potential\n#> scale reduction factor on split chains (at convergence, Rhat = 1).\nplot(fit_partial)\n# on récupère les valeurs simulées dans les distributions a posteriori des paramètres\npost <- as_draws_matrix(fit_partial)\nsbzero <- post[, \"b_Intercept\"]\nsbun <- post[, \"b_Temp\"]\n\n# on récupère moyenne et écart-type de la température\nmu <- attr(scale(sim_simple$Temperature), \"scaled:center\")\nsg <- attr(scale(sim_simple$Temperature), \"scaled:scale\")\n\n# on convertit les coefficients standardisés\nbun   <- sbun / sg # beta1 réel\nbzero <- sbzero - sbun * mu / sg # beta0 réel\ntibble(b0 = bzero) %>%\n  ggplot(aes(x = b0)) +\n  geom_histogram(color = \"white\", fill = \"skyblue\", bins = 30) +\n  geom_vline(xintercept = 0, color = \"red\", linewidth = 1.2) +\n  labs(\n    x = expression(beta[0]),\n    y = \"Fréquence\"\n  ) +\n  theme_minimal()\ntibble(b1 = bun) %>%\n  ggplot(aes(x = b1)) +\n  geom_histogram(color = \"white\", fill = \"skyblue\", bins = 30) +\n  geom_vline(xintercept = 0.2, color = \"red\", linewidth = 1.2) +\n  labs(\n    x = expression(beta[1]),\n    y = \"Fréquence\"\n  ) +\n  theme_minimal()\n# modèle avec partial pooling (effet aléatoire transect)\nfit_partial2 <- brm(Ragondins ~ 1 + (1 | Transect), # un intercept moyen, pas d'effet de la température, avec l'effet aléatoire transect\n                    data = sim_simple, # données simulées\n                    family = poisson(\"log\")) # distribution de Poisson, lien log\nwaic1 <- waic(fit_partial)\nwaic2 <- waic(fit_partial2)\ntibble(\n  Modèle = c(\"Avec température\", \"Sans température\"),\n  WAIC = c(waic1$estimates[\"waic\", \"Estimate\"],\n           waic2$estimates[\"waic\", \"Estimate\"])\n)\n#> # A tibble: 2 × 2\n#>   Modèle            WAIC\n#>   <chr>            <dbl>\n#> 1 Avec température  542.\n#> 2 Sans température  551."},{"path":"glms.html","id":"ajustement-du-modèle-avec-nimble","chapter":"6 Modèles linéaires généralisés, et généralisés mixtes","heading":"6.3.4.2 Ajustement du modèle avec NIMBLE","text":"fait la même analyse avec un GLMM et NIMBLE cette fois-ci. commence par écrire le code :Commentons un peu ce code. écrit la vraisemblance des données count[] avec une loi de Poisson count[] ~ dpois(theta[]) de chacune des 200 mesures (20 points fois 10 transects) dans la boucle (1:n). L’intensité theta[], c’est-à-dire le nombre attendu de ragondins, est liée à deux effets : intercept[transect[]] est l’intercept spécifique au transect auquel appartient l’observation \\(\\) et beta1 * x[] est l’effet linéaire de la température. Le terme intercept[transect[]] illustre ce qu’appelle l’indexation imbriquée (ou “nested indexing”) : pour chaque observation \\(\\), va chercher le bon intercept dans un vecteur d’intercepts (intercept[j]) à l’aide de l’indice transect[]. Le vecteur transect contient, pour chaque observation \\(\\), l’identifiant du transect auquel elle appartient. Par exemple, si l’observation 5 appartient au transect 3, alors transect[5] = 3, et va chercher directement intercept[3], l’intercept spécifique au transect 3. Ce “nested indexing” (ici, points imbriqués dans des transects) évite d’écrire une boucle pour parcourir les transects (et donc d’avoir une double boucle) : chaque observation récupère dynamiquement l’intercept qui lui correspond. Le bloc (j 1:nbtransects){intercept[j] ~ dnorm(beta0, sd = sigma)} précise la structure hiérarchique du modèle : les intercepts spécifiques à chaque transect (intercept[j]) ne sont pas estimés séparément comme dans un modèle classique, mais sont considérés comme des tirages aléatoires autour d’une moyenne globale beta0, avec une variabilité entre transects donnée par sigma.lit les constantes et les données :spécifie les valeurs initiales pour les chaînes MCMC (pour 2 chaînes) :spécifie aussi les paramètres à surveiller, ainsi que les détails en lien avec les chaînes MCMC :Finalement, lance NIMBLE :obtient comme résultats :Comme l’vu avec brms, obtient les coefficients estimés sur la température centrée-réduite, et pour revenir à l’échelle réelle il nous faut utiliser les formules suivantes :\\[\n\\beta_1^{\\text{réel}} = \\frac{\\beta_1^{\\text{standardisé}}}{\\text{écart-type de la température}}\n\\]\\[\n\\beta_0^{\\text{réel}} = \\beta_0^{\\text{standardisé}} - \\beta_1^{\\text{standardisé}} \\times \\frac{\\text{moyenne de la température}}{\\text{écart-type de la température}}\n\\]\nDans R, vous pouvez utiliser le code suivant :peut alors visualiser les coefficients sur l’échelle originale et comparer à la valeur utiliser pour simuler les données comme dans les Figures 6.14 et 6.15 :\nFigure 6.14: Distribution posteriori de l’intercept moyen (échelle réelle). La ligne rouge indique la vraie valeur (0).\n\nFigure 6.15: Distribution posteriori de l’effet de la température (échelle réelle). La ligne rouge indique la vraie valeur (0.2).\nretrouve les paramètres ayant servi à simuler les données (en rouge). Comme avec brms, n’fait qu’une seule simulation, c’est donc normal qu’en moyenne n’obtienne pas exactement la même chose (c’est-à-dire que le trait rouge ne coïncide pas plus à la plus grande valeur de l’histogramme), c’est seulement en répétant l’expérience de simulations un grand nombre de fois que cela se produirait.Comparons les modèles avec et sans température via le WAIC. Il nous faut ajuster le modèle sans la température :Il faut faire tourner à nouveau le modèle avec la température pour calculer le WAIC, en ajoutant WAIC = TRUE dans l’appel à la fonction nimbleMCMC(), je ne montre pas le code ici.Et peut alors comparer :","code":"\nmodel <- nimbleCode({\n  for (i in 1:n){\n    count[i] ~ dpois(theta[i]) # loi de Poisson\n    log(theta[i]) <- intercept[transect[i]] + # intercept aléatoire par transect\n                       beta1 * x[i] # effet linéaire de la température\n  }\n  for (j in 1:nbtransects){\n    intercept[j] ~ dnorm(beta0, sd = sigma) # intercepts ~ N(beta0, sigma)\n  }\n  beta0 ~ dnorm(0, sd = 1.5) # prior sur la moyenne des intercepts\n  sigma ~ dexp(1) # prior non informatif sur l'écart-type\n  beta1 ~ dnorm(0, sd = 1.5) # prior sur le coef linéaire\n})\nmy.constants <- list(\n  n = nrow(sim_simple), # nombre d'observations\n  nbtransects = transects # nombre de transects\n)\nmy.data <- list(\n  x = as.vector(sim_simple$Temp), # covariable standardisée\n  count = sim_simple$Ragondins, # comptages\n  transect = as.numeric(sim_simple$Transect) # identifiant du transect (effet aléatoire)\n)\ninit1 <- list(\n  intercept = rnorm(transects),\n  beta1 = rnorm(1),\n  beta0 = rnorm(1),\n  sigma = rexp(1)\n)\n\ninit2 <- list(\n  intercept = rnorm(transects),\n  beta1 = rnorm(1),\n  beta0 = rnorm(1),\n  sigma = rexp(1)\n)\n\ninitial.values <- list(init1, init2)\nparameters.to.save <- c(\"beta1\", \"beta0\", \"sigma\")\nn.iter <- 5000 # nb itérations totales\nn.burnin <- 1000 # nb itérations burn-in\nn.chains <- 2 # nombre de chaînes\nmcmc.output <- nimbleMCMC(\n  code = model,\n  data = my.data,\n  constants = my.constants,\n  inits = initial.values,\n  monitors = parameters.to.save,\n  niter = n.iter,\n  nburnin = n.burnin,\n  nchains = n.chains,\n  progressBar = FALSE)\nMCMCsummary(object = mcmc.output, round = 2)\n#>       mean   sd 2.5%  50% 97.5% Rhat n.eff\n#> beta0 4.07 0.09 3.88 4.07  4.24 1.00  4587\n#> beta1 0.17 0.05 0.07 0.16  0.28 1.03    77\n#> sigma 0.26 0.08 0.16 0.25  0.46 1.00   856\n# on concatène des 2 chaînes\nsamples <- rbind(mcmc.output$chain1, mcmc.output$chain2)  \n\n# on récupère les valuers simulées dans les distributions a posteriori des paramètres\nsbzero <- samples[, 'beta0'] # beta0 standardisé\nsbun   <- samples[, 'beta1'] # beta1 standardisé\n\n# on récupère moyenne et écart-type de la température\nmu <- attr(scale(sim_simple$Temperature), \"scaled:center\")\nsg <- attr(scale(sim_simple$Temperature), \"scaled:scale\")\n\n# on convertit les coefficients standardisés\nbun   <- sbun / sg # beta1 réel\nbzero <- sbzero - sbun * mu / sg # beta0 réel\ntibble(b0 = bzero) %>%\n  ggplot(aes(x = b0)) +\n  geom_histogram(color = \"white\", fill = \"skyblue\", bins = 30) +\n  geom_vline(xintercept = 0, color = \"red\", linewidth = 1.2) +\n  labs(\n    x = expression(beta[0]),\n    y = \"Fréquence\"\n  ) +\n  theme_minimal()\ntibble(b1 = bun) %>%\n  ggplot(aes(x = b1)) +\n  geom_histogram(color = \"white\", fill = \"skyblue\", bins = 30) +\n  geom_vline(xintercept = 0.2, color = \"red\", linewidth = 1.2) +\n  labs(\n    x = expression(beta[1]),\n    y = \"Fréquence\"\n  ) +\n  theme_minimal()\n# code du modèle sans température\nmodel.null <- nimbleCode({\n  for (i in 1:n){\n    count[i] ~ dpois(theta[i])\n    log(theta[i]) <- intercept[transect[i]]\n  }\n  for (j in 1:nbtransects){\n    intercept[j] ~ dnorm(beta0, sd = sigma)\n  }\n  beta0 ~ dnorm(0, sd = 1.5)\n  sigma ~ dexp(1)\n})\n# exécution du modèle nul\nparameters.null <- c(\"beta0\", \"sigma\")\nmcmc.null <- nimbleMCMC(\n  code = model.null,\n  data = my.data,\n  constants = my.constants,\n  inits = list(beta0 = 0, sigma = 1, intercept = rnorm(transects)),\n  monitors = parameters.null,\n  niter = n.iter,\n  nburnin = n.burnin,\n  nchains = n.chains,\n  progressBar = FALSE,\n  WAIC = TRUE\n)\n#>   [Warning] There are 3 individual pWAIC values that are greater than 0.4. This may indicate that the WAIC estimate is unstable (Vehtari et al., 2017), at least in cases without grouping of data nodes or multivariate data nodes.\n# calcul du WAIC\nwaic.full <- mcmc.output$WAIC$WAIC\nwaic.null <- mcmc.null$WAIC$WAIC\n\n# affichage comparatif\ntibble(\n  Modèle = c(\"Avec température\", \"Sans température\"),\n  WAIC = c(waic.full,\n           waic.null)\n)\n#> # A tibble: 2 × 2\n#>   Modèle            WAIC\n#>   <chr>            <dbl>\n#> 1 Avec température  543.\n#> 2 Sans température  552."},{"path":"glms.html","id":"ajustement-du-modèle-en-fréquentiste-avec-lme4","chapter":"6 Modèles linéaires généralisés, et généralisés mixtes","heading":"6.3.4.3 Ajustement du modèle en fréquentiste avec lme4","text":"Pour clôre ce chapitre, je vous propose de faire la même analyse avec le package lme4 en fréquentiste.charge le dit package :Puis applique le GLMM, notez que la syntaxe de brms est inspirée de celle utilisée dans lme4 :Voici les résultats :Comment lire les sorties ?peut noter que les estimations des paramètres obtenus sont très proches des estimations obtenues avec brms et NIMBLE.","code":"\nlibrary(lme4)\nfit_lme4 <- glmer(\n  Ragondins ~ Temp + (1 | Transect), # formule complète\n  data   = sim_simple,        # jeu de données simulé précédemment\n  family = poisson      # distribution adaptée à un comptage\n)\nsummary(fit_lme4)\n#> Generalized linear mixed model fit by maximum likelihood (Laplace\n#>   Approximation) [glmerMod]\n#>  Family: poisson  ( log )\n#> Formula: Ragondins ~ Temp + (1 | Transect)\n#>    Data: sim_simple\n#> \n#>       AIC       BIC    logLik -2*log(L)  df.resid \n#>     568.3     575.3    -281.1     562.3        75 \n#> \n#> Scaled residuals: \n#>     Min      1Q  Median      3Q     Max \n#> -1.9501 -0.6223 -0.1098  0.4779  2.3897 \n#> \n#> Random effects:\n#>  Groups   Name        Variance Std.Dev.\n#>  Transect (Intercept) 0.04402  0.2098  \n#> Number of obs: 78, groups:  Transect, 10\n#> \n#> Fixed effects:\n#>             Estimate Std. Error z value Pr(>|z|)    \n#> (Intercept)  4.08804    0.06898  59.266  < 2e-16 ***\n#> Temp         0.15797    0.04863   3.248  0.00116 ** \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Correlation of Fixed Effects:\n#>      (Intr)\n#> Temp -0.106"},{"path":"glms.html","id":"en-résumé-1","chapter":"6 Modèles linéaires généralisés, et généralisés mixtes","heading":"6.4 En résumé","text":"Les modèles linéaires généralisés (GLM) permettent d’étendre les modèles linéaires aux situations où l’ne peut pas supposer une erreur normale.Les modèles linéaires généralisés (GLM) permettent d’étendre les modèles linéaires aux situations où l’ne peut pas supposer une erreur normale.L’idée générale est d’utiliser une distribution adaptée à la variable réponse — Bernoulli ou binomiale pour les variables binaires (0/1), Poisson pour les comptages (0, 1, 2, etc.) - et de relier la moyenne de cette distribution aux variables explicatives par une fonction de lien (comme logit ou log).L’idée générale est d’utiliser une distribution adaptée à la variable réponse — Bernoulli ou binomiale pour les variables binaires (0/1), Poisson pour les comptages (0, 1, 2, etc.) - et de relier la moyenne de cette distribution aux variables explicatives par une fonction de lien (comme logit ou log).L’introduction d’effets aléatoires permet de modéliser des groupes hiérarchiques dans les données (e.g., sites, individus, transects), en tenant compte de leur hétérogénéité tout en partageant l’information entre eux.L’introduction d’effets aléatoires permet de modéliser des groupes hiérarchiques dans les données (e.g., sites, individus, transects), en tenant compte de leur hétérogénéité tout en partageant l’information entre eux.Les modèles linéaires généralisés mixtes (GLMM) permettent d’estimer simultanément des effets fixes (valables pour toute la population), et des effets aléatoires (propres à chaque groupe, mais supposés tirés d’une distribution commune).Les modèles linéaires généralisés mixtes (GLMM) permettent d’estimer simultanément des effets fixes (valables pour toute la population), et des effets aléatoires (propres à chaque groupe, mais supposés tirés d’une distribution commune).Dans un modèle à complete pooling, ignore la structure en groupes : suppose que toutes les données suivent exactement la même relation avec les variables explicatives. Cela peut mener à des conclusions biaisées si les groupes diffèrent réellement. Dans un modèle à pooling, estime une relation distincte pour chaque groupe, sans partage d’information. Cela produit des estimations très variables, surtout si certains groupes ont des tailles d’échantillon faibles. Les modèles à partial pooling, ou GLMM, ou modèles hiérarchiques, représentent un compromis entre ces deux extrêmes : les groupes ont leurs propres paramètres, mais ceux-ci sont liés via une distribution commune. Cela permet d’améliorer la stabilité des estimations tout en respectant les différences entre groupes.Dans un modèle à complete pooling, ignore la structure en groupes : suppose que toutes les données suivent exactement la même relation avec les variables explicatives. Cela peut mener à des conclusions biaisées si les groupes diffèrent réellement. Dans un modèle à pooling, estime une relation distincte pour chaque groupe, sans partage d’information. Cela produit des estimations très variables, surtout si certains groupes ont des tailles d’échantillon faibles. Les modèles à partial pooling, ou GLMM, ou modèles hiérarchiques, représentent un compromis entre ces deux extrêmes : les groupes ont leurs propres paramètres, mais ceux-ci sont liés via une distribution commune. Cela permet d’améliorer la stabilité des estimations tout en respectant les différences entre groupes.","code":""},{"path":"conclusions.html","id":"conclusions","chapter":"Conclusions","heading":"Conclusions","text":"","code":""},{"path":"conclusions.html","id":"what-we-covered","chapter":"Conclusions","heading":"What we covered","text":"hope book (least little) demystified Bayesian statistics MCMC methods. also hope given tools understand difference frequentist Bayesian approaches, better read “Methods” section papers using Bayesian statistics, gain certain level autonomy conducting Bayesian analyses.Throughout book, covered several essential steps. began exploring motivations using Bayesian approach. introduced Bayes’ theorem discussed interpretation. discovered Markov chain Monte Carlo (MCMC) methods, worked two powerful tools, NIMBLE brms, fit complex models. Particular attention given role prior distributions, whether non-informative informative, well use approaches case studies involving GLM GLMM.","code":""},{"path":"conclusions.html","id":"bayesian-statistics-in-a-nutshell","chapter":"Conclusions","heading":"Bayesian statistics, in a nutshell","text":"Bayesian approach offers many advantages. allows uncertainty quantified coherently using probability, enables explicit integration prior knowledge, makes possible fit complex models via MCMC. addition, Bayesian credible intervals intuitive frequentist confidence intervals.caution nevertheless required. Checking convergence MCMC chains crucial step, sometimes laborious one. choice prior distributions requires careful consideration. Model fit must always evaluated. Finally, computational cost negligible, especially complex models /large datasets.","code":""},{"path":"conclusions.html","id":"a-few-tips","chapter":"Conclusions","heading":"A few tips","text":"finishing, like leave tips inspired experience. tips necessarily specific Bayesian statistics, worth worth.First, take time clearly formulate question. may seem obvious, step essential stay track make right choices, example deciding use subset data answer specific question.Next, think model first, formalize either equations, drawing , words. nature data, therefore, regression framework, family distributions use saw Chapters 5 (normal) 6 (Bernoulli/binomial Poisson)? rush keyboard. Make sure understand , example explaining colleagues.note, remember run simulations. Simulating data model often helps understand better, Chapters 5 6. excellent way test assumptions diagnose potential issues.Choose R environment comfortable ; illustrated brms NIMBLE (Chapter 2), solutions exist.fitting model, start simple. model parameters constant good baseline. ensures data read formatted correctly, outliers (extra zero, misplaced comma), priors generate unexpected behavior (see Chapter 4). approach particularly important Bayesian statistics ensure good performance convergence MCMC algorithm (Chapter 2), also giving idea time required run analysis. everything looks good, gradually add complexity, random effects example (Chapter 6), reach model structure seems appropriate answer question. likely implies several iterations fitting, comparing, validating models (Chapters 5 6).practical guidance, recommend reading papers “Ten quick tips get started Bayesian statistics” (Gimenez et al. 2025) “Bayesian workflow” (Andrew Gelman et al. 2020).","code":""},{"path":"conclusions.html","id":"to-conclude","chapter":"Conclusions","heading":"To conclude","text":"Adopt pragmatic approach. choice statistical approach (frequentist Bayesian) depends objectives, whether concern speed, model complexity, type uncertainty want quantify. Discuss options experienced colleagues needed. Bayesian statistics dogma: powerful tool among others toolbox.Thank attention. Feel free write questions like see particular aspect developed new edition book. enjoy exploring Bayesian statistics!","code":""},{"path":"références.html","id":"références","chapter":"Références","heading":"Références","text":"","code":""}]
