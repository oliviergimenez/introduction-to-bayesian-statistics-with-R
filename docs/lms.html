<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 5 Regression | Introduction to Bayesian Statistics with R</title>
<meta name="author" content="Olivier Gimenez">
<meta name="description" content="5.1 Introduction This chapter presents the application of Bayesian statistics to linear regression. We will use an example that allows us to go a bit further than our running example on survival....">
<meta name="generator" content="bookdown 0.43 with bs4_book()">
<meta property="og:title" content="Chapter 5 Regression | Introduction to Bayesian Statistics with R">
<meta property="og:type" content="book">
<meta property="og:url" content="https://oliviergimenez.github.io/introduction-to-bayesian-statistics-with-R/lms.html">
<meta property="og:description" content="5.1 Introduction This chapter presents the application of Bayesian statistics to linear regression. We will use an example that allows us to go a bit further than our running example on survival....">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 5 Regression | Introduction to Bayesian Statistics with R">
<meta name="twitter:description" content="5.1 Introduction This chapter presents the application of Bayesian statistics to linear regression. We will use an example that allows us to go a bit further than our running example on survival....">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><link href="libs/Roboto-0.4.10/font.css" rel="stylesheet">
<script src="libs/bs3compat-0.9.0/transition.js"></script><script src="libs/bs3compat-0.9.0/tabs.js"></script><script src="libs/bs3compat-0.9.0/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><!-- Google tag (gtag.js) --><script async src="https://www.googletagmanager.com/gtag/js?id=G-MTKSQWQE5K"></script><script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-MTKSQWQE5K');
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
          margin-bottom: 0em;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
<link rel="stylesheet" href="style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="using NIMBLE and brms">Introduction to Bayesian Statistics with R</a>:
        <small class="text-muted">using NIMBLE and brms</small>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Introduction</a></li>
<li><a class="" href="principles.html"><span class="header-section-number">1</span> The Bayesian approach</a></li>
<li><a class="" href="mcmc.html"><span class="header-section-number">2</span> MCMC methods</a></li>
<li><a class="" href="software.html"><span class="header-section-number">3</span> Practical implementation</a></li>
<li><a class="" href="prior.html"><span class="header-section-number">4</span> Prior distributions</a></li>
<li><a class="active" href="lms.html"><span class="header-section-number">5</span> Regression</a></li>
<li><a class="" href="glms.html"><span class="header-section-number">6</span> Generalized linear models, and generalized linear mixed models</a></li>
<li><a class="" href="conclusions.html">Conclusions</a></li>
<li><a class="" href="r%C3%A9f%C3%A9rences.html">Références</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/oliviergimenez/introduction-to-bayesian-statistics-with-R">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="lms" class="section level1" number="5">
<h1>
<span class="header-section-number">5</span> Regression<a class="anchor" aria-label="anchor" href="#lms"><i class="fas fa-link"></i></a>
</h1>
<div id="introduction-5" class="section level2" number="5.1">
<h2>
<span class="header-section-number">5.1</span> Introduction<a class="anchor" aria-label="anchor" href="#introduction-5"><i class="fas fa-link"></i></a>
</h2>
<p>This chapter presents the application of Bayesian statistics to linear regression. We will use an example that allows us to go a bit further than our running example on survival. This will be an opportunity to discuss how and why to use a model to simulate data. We will also illustrate model comparison and validation. We will use <code>NIMBLE</code> and <code>brms</code> and compare with the frequentist approach.</p>
</div>
<div id="linear-regression" class="section level2" number="5.2">
<h2>
<span class="header-section-number">5.2</span> Linear regression<a class="anchor" aria-label="anchor" href="#linear-regression"><i class="fas fa-link"></i></a>
</h2>
<div id="the-model" class="section level3" number="5.2.1">
<h3>
<span class="header-section-number">5.2.1</span> The model<a class="anchor" aria-label="anchor" href="#the-model"><i class="fas fa-link"></i></a>
</h3>
<p>To change things a bit, I suggest using <code>NIMBLE</code> and <code>brms</code> on an example different from survival estimation. Let us focus on linear regression.</p>
<p>Let us start by laying out the foundations of our linear model. We have <span class="math inline">\(n\)</span> measurements of a response variable <span class="math inline">\(y_i\)</span> with <span class="math inline">\(i\)</span> ranging from 1 to <span class="math inline">\(n\)</span>. Think for example of the mass (in kilograms) of our coypus in the running example. We associate each measurement with an explanatory variable <span class="math inline">\(x_i\)</span>, for example the average outdoor temperature in winter (in degrees Celsius) for our coypus. We want to study the effect of temperature on mass. The simplest assumption is a linear relationship between the two, so we use a linear regression model. The model includes an intercept <span class="math inline">\(\beta_0\)</span>, and a slope <span class="math inline">\(\beta_1\)</span> that describes the effect of <span class="math inline">\(x_i\)</span> on <span class="math inline">\(y_i\)</span>, or of temperature on coypu mass. We also need a parameter to describe residual variability represented by a variance parameter <span class="math inline">\(\sigma^2\)</span>, which captures the part of variation in the <span class="math inline">\(y_i\)</span> not explained by the <span class="math inline">\(x_i\)</span>. You have probably already encountered this model in the form: <span class="math inline">\(y_i = \beta_0 + \beta_1 x_i + \varepsilon_i\)</span> where the errors <span class="math inline">\(\varepsilon_i\)</span> are assumed independent and normally distributed with mean 0 and variance <span class="math inline">\(\sigma^2\)</span>.</p>
<p>The intercept <span class="math inline">\(\beta_0\)</span> gives us the mass when the temperature is 0 degrees (<span class="math inline">\(x_i = 0\)</span>). The parameter <span class="math inline">\(\beta_1\)</span> tells us the change in the response variable for a one‑unit increase (here 1 degree Celsius) in the explanatory variable (hence the term “slope” for this parameter). In general, it is (strongly) recommended to center (subtract the mean) and scale (divide by the standard deviation) the values of the explanatory variable for numerical and interpretational reasons. Numerical first, because it allows algorithms, whether frequentist or Bayesian, not to get lost in corners of the parameter space. Interpretation next, because the intercept <span class="math inline">\(\beta_0\)</span> is then interpreted as the value of the response variable for an average value of the explanatory variable.</p>
<p>In this section, rather than analyzing “real” data, we will, from the parameters <span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(\sigma\)</span>, simulate artificial data, as if they came from a real underlying process.</p>
</div>
<div id="simulating-data" class="section level3" number="5.2.2">
<h3>
<span class="header-section-number">5.2.2</span> Simulating data<a class="anchor" aria-label="anchor" href="#simulating-data"><i class="fas fa-link"></i></a>
</h3>
<p>What do I mean by simulating data? Data analysis and data simulation are two sides of the same model. In analysis, we use the data to estimate the parameters of a model. In simulation, we fix the parameters and use the model to generate data. One reason to use simulations is that this exercise forces us to really understand the model; if I cannot simulate data from a model, it means I have not fully understood how it works. There are many other good reasons to use simulations. Since the truth (the parameters and the model) is known, we can check that the model is correctly coded. We can evaluate bias and precision of our parameter estimates, assess the effects of violating model assumptions, plan a data collection protocol, or evaluate the power of a statistical test. In short, it is a very useful technique to have in your toolbox!</p>
<p>Let us return to our example. To simulate data according to the linear regression model, we start by fixing our parameters: <span class="math inline">\(\beta_0 = 0.1\)</span>, <span class="math inline">\(\beta_1 = 1\)</span> and <span class="math inline">\(\sigma^2 = 0.5\)</span> :</p>
<div class="sourceCode" id="cb69"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">beta0</span> <span class="op">&lt;-</span> <span class="fl">0.1</span> <span class="co"># true value of the intercept</span></span>
<span><span class="va">beta1</span> <span class="op">&lt;-</span> <span class="fl">1</span> <span class="co"># true value of the coefficient of x</span></span>
<span><span class="va">sigma</span> <span class="op">&lt;-</span> <span class="fl">0.5</span> <span class="co"># standard deviation of the errors</span></span></code></pre></div>
<p>Then we simulate <span class="math inline">\(n = 100\)</span> values <span class="math inline">\(x_i\)</span> of our explanatory variable from a normal distribution with mean 0 and standard deviation 1, that is <span class="math inline">\(N(0,1)\)</span> :</p>
<div class="sourceCode" id="cb70"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">666</span><span class="op">)</span> <span class="co"># to make the simulation reproducible</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">100</span> <span class="co"># number of observations</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">n</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1</span><span class="op">)</span> <span class="co"># covariate x simulated from a standard normal distribution</span></span></code></pre></div>
<p>Finally, we simulate the values of the response variable by adding a normal error <code>epsilon</code> to the linear relationship <code>beta0 + beta1 * x</code> :</p>
<div class="sourceCode" id="cb71"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">epsilon</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="va">sigma</span><span class="op">)</span> <span class="co"># generate normal errors</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="va">beta0</span> <span class="op">+</span> <span class="va">beta1</span> <span class="op">*</span> <span class="va">x</span> <span class="op">+</span> <span class="va">epsilon</span> <span class="co"># add errors to the linear relationship</span></span>
<span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>y <span class="op">=</span> <span class="va">y</span>, x <span class="op">=</span> <span class="va">x</span><span class="op">)</span></span></code></pre></div>
Figure <a href="lms.html#fig:donnees-simulees">5.1</a> below shows the simulated data, as well as the regression line corresponding to the model used to generate them :
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:donnees-simulees"></span>
<img src="05-regression_files/figure-html/donnees-simulees-1.png" alt="Simulated data (n = 100) according to the model \(y_i = \beta_0 + \beta_1 x_i + \varepsilon_i\), with \(\beta_0 = 0.1\), \(\beta_1 = 1\) and \(\sigma = 1\). The red line corresponds to the regression line." width="90%"><p class="caption">
Figure 5.1: Simulated data (n = 100) according to the model <span class="math inline">\(y_i = \beta_0 + \beta_1 x_i + \varepsilon_i\)</span>, with <span class="math inline">\(\beta_0 = 0.1\)</span>, <span class="math inline">\(\beta_1 = 1\)</span> and <span class="math inline">\(\sigma = 1\)</span>. The red line corresponds to the regression line.
</p>
</div>
</div>
<div id="fitting-with-brms" class="section level3" number="5.2.3">
<h3>
<span class="header-section-number">5.2.3</span> Fitting with <code>brms</code><a class="anchor" aria-label="anchor" href="#fitting-with-brms"><i class="fas fa-link"></i></a>
</h3>
<p>In this section, we use <code>brms</code> to fit the linear regression model to the data we have just generated. If everything goes well, the estimated parameters should be close to the values used to generate the data. I will go relatively quickly here since we covered the different steps in Chapter <a href="software.html#software">3</a>. The syntax is very close to what we would use to fit the model by maximum likelihood with the <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code> function in <code>R</code>:</p>
<div class="sourceCode" id="cb72"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">lm.brms</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://paulbuerkner.com/brms/reference/brm.html">brm</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">x</span>, <span class="co"># formula: y as a function of x</span></span>
<span>               data <span class="op">=</span> <span class="va">data</span>, <span class="co"># dataset</span></span>
<span>               family <span class="op">=</span> <span class="va">gaussian</span><span class="op">)</span> <span class="co"># normal distribution</span></span></code></pre></div>
<p>Let’s take a look at the numerical summaries and the convergence diagnostics:</p>
<div class="sourceCode" id="cb73"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">lm.brms</span><span class="op">)</span></span>
<span><span class="co">#&gt;  Family: gaussian </span></span>
<span><span class="co">#&gt;   Links: mu = identity; sigma = identity </span></span>
<span><span class="co">#&gt; Formula: y ~ x </span></span>
<span><span class="co">#&gt;    Data: data (Number of observations: 100) </span></span>
<span><span class="co">#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;</span></span>
<span><span class="co">#&gt;          total post-warmup draws = 4000</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Regression Coefficients:</span></span>
<span><span class="co">#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS</span></span>
<span><span class="co">#&gt; Intercept     0.06      0.06    -0.05     0.17 1.00     4366     3028</span></span>
<span><span class="co">#&gt; x             1.10      0.06     0.99     1.21 1.00     4188     3147</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Further Distributional Parameters:</span></span>
<span><span class="co">#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS</span></span>
<span><span class="co">#&gt; sigma     0.57      0.04     0.49     0.65 1.00     4090     3050</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS</span></span>
<span><span class="co">#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential</span></span>
<span><span class="co">#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).</span></span></code></pre></div>
<p>By default, <code>brms</code> used four chains that each ran for 2000 iterations with 1000 iterations used as burn-in, for a total of 4000 iterations for posterior inference. In the output, <code>Intercept</code>, <code>x</code> and <code>sigma</code> correspond respectively to the parameters <span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(\sigma\)</span> of the model. The <span class="math inline">\(\hat{R}\)</span> for the 3 parameters is 1, and the effective sample sizes are satisfactory. The credible intervals contain the true parameter value used to simulate the data.</p>
<p>We check that the mixing is good (Figure <a href="lms.html#fig:fig-posterior-regression">5.2</a>):</p>
<div class="sourceCode" id="cb74"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">lm.brms</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:fig-posterior-regression"></span>
<img src="05-regression_files/figure-html/fig-posterior-regression-1.png" alt="Histograms of the posterior distributions (left column) and traces (right column) of the linear regression parameters. In the histograms, the x-axis represents the possible values of the estimated parameter (intercept, slope, or standard deviation) and the y-axis corresponds to their frequency in the posterior sample. In the trace plots, the x-axis indicates the MCMC iteration number, while the y-axis represents the simulated value of the parameter at each iteration." width="90%"><p class="caption">
Figure 5.2: Histograms of the posterior distributions (left column) and traces (right column) of the linear regression parameters. In the histograms, the x-axis represents the possible values of the estimated parameter (intercept, slope, or standard deviation) and the y-axis corresponds to their frequency in the posterior sample. In the trace plots, the x-axis indicates the MCMC iteration number, while the y-axis represents the simulated value of the parameter at each iteration.
</p>
</div>
</div>
<div id="weakly-informative-priors" class="section level3" number="5.2.4">
<h3>
<span class="header-section-number">5.2.4</span> Weakly informative priors<a class="anchor" aria-label="anchor" href="#weakly-informative-priors"><i class="fas fa-link"></i></a>
</h3>
<p>Rather than using the default priors in <code>brms</code>, let’s choose other priors. We will use weakly informative priors, and more specifically a normal with mean 0 and standard deviation 1.5, or <span class="math inline">\(N(0, 1.5)\)</span>, for the regression parameters <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>. We already discussed weakly informative priors in Chapter <a href="prior.html#prior">4</a>. The idea is close to that of vague or non-informative priors, in the sense that we try, through weakly informative priors, to reflect the fact that we do not really have information on the model parameters. The difference is that non-informative priors can induce aberrant values as we saw in Chapter <a href="prior.html#prior">4</a>. This is still the case here. Take for example <span class="math inline">\(N(0, 100)\)</span> for the parameters of the linear relationship that links the mass of coypus to temperature, and simulate a whole bunch of values from these priors, then form the linear relationship:</p>
<div class="sourceCode" id="cb75"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="co"># number of lines to simulate</span></span>
<span><span class="va">n_lines</span> <span class="op">&lt;-</span> <span class="fl">100</span></span>
<span></span>
<span><span class="co"># draws of intercepts and slopes from the priors</span></span>
<span><span class="va">intercepts</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n_lines</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">100</span><span class="op">)</span></span>
<span><span class="va">slopes</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n_lines</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">100</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># create a data frame</span></span>
<span><span class="va">lines_df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">n_lines</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">y_vals</span> <span class="op">&lt;-</span> <span class="va">intercepts</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">+</span> <span class="va">slopes</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">*</span> <span class="va">x</span></span>
<span>  <span class="va">temp_df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">y_vals</span>, line <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">as.factor</a></span><span class="op">(</span><span class="va">i</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="va">lines_df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">rbind</a></span><span class="op">(</span><span class="va">lines_df</span>, <span class="va">temp_df</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># plot with ggplot2</span></span>
<span><span class="fu">ggplot</span><span class="op">(</span><span class="va">lines_df</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">y</span>, group <span class="op">=</span> <span class="va">line</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_line</span><span class="op">(</span>alpha <span class="op">=</span> <span class="fl">0.3</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme_minimal</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span>x <span class="op">=</span> <span class="st">"x"</span>, y <span class="op">=</span> <span class="st">"y"</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:fig-prior-regression-vague"></span>
<img src="05-regression_files/figure-html/fig-prior-regression-vague-1.png" alt="Simulation of regression lines drawn from the prior distributions. Each line corresponds to a draw of the parameters: intercept and slope ~ N(0, 100)." width="90%"><p class="caption">
Figure 5.3: Simulation of regression lines drawn from the prior distributions. Each line corresponds to a draw of the parameters: intercept and slope ~ N(0, 100).
</p>
</div>
In Figure <a href="lms.html#fig:fig-prior-regression-vague">5.3</a>, we see that we obtain aberrant values for the <span class="math inline">\(y_i\)</span>, with coypus weighing more than 400 kilograms, and (very) negative values for the mass. We have just done a “prior predictive check”, as in Chapter <a href="prior.html#prior">4</a>. In Figure <a href="lms.html#fig:fig-prior-regression">5.4</a>, we do the same thing with our weakly informative prior <span class="math inline">\(N(0, 1.5)\)</span>:
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:fig-prior-regression"></span>
<img src="05-regression_files/figure-html/fig-prior-regression-1.png" alt="Simulation of regression lines drawn from the prior distributions. Each line corresponds to a draw of the parameters: intercept and slope ~ N(0, 1.5)." width="90%"><p class="caption">
Figure 5.4: Simulation of regression lines drawn from the prior distributions. Each line corresponds to a draw of the parameters: intercept and slope ~ N(0, 1.5).
</p>
</div>
<p>We obtain more reasonable values for the mass of coypus, which rarely exceeds 10 kilograms. We still have negative values, but smaller ones, and the MCMC algorithm should cope. There is also a numerical advantage to using weakly informative priors: they help MCMC methods not to get lost in the space of all possible values for the parameters to be estimated, and allow them to focus on realistic values of these parameters. By doing this, you may have the impression that we are using the data to construct the priors, whereas we said that the prior should reflect the information available before seeing the data. This is an opportunity to clarify this point a bit. The important thing is above all that the prior represents information independent of the data that are used in the likelihood.</p>
<p>So far we have focused on the regression parameters, the intercept <span class="math inline">\(\beta_0\)</span> and the slope <span class="math inline">\(\beta_1\)</span>. But what about the standard deviation, <span class="math inline">\(\sigma\)</span>? This parameter is just as important: it reflects how much the observations deviate from the average trend described by the regression line.</p>
<p>One option often considered is to assign it a uniform distribution, for example <span class="math inline">\(\sigma \sim U(0, B)\)</span>, with a natural lower bound (0, since <span class="math inline">\(\sigma\)</span> is always positive), but an upper bound <span class="math inline">\(B\)</span> that is difficult to choose. What maximum value should one give to a standard deviation? In some cases, an apparently reasonable value can turn out to be too wide. For example, if we model human heights and set <span class="math inline">\(\sigma \sim U(0, 50)\)</span> (in cm), this amounts to assuming that 95% of heights are spread over a 100 cm range around the mean—which is very unlikely.</p>
<p>A more flexible and more realistic alternative is to use an exponential distribution <span class="math inline">\(\sigma \sim \exp(\lambda)\)</span> where <span class="math inline">\(\lambda &gt; 0\)</span> is a rate parameter. This distribution is defined only for positive values, which is consistent with the nature of <span class="math inline">\(\sigma\)</span>, and it favors small values of the standard deviation while leaving the possibility for <span class="math inline">\(\sigma\)</span> to be larger if the data justify it.</p>
<p>By default, one often takes <span class="math inline">\(\lambda = 1\)</span>. With <span class="math inline">\(\lambda = 1\)</span>, the mean and the standard deviation of this distribution are both equal to <span class="math inline">\(1\)</span>, which induces a modest but non-restrictive prior (Figure <a href="lms.html#fig:fig-prior-sigma">5.5</a>).</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:fig-prior-sigma"></span>
<img src="05-regression_files/figure-html/fig-prior-sigma-1.png" alt="Comparison between two prior distributions for the standard deviation \(\sigma\): a uniform distribution \(\text{U}(0,5)\), which gives the same density between 0 and 5, and an exponential distribution \(\text{Exp}(1)\), which favors small values while retaining a heavier tail." width="90%"><p class="caption">
Figure 5.5: Comparison between two prior distributions for the standard deviation <span class="math inline">\(\sigma\)</span>: a uniform distribution <span class="math inline">\(\text{U}(0,5)\)</span>, which gives the same density between 0 and 5, and an exponential distribution <span class="math inline">\(\text{Exp}(1)\)</span>, which favors small values while retaining a heavier tail.
</p>
</div>
<p>We can formalize this model as follows:
<span class="math display">\[\begin{align}
y_i &amp;\sim \text{Normal}(\mu_i, \sigma^2) &amp;\text{[likelihood]}\\
\mu_i &amp;= \beta_0 + \beta_1 \; x_i &amp;\text{[linear relationship]}\\
\beta_0, \beta_1 &amp;\sim \text{Normal}(0, 1.5) &amp;\text{[prior on parameters]} \\
\sigma &amp;\sim \text{Exp}(1) &amp;\text{[prior on parameters]} \\
\end{align}\]</span></p>
<p>Let us specify these priors:</p>
<div class="sourceCode" id="cb76"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">myprior</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://paulbuerkner.com/brms/reference/set_prior.html">prior</a></span><span class="op">(</span><span class="fu">normal</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1.5</span><span class="op">)</span>, class <span class="op">=</span> <span class="va">b</span><span class="op">)</span>, <span class="co"># prior on the coefficient of x</span></span>
<span>  <span class="fu"><a href="https://paulbuerkner.com/brms/reference/set_prior.html">prior</a></span><span class="op">(</span><span class="fu">normal</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1.5</span><span class="op">)</span>, class <span class="op">=</span> <span class="va">Intercept</span><span class="op">)</span>, <span class="co"># prior on the intercept</span></span>
<span>  <span class="fu"><a href="https://paulbuerkner.com/brms/reference/set_prior.html">prior</a></span><span class="op">(</span><span class="fu"><a href="https://paulbuerkner.com/brms/reference/brmsfamily.html">exponential</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span>, class <span class="op">=</span> <span class="va">sigma</span><span class="op">)</span> <span class="co"># prior on the standard deviation of the error</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>Then let’s refit with <code>brms</code>:</p>
<div class="sourceCode" id="cb77"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">lm.brms</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://paulbuerkner.com/brms/reference/brm.html">brm</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">x</span>, </span>
<span>               data <span class="op">=</span> <span class="va">data</span>, </span>
<span>               family <span class="op">=</span> <span class="va">gaussian</span>, </span>
<span>               prior <span class="op">=</span> <span class="va">myprior</span><span class="op">)</span></span></code></pre></div>
<p>We check that the numerical summaries obtained are close to those obtained with the default priors, and above all close to the values used to simulate the data:</p>
<div class="sourceCode" id="cb78"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">lm.brms</span><span class="op">)</span></span>
<span><span class="co">#&gt;  Family: gaussian </span></span>
<span><span class="co">#&gt;   Links: mu = identity; sigma = identity </span></span>
<span><span class="co">#&gt; Formula: y ~ x </span></span>
<span><span class="co">#&gt;    Data: data (Number of observations: 100) </span></span>
<span><span class="co">#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;</span></span>
<span><span class="co">#&gt;          total post-warmup draws = 4000</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Regression Coefficients:</span></span>
<span><span class="co">#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS</span></span>
<span><span class="co">#&gt; Intercept     0.06      0.06    -0.05     0.18 1.00     3562     2765</span></span>
<span><span class="co">#&gt; x             1.10      0.06     0.99     1.21 1.00     3870     2731</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Further Distributional Parameters:</span></span>
<span><span class="co">#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS</span></span>
<span><span class="co">#&gt; sigma     0.57      0.04     0.49     0.66 1.00     3540     2633</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS</span></span>
<span><span class="co">#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential</span></span>
<span><span class="co">#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).</span></span></code></pre></div>
<p>Here, the two models give almost the same thing, which is not surprising because the data are informative enough for them to “take over from” the prior. The interest of weakly informative priors is not so much seen in this small example as in other situations: they avoid aberrant values, stabilize the MCMC computations, and remain useful when we have fewer data or more complex models.</p>
</div>
<div id="fitting-with-nimble" class="section level3" number="5.2.5">
<h3>
<span class="header-section-number">5.2.5</span> Fitting with <code>NIMBLE</code><a class="anchor" aria-label="anchor" href="#fitting-with-nimble"><i class="fas fa-link"></i></a>
</h3>
<p>We start by writing the model:</p>
<div class="sourceCode" id="cb79"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/nimble/man/nimbleCode.html">nimbleCode</a></span><span class="op">(</span><span class="op">{</span></span>
<span>  <span class="co"># priors</span></span>
<span>  <span class="va">beta0</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1.5</span><span class="op">)</span> <span class="co"># normal prior on intercept</span></span>
<span>  <span class="va">beta1</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1.5</span><span class="op">)</span> <span class="co"># normal prior on coefficient</span></span>
<span>  <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Exponential.html">dexp</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span> <span class="co"># exponential prior on standard deviation</span></span>
<span>  <span class="co"># likelihood</span></span>
<span>  <span class="kw">for</span><span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">n</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">y</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">beta0</span> <span class="op">+</span> <span class="va">beta1</span> <span class="op">*</span> <span class="va">x</span><span class="op">[</span><span class="va">i</span><span class="op">]</span>, sd <span class="op">=</span> <span class="va">sigma</span><span class="op">)</span> <span class="co"># equiv of yi = beta0 + beta1 * xi + epsiloni</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">}</span><span class="op">)</span></span></code></pre></div>
<p>In this code block, we start by specifying priors on the three model parameters: a normal prior centered on 0 with standard deviation 1.5 for the intercept <span class="math inline">\(\beta_0\)</span> and for the slope <span class="math inline">\(\beta_1\)</span>, as well as an exponential prior for the standard deviation <span class="math inline">\(\sigma\)</span> of the errors. The next part is a <code>for(i in 1:n)</code> loop that defines the likelihood. We specify the likelihood observation by observation, and <code>NIMBLE</code> automatically deduces the product of likelihoods over all individuals, which corresponds to the likelihood of the dataset. For each observation <span class="math inline">\(i\)</span>, we have a normal distribution centered at <code>beta0 + beta1 * x[i]</code>, with standard deviation <code>sigma</code>. We recover the relationship <span class="math inline">\(y_i = \beta_0 + \beta_1 x_i + \varepsilon_i\)</span> where <span class="math inline">\(\varepsilon_i \sim N(0,\sigma^2)\)</span>, which is strictly equivalent to <span class="math inline">\(y_i \sim N(\beta_0 + \beta_1 x_i,\sigma^2)\)</span>.</p>
<p>The next steps are to put the data into a list, specify initial values, and indicate the parameters for which we want output:</p>
<div class="sourceCode" id="cb80"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">y</span>, n <span class="op">=</span> <span class="va">n</span><span class="op">)</span> <span class="co"># data</span></span>
<span><span class="va">inits</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>beta0 <span class="op">=</span> <span class="op">-</span><span class="fl">0.5</span>, beta1 <span class="op">=</span> <span class="op">-</span><span class="fl">0.5</span>, sigma <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span>, <span class="co"># inits chain 1</span></span>
<span>              <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>beta0 <span class="op">=</span> <span class="fl">0</span>, beta1 <span class="op">=</span> <span class="fl">0</span>, sigma <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>, <span class="co"># inits chain 2</span></span>
<span>              <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>beta0 <span class="op">=</span> <span class="fl">0.5</span>, beta1 <span class="op">=</span> <span class="fl">0.5</span>, sigma <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span><span class="op">)</span> <span class="co"># inits chain 3</span></span>
<span><span class="va">par</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"beta0"</span>, <span class="st">"beta1"</span>, <span class="st">"sigma"</span><span class="op">)</span></span></code></pre></div>
<p>We then have all the ingredients to run <code>NIMBLE</code>:</p>
<div class="sourceCode" id="cb81"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">lm.nimble</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/nimble/man/nimbleMCMC.html">nimbleMCMC</a></span><span class="op">(</span></span>
<span>  code <span class="op">=</span> <span class="va">model</span>,</span>
<span>  data <span class="op">=</span> <span class="va">dat</span>,</span>
<span>  inits <span class="op">=</span> <span class="va">inits</span>,</span>
<span>  monitors <span class="op">=</span> <span class="va">par</span>,</span>
<span>  niter <span class="op">=</span> <span class="fl">2000</span>,</span>
<span>  nburnin <span class="op">=</span> <span class="fl">1000</span>,</span>
<span>  nchains <span class="op">=</span> <span class="fl">3</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>Let’s inspect the results:</p>
<div class="sourceCode" id="cb82"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/MCMCvis/man/MCMCsummary.html">MCMCsummary</a></span><span class="op">(</span><span class="va">lm.nimble</span>, round <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="co">#&gt;       mean   sd  2.5%  50% 97.5% Rhat n.eff</span></span>
<span><span class="co">#&gt; beta0 0.06 0.06 -0.05 0.06  0.17 1.00  3000</span></span>
<span><span class="co">#&gt; beta1 1.10 0.06  0.99 1.10  1.21 1.00  3000</span></span>
<span><span class="co">#&gt; sigma 0.57 0.04  0.49 0.56  0.65 1.01   772</span></span></code></pre></div>
<p>We obtain numerical summaries that are close to those obtained with <code>brms</code>, and close to the true parameter values used to simulate the data.</p>
<p>For convergence, we can inspect the trace plots:</p>
<div class="sourceCode" id="cb83"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/MCMCvis/man/MCMCtrace.html">MCMCtrace</a></span><span class="op">(</span>object <span class="op">=</span> <span class="va">lm.nimble</span>,</span>
<span>          pdf <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>          ind <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>          Rhat <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>          n.eff <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="05-regression_files/figure-html/unnamed-chunk-19-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>Everything looks good. Mixing is correct, and the convergence diagnostics are in the green.</p>
</div>
<div id="maximum-likelihood-fitting" class="section level3" number="5.2.6">
<h3>
<span class="header-section-number">5.2.6</span> Maximum likelihood fitting<a class="anchor" aria-label="anchor" href="#maximum-likelihood-fitting"><i class="fas fa-link"></i></a>
</h3>
<p>Finally, we can compare with maximum likelihood fitting, obtained simply with the command <code>lm(y ~ x, data = data)</code>. Everything is in Figure <a href="lms.html#fig:comparaison-methodes">5.6</a>:</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:comparaison-methodes"></span>
<img src="05-regression_files/figure-html/comparaison-methodes-1.png" alt="Comparison of parameter estimates (intercept and slope) across methods (brms, lm, and NIMBLE). Points show posterior means for brms and NIMBLE, and the maximum likelihood estimate for lm. We also show 95% credible intervals (brms and NIMBLE) and the 95% confidence interval (lm). The dashed black line indicates the true value used to simulate the data." width="90%"><p class="caption">
Figure 5.6: Comparison of parameter estimates (intercept and slope) across methods (brms, lm, and NIMBLE). Points show posterior means for brms and NIMBLE, and the maximum likelihood estimate for lm. We also show 95% credible intervals (brms and NIMBLE) and the 95% confidence interval (lm). The dashed black line indicates the true value used to simulate the data.
</p>
</div>
<p>The posterior means obtained with <code>NIMBLE</code> and <code>brms</code> are close to the maximum likelihood estimates for the intercept and the slope, to a lesser extent. The credible intervals obtained with <code>NIMBLE</code> and <code>brms</code> and the confidence interval obtained by maximum likelihood all include the true parameter values used to simulate the data. Keep in mind that this is a single simulation; the exercise would need to be repeated many times to formally assess the distance between the true values and the parameter estimates (bias).</p>
</div>
</div>
<div id="model-evaluation" class="section level2" number="5.3">
<h2>
<span class="header-section-number">5.3</span> Model evaluation<a class="anchor" aria-label="anchor" href="#model-evaluation"><i class="fas fa-link"></i></a>
</h2>
<p>The quality of a model fit to data is essential to assess how much confidence we can place in parameter estimates. Goodness-of-fit tests are well established in frequentist statistics, and many of them can also be used in simple Bayesian models. This is the case, for example, for residual analysis.</p>
<p>In the case of linear regression, the model rests on several assumptions. These are the assumptions of independence, normality, linearity, and homoscedasticity (<span class="math inline">\(\sigma\)</span> does not vary with the explanatory variable). In general, we can evaluate the first two with context. For the other two, we can visualize the fit by overlaying the estimated regression line on the observed scatter plot. With the <code>brms</code> package, this gives Figure <a href="lms.html#fig:brms-fit-plot">5.7</a>:</p>
<div class="sourceCode" id="cb84"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># extract values from posteriors</span></span>
<span><span class="va">post</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/posterior/reference/draws_df.html">as_draws_df</a></span><span class="op">(</span><span class="va">lm.brms</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># create grid of x values</span></span>
<span><span class="va">grille_x</span> <span class="op">&lt;-</span> <span class="fu">tibble</span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">min</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">x</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">x</span><span class="op">)</span>, length.out <span class="op">=</span> <span class="fl">100</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># for each x, simulate y values</span></span>
<span><span class="va">pred</span> <span class="op">&lt;-</span> <span class="va">post</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">select</span><span class="op">(</span><span class="va">b_Intercept</span>, <span class="va">b_x</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">expand_grid</span><span class="op">(</span><span class="va">grille_x</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">mutate</span><span class="op">(</span>y <span class="op">=</span> <span class="va">b_Intercept</span> <span class="op">+</span> <span class="va">b_x</span> <span class="op">*</span> <span class="va">x</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">group_by</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">summarise</span><span class="op">(</span></span>
<span>    mean <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span>,</span>
<span>    lower <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/quantile.html">quantile</a></span><span class="op">(</span><span class="va">y</span>, <span class="fl">0.025</span><span class="op">)</span>,</span>
<span>    upper <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/quantile.html">quantile</a></span><span class="op">(</span><span class="va">y</span>, <span class="fl">0.975</span><span class="op">)</span>,</span>
<span>    .groups <span class="op">=</span> <span class="st">"drop"</span></span>
<span>  <span class="op">)</span></span>
<span></span>
<span><span class="co"># extract post means</span></span>
<span><span class="va">intercept</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">lm.brms</span><span class="op">)</span><span class="op">$</span><span class="va">fixed</span><span class="op">[</span><span class="fl">1</span>,<span class="fl">1</span><span class="op">]</span></span>
<span><span class="va">slope</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">lm.brms</span><span class="op">)</span><span class="op">$</span><span class="va">fixed</span><span class="op">[</span><span class="fl">2</span>,<span class="fl">1</span><span class="op">]</span></span>
<span></span>
<span><span class="co"># dataviz</span></span>
<span><span class="fu">ggplot</span><span class="op">(</span><span class="va">data</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">y</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_point</span><span class="op">(</span>alpha <span class="op">=</span> <span class="fl">0.6</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_ribbon</span><span class="op">(</span>data <span class="op">=</span> <span class="va">pred</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, ymin <span class="op">=</span> <span class="va">lower</span>, ymax <span class="op">=</span> <span class="va">upper</span><span class="op">)</span>, fill <span class="op">=</span> <span class="st">"blue"</span>, alpha <span class="op">=</span> <span class="fl">0.2</span>, inherit.aes <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_line</span><span class="op">(</span>data <span class="op">=</span> <span class="va">pred</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">mean</span><span class="op">)</span>, color <span class="op">=</span> <span class="st">"blue"</span>, size <span class="op">=</span> <span class="fl">1.2</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span>x <span class="op">=</span> <span class="st">"x"</span>, y <span class="op">=</span> <span class="st">"y"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">coord_cartesian</span><span class="op">(</span>xlim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/range.html">range</a></span><span class="op">(</span><span class="va">grille_x</span><span class="op">$</span><span class="va">x</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme_minimal</span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:brms-fit-plot"></span>
<img src="05-regression_files/figure-html/brms-fit-plot-1.png" alt="Linear model fit with brms. The blue line is the estimated regression, obtained by setting the intercept and slope to their posterior means, surrounded by its 95% credible interval." width="90%"><p class="caption">
Figure 5.7: Linear model fit with brms. The blue line is the estimated regression, obtained by setting the intercept and slope to their posterior means, surrounded by its 95% credible interval.
</p>
</div>
<p>With <code>NIMBLE</code>, this is Figure <a href="lms.html#fig:nimble-fit-plot">5.8</a>:</p>
<div class="sourceCode" id="cb85"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">x</span> <span class="op">&lt;-</span> <span class="va">data</span><span class="op">$</span><span class="va">x</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="va">data</span><span class="op">$</span><span class="va">y</span></span>
<span></span>
<span><span class="va">posterior</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">rbind</a></span><span class="op">(</span><span class="va">lm.nimble</span><span class="op">$</span><span class="va">chain1</span>, <span class="va">lm.nimble</span><span class="op">$</span><span class="va">chain2</span>, <span class="va">lm.nimble</span><span class="op">$</span><span class="va">chain3</span><span class="op">)</span></span>
<span><span class="va">beta0</span> <span class="op">&lt;-</span> <span class="va">posterior</span><span class="op">[</span>,<span class="st">'beta0'</span><span class="op">]</span></span>
<span><span class="va">beta1</span> <span class="op">&lt;-</span> <span class="va">posterior</span><span class="op">[</span>,<span class="st">'beta1'</span><span class="op">]</span></span>
<span></span>
<span><span class="va">x_seq</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">min</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">x</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">x</span><span class="op">)</span>, length.out <span class="op">=</span> <span class="fl">100</span><span class="op">)</span></span>
<span></span>
<span><span class="va">pred_matrix</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">sapply</a></span><span class="op">(</span><span class="va">x_seq</span>, <span class="kw">function</span><span class="op">(</span><span class="va">xi</span><span class="op">)</span> <span class="va">beta0</span> <span class="op">+</span> <span class="va">beta1</span> <span class="op">*</span> <span class="va">xi</span><span class="op">)</span></span>
<span></span>
<span><span class="va">pred_df</span> <span class="op">&lt;-</span> <span class="fu">tibble</span><span class="op">(</span></span>
<span>  x <span class="op">=</span> <span class="va">x_seq</span>,</span>
<span>  y_mean <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/colSums.html">colMeans</a></span><span class="op">(</span><span class="va">pred_matrix</span><span class="op">)</span>,</span>
<span>  y_lower <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">pred_matrix</span>, <span class="fl">2</span>, <span class="va">quantile</span>, probs <span class="op">=</span> <span class="fl">0.025</span><span class="op">)</span>,</span>
<span>  y_upper <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">pred_matrix</span>, <span class="fl">2</span>, <span class="va">quantile</span>, probs <span class="op">=</span> <span class="fl">0.975</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">true_df</span> <span class="op">&lt;-</span> <span class="fu">tibble</span><span class="op">(</span>x <span class="op">=</span> <span class="va">x_seq</span>, y_true <span class="op">=</span> <span class="fl">0.1</span> <span class="op">+</span> <span class="fl">1</span> <span class="op">*</span> <span class="va">x_seq</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">ggplot</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_point</span><span class="op">(</span>data <span class="op">=</span> <span class="va">data</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">y</span><span class="op">)</span>, alpha <span class="op">=</span> <span class="fl">0.6</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_ribbon</span><span class="op">(</span>data <span class="op">=</span> <span class="va">pred_df</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, ymin <span class="op">=</span> <span class="va">y_lower</span>, ymax <span class="op">=</span> <span class="va">y_upper</span><span class="op">)</span>, fill <span class="op">=</span> <span class="st">"blue"</span>, alpha <span class="op">=</span> <span class="fl">0.2</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_line</span><span class="op">(</span>data <span class="op">=</span> <span class="va">pred_df</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">y_mean</span><span class="op">)</span>, color <span class="op">=</span> <span class="st">"blue"</span>, size <span class="op">=</span> <span class="fl">1.2</span><span class="op">)</span> <span class="op">+</span></span>
<span> <span class="co"># geom_line(data = true_df, aes(x = x, y = y_true), color = "red", size = 1.2) +</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span>x <span class="op">=</span> <span class="st">"x"</span>, y <span class="op">=</span> <span class="st">"y"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme_minimal</span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:nimble-fit-plot"></span>
<img src="05-regression_files/figure-html/nimble-fit-plot-1.png" alt="Linear model fit with NIMBLE. The blue line is the estimated regression, obtained by setting the intercept and slope to their posterior means, surrounded by its 95% credible interval." width="90%"><p class="caption">
Figure 5.8: Linear model fit with NIMBLE. The blue line is the estimated regression, obtained by setting the intercept and slope to their posterior means, surrounded by its 95% credible interval.
</p>
</div>
<p>Bayesian methods are often used for more complex models than linear regression (such as mixed models; see Chapter <a href="glms.html#glms">6</a>), for which there are no standard turnkey goodness-of-fit tests. In these situations, we commonly use what are called posterior predictive checks. The idea is to simulate new datasets from the posterior distribution of the model parameters, and then compare them to the observed data. The more the simulated data resemble the real data, the more it suggests that the model fits well. This comparison can be done visually or using a Bayesian p-value that quantifies the discrepancy between simulated and observed data.</p>
<p>In <code>brms</code>, you just do:</p>
<div class="sourceCode" id="cb86"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://mc-stan.org/bayesplot/reference/pp_check.html">pp_check</a></span><span class="op">(</span><span class="va">lm.brms</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:ppcheck-brms"></span>
<img src="05-regression_files/figure-html/ppcheck-brms-1.png" alt="Posterior predictive checks produced with brms. The black curve corresponds to the observed data; the blue curves to data simulated under the model. The x-axis shows the possible values of the simulated or observed response. The y-axis shows their estimated density." width="90%"><p class="caption">
Figure 5.9: Posterior predictive checks produced with brms. The black curve corresponds to the observed data; the blue curves to data simulated under the model. The x-axis shows the possible values of the simulated or observed response. The y-axis shows their estimated density.
</p>
</div>
<p>The <code><a href="https://mc-stan.org/bayesplot/reference/pp_check.html">pp_check()</a></code> function generates posterior predictive check plots (Figure <a href="lms.html#fig:ppcheck-brms">5.9</a>). It compares observed data to data simulated from the fitted model. If the model fits the data well, then we should be able to use it to generate data that resemble the observed data. Therefore, if the simulated curves overlap the observations well, this indicates that the model captures the structure of the data correctly. Otherwise, this may suggest a model misspecification, for example an inappropriate link or distribution family (see Chapter <a href="glms.html#glms">6</a>).</p>
<p>There is no dedicated function in <code>NIMBLE</code>, so we will need to simulate data under the model with the estimated parameters. We could do it by hand as with life expectancy, but the simplest approach is to include an additional line in the <code>NIMBLE</code> code:</p>
<div class="sourceCode" id="cb87"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/nimble/man/nimbleCode.html">nimbleCode</a></span><span class="op">(</span><span class="op">{</span></span>
<span>  <span class="va">beta0</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1.5</span><span class="op">)</span> <span class="co"># normal prior on intercept</span></span>
<span>  <span class="va">beta1</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1.5</span><span class="op">)</span> <span class="co"># normal prior on coefficient</span></span>
<span>  <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Exponential.html">dexp</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span> <span class="co"># exponential prior on standard deviation</span></span>
<span>  <span class="kw">for</span><span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">n</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">y</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">beta0</span> <span class="op">+</span> <span class="va">beta1</span> <span class="op">*</span> <span class="va">x</span><span class="op">[</span><span class="va">i</span><span class="op">]</span>, sd <span class="op">=</span> <span class="va">sigma</span><span class="op">)</span> <span class="co"># model for observed data</span></span>
<span>    <span class="va">y_sim</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">beta0</span> <span class="op">+</span> <span class="va">beta1</span> <span class="op">*</span> <span class="va">x</span><span class="op">[</span><span class="va">i</span><span class="op">]</span>, sd <span class="op">=</span> <span class="va">sigma</span><span class="op">)</span> <span class="co"># model for simulated data</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">}</span><span class="op">)</span></span></code></pre></div>
<p>This is the line <code>y_sim[i] ~ dnorm(beta0 + beta1 * x[i], sd = sigma)</code> that I added to simulate under the fitted model. The data and initial values do not change; we just need to add <code>y_sim</code> to the list of parameters we want to retrieve in the output:</p>
<div class="sourceCode" id="cb88"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">par</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"beta0"</span>, <span class="st">"beta1"</span>, <span class="st">"sigma"</span>, <span class="st">"y_sim"</span><span class="op">)</span></span></code></pre></div>
<p>Then we rerun <code>NIMBLE</code>:</p>
<div class="sourceCode" id="cb89"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">lm.nimble</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/nimble/man/nimbleMCMC.html">nimbleMCMC</a></span><span class="op">(</span></span>
<span>  code <span class="op">=</span> <span class="va">model</span>,</span>
<span>  data <span class="op">=</span> <span class="va">dat</span>,</span>
<span>  inits <span class="op">=</span> <span class="va">inits</span>,</span>
<span>  monitors <span class="op">=</span> <span class="va">par</span>,</span>
<span>  niter <span class="op">=</span> <span class="fl">2000</span>,</span>
<span>  nburnin <span class="op">=</span> <span class="fl">1000</span>,</span>
<span>  nchains <span class="op">=</span> <span class="fl">3</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; |-------------|-------------|-------------|-------------|</span></span>
<span><span class="co">#&gt; |-------------------------------------------------------|</span></span>
<span><span class="co">#&gt; |-------------|-------------|-------------|-------------|</span></span>
<span><span class="co">#&gt; |-------------------------------------------------------|</span></span>
<span><span class="co">#&gt; |-------------|-------------|-------------|-------------|</span></span>
<span><span class="co">#&gt; |-------------------------------------------------------|</span></span></code></pre></div>
<p>We then merge the 3 chains, and select only the columns corresponding to <code>y_sim</code>:</p>
<div class="sourceCode" id="cb90"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># merge</span></span>
<span><span class="va">y_sim_mcmc</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">rbind</a></span><span class="op">(</span><span class="va">lm.nimble</span><span class="op">$</span><span class="va">chain1</span>, <span class="va">lm.nimble</span><span class="op">$</span><span class="va">chain2</span>, <span class="va">lm.nimble</span><span class="op">$</span><span class="va">chain3</span><span class="op">)</span></span>
<span><span class="co"># get columns corresponding to simulated y (y_sim[i])</span></span>
<span><span class="va">y_sim_cols</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/grep.html">grep</a></span><span class="op">(</span><span class="st">"^y_sim\\["</span>, <span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="va">y_sim_mcmc</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co"># extract</span></span>
<span><span class="va">y_sim_matrix</span> <span class="op">&lt;-</span> <span class="va">y_sim_mcmc</span><span class="op">[</span>, <span class="va">y_sim_cols</span><span class="op">]</span></span></code></pre></div>
<p>We then take 10 draws, as <code>brms</code> does by default, and format the results:</p>
<div class="sourceCode" id="cb91"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># set seed for reproducibility</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span>
<span><span class="co"># select at random 10 values</span></span>
<span><span class="va">sim_indices</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">y_sim_matrix</span><span class="op">)</span>, <span class="fl">10</span><span class="op">)</span></span>
<span><span class="co"># format simulated data</span></span>
<span><span class="va">simulations_df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span></span>
<span>  y_sim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/vector.html">as.vector</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">y_sim_matrix</span><span class="op">[</span><span class="va">sim_indices</span>, <span class="op">]</span><span class="op">)</span><span class="op">)</span>, <span class="co"># sim values</span></span>
<span>  Replicate <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">sim_indices</span><span class="op">)</span>, each <span class="op">=</span> <span class="va">n</span><span class="op">)</span>, <span class="co"># id draw</span></span>
<span>  Observation <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">n</span>, times <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">sim_indices</span><span class="op">)</span><span class="op">)</span> <span class="co"># id obs</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>Finally, we obtain the posterior predictive checks plot in Figure <a href="lms.html#fig:ppcheck-nimble">5.10</a>:</p>
<div class="sourceCode" id="cb92"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">ggplot</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_density</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">y_sim</span>, group <span class="op">=</span> <span class="va">Replicate</span><span class="op">)</span>, color <span class="op">=</span> <span class="st">"lightblue"</span>, alpha <span class="op">=</span> <span class="fl">0.2</span>, data <span class="op">=</span> <span class="va">simulations_df</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_density</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">y</span><span class="op">)</span>, color <span class="op">=</span> <span class="st">"black"</span>, alpha <span class="op">=</span> <span class="fl">0.5</span>, size <span class="op">=</span> <span class="fl">1.2</span>, data <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>y <span class="op">=</span> <span class="va">y</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span>x <span class="op">=</span> <span class="st">""</span>,</span>
<span>       y <span class="op">=</span> <span class="st">""</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme_minimal</span><span class="op">(</span>base_size <span class="op">=</span> <span class="fl">14</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:ppcheck-nimble"></span>
<img src="05-regression_files/figure-html/ppcheck-nimble-1.png" alt="Posterior predictive checks produced with NIMBLE. The black curve corresponds to the observed data; the blue curves to data simulated under the model. The x-axis shows the possible values of the simulated or observed response. The y-axis shows their estimated density." width="90%"><p class="caption">
Figure 5.10: Posterior predictive checks produced with NIMBLE. The black curve corresponds to the observed data; the blue curves to data simulated under the model. The x-axis shows the possible values of the simulated or observed response. The y-axis shows their estimated density.
</p>
</div>
<p>We can also compute a Bayesian p-value, which represents the proportion of datasets simulated under the model for which the chosen statistic (here the mean) is as large as or larger than the observed one. A value close to 0 or 1 can indicate a poor fit of the model for that particular statistic, whereas a value close to 0.5 suggests a good fit. This Bayesian p-value is obtained as follows:</p>
<div class="sourceCode" id="cb93"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Observed test stat</span></span>
<span><span class="va">T_obs</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Simulated test stat</span></span>
<span><span class="va">T_sim</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">y_sim_matrix</span>, <span class="fl">1</span>, <span class="va">mean</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Bayesian p-value: proportion of simulations where T_sim is more extreme than T_obs</span></span>
<span><span class="va">bayes_pval</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">T_sim</span> <span class="op">&gt;=</span> <span class="va">T_obs</span><span class="op">)</span></span>
<span><span class="va">bayes_pval</span></span>
<span><span class="co">#&gt; [1] 0.512</span></span></code></pre></div>
<p>With <code>brms</code>, we can also obtain this Bayesian p-value:</p>
<div class="sourceCode" id="cb94"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># extract simulations</span></span>
<span><span class="va">y_rep</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/rstantools/reference/posterior_predict.html">posterior_predict</a></span><span class="op">(</span><span class="va">lm.brms</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># compute test stat on sim data</span></span>
<span><span class="va">T_sim</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/colSums.html">rowMeans</a></span><span class="op">(</span><span class="va">y_rep</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># compute test stat on observed data</span></span>
<span><span class="va">T_obs</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">lm.brms</span><span class="op">$</span><span class="va">data</span><span class="op">$</span><span class="va">y</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># compute Bayesian p-value</span></span>
<span><span class="va">bayes_pval</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">T_sim</span> <span class="op">&gt;=</span> <span class="va">T_obs</span><span class="op">)</span></span>
<span><span class="va">bayes_pval</span></span>
<span><span class="co">#&gt; [1] 0.49075</span></span></code></pre></div>
</div>
<div id="model-comparison" class="section level2" number="5.4">
<h2>
<span class="header-section-number">5.4</span> Model comparison<a class="anchor" aria-label="anchor" href="#model-comparison"><i class="fas fa-link"></i></a>
</h2>
<p>As we saw in Chapter <a href="principles.html#principles">1</a>, Bayesian statistics makes it possible to compare several hypotheses with each other, and to assess how plausible a hypothesis is given the data we have collected.</p>
<p>Before comparing models, it is essential to ask what the goal of the analysis is: is it to better understand a phenomenon (an explanatory approach), or rather to make predictions (a predictive approach)?</p>
<p>One strategy is to build a single model that includes the variables deemed relevant, then fit it, examine it, test it, and improve it progressively. This approach aims less at identifying the best model than at exploring different variants to better understand the system under study.</p>
<p>To evaluate a model’s predictive ability, one can rely on data already used for fitting (internal prediction) or, more reliably, on new data (external prediction). The latter approach, however, requires splitting the data into a training set and a test set. If that is not possible, it is still possible to estimate predictive performance on the training data themselves using tools such as WAIC or LOO-CV.</p>
<p>WAIC (Watanabe–Akaike Information Criterion) and LOO-CV (Leave-One-Out cross-validation) allow models to be compared by estimating their ability to predict new data. They combine the fit to the observed data with a penalization for model complexity. A lower WAIC or LOO-CV value indicates a better model. WAIC is based on a theoretical approximation, whereas LOO-CV relies on cross-validation. LOO-CV is generally more accurate, especially for complex models or limited sample sizes, but it is also more computationally costly. In practice, when models are well specified and the sample is large, WAIC and LOO-CV often give very similar results for a given model.</p>
<p>Let us return to the linear regression example. We would like to test the hypothesis that the variable <span class="math inline">\(x\)</span> does explain an important part of the variation in <span class="math inline">\(y\)</span>. This amounts to comparing models with and without this variable.</p>
<p>In <code>brms</code>, we fit these two models using weakly informative priors:</p>
<div class="sourceCode" id="cb95"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb95-1"><a href="lms.html#cb95-1" tabindex="-1"></a><span class="co"># Model with covariate</span></span>
<span id="cb95-2"><a href="lms.html#cb95-2" tabindex="-1"></a>fit1 <span class="ot">&lt;-</span> <span class="fu">brm</span>(y <span class="sc">~</span> x, <span class="at">data =</span> data, <span class="at">family =</span> <span class="fu">gaussian</span>(),</span>
<span id="cb95-3"><a href="lms.html#cb95-3" tabindex="-1"></a>            <span class="at">prior =</span> <span class="fu">c</span>(</span>
<span id="cb95-4"><a href="lms.html#cb95-4" tabindex="-1"></a>              <span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">0</span>, <span class="fl">1.5</span>), <span class="at">class =</span> Intercept),</span>
<span id="cb95-5"><a href="lms.html#cb95-5" tabindex="-1"></a>              <span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">0</span>, <span class="fl">1.5</span>), <span class="at">class =</span> b),</span>
<span id="cb95-6"><a href="lms.html#cb95-6" tabindex="-1"></a>              <span class="fu">prior</span>(<span class="fu">exponential</span>(<span class="dv">1</span>), <span class="at">class =</span> sigma)</span>
<span id="cb95-7"><a href="lms.html#cb95-7" tabindex="-1"></a>            ))</span>
<span id="cb95-8"><a href="lms.html#cb95-8" tabindex="-1"></a></span>
<span id="cb95-9"><a href="lms.html#cb95-9" tabindex="-1"></a><span class="co"># Model without covariate</span></span>
<span id="cb95-10"><a href="lms.html#cb95-10" tabindex="-1"></a>fit0 <span class="ot">&lt;-</span> <span class="fu">brm</span>(y <span class="sc">~</span> <span class="dv">1</span>, <span class="at">data =</span> data, <span class="at">family =</span> <span class="fu">gaussian</span>(),</span>
<span id="cb95-11"><a href="lms.html#cb95-11" tabindex="-1"></a>            <span class="at">prior =</span> <span class="fu">c</span>(</span>
<span id="cb95-12"><a href="lms.html#cb95-12" tabindex="-1"></a>              <span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">0</span>, <span class="fl">1.5</span>), <span class="at">class =</span> Intercept),</span>
<span id="cb95-13"><a href="lms.html#cb95-13" tabindex="-1"></a>              <span class="fu">prior</span>(<span class="fu">exponential</span>(<span class="dv">1</span>), <span class="at">class =</span> sigma))</span></code></pre></div>
<p>The function <code><a href="https://mc-stan.org/loo/reference/waic.html">waic()</a></code> can be used to extract the WAIC; the model with the smallest value is preferred. If the model with <span class="math inline">\(x\)</span> is indeed the correct one (which is what we expect since that is how the data were simulated), we should see that it is clearly better than the one without the covariate:</p>
<div class="sourceCode" id="cb96"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Compute WAIC</span></span>
<span><span class="va">waic1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/loo/reference/waic.html">waic</a></span><span class="op">(</span><span class="va">fit1</span><span class="op">)</span></span>
<span><span class="va">waic0</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/loo/reference/waic.html">waic</a></span><span class="op">(</span><span class="va">fit0</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Compare</span></span>
<span><span class="va">waic1</span><span class="op">$</span><span class="va">estimates</span><span class="op">[</span><span class="st">'waic'</span>,<span class="op">]</span></span>
<span><span class="co">#&gt;  Estimate        SE </span></span>
<span><span class="co">#&gt; 172.50456  13.13435</span></span>
<span><span class="va">waic0</span><span class="op">$</span><span class="va">estimates</span><span class="op">[</span><span class="st">'waic'</span>,<span class="op">]</span></span>
<span><span class="co">#&gt;  Estimate        SE </span></span>
<span><span class="co">#&gt; 333.97491  17.23233</span></span></code></pre></div>
<p>Phew, that is indeed the case. The function <code><a href="https://mc-stan.org/loo/reference/loo.html">loo()</a></code> can be used to compute the LOO-CV (an approximation, in fact):</p>
<div class="sourceCode" id="cb97"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Leave-one-out cross-validation</span></span>
<span><span class="va">loo1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/loo/reference/loo.html">loo</a></span><span class="op">(</span><span class="va">fit1</span><span class="op">)</span></span>
<span><span class="va">loo0</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/loo/reference/loo.html">loo</a></span><span class="op">(</span><span class="va">fit0</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Compare</span></span>
<span><span class="fu"><a href="https://mc-stan.org/loo/reference/loo_compare.html">loo_compare</a></span><span class="op">(</span><span class="va">loo0</span>, <span class="va">loo1</span><span class="op">)</span></span>
<span><span class="co">#&gt;      elpd_diff se_diff</span></span>
<span><span class="co">#&gt; fit1   0.0       0.0  </span></span>
<span><span class="co">#&gt; fit0 -80.7       9.1</span></span></code></pre></div>
<p>In this <code>R</code> output, <code>elpd_diff</code> gives the difference in LOO-CV between each model and the one with the largest value. Thus, the best model is on the first line with an elpd_diff equal to zero; here, it is the model with the covariate. We therefore reach the same conclusion as with WAIC.</p>
<p>We can also obtain WAIC values with <code>NIMBLE</code>. To do so, we simply add <code>WAIC = TRUE</code> in the call to the function <code>nimbleMCMC</code>:</p>
<div class="sourceCode" id="cb98"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Code of model with covariate</span></span>
<span><span class="va">model_avec</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/nimble/man/nimbleCode.html">nimbleCode</a></span><span class="op">(</span><span class="op">{</span></span>
<span>  <span class="co"># priors</span></span>
<span>  <span class="va">beta0</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1.5</span><span class="op">)</span></span>
<span>  <span class="va">beta1</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1.5</span><span class="op">)</span></span>
<span>  <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Exponential.html">dexp</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span></span>
<span>  <span class="co"># likelihood</span></span>
<span>  <span class="kw">for</span><span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">n</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">y</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">beta0</span> <span class="op">+</span> <span class="va">beta1</span> <span class="op">*</span> <span class="va">x</span><span class="op">[</span><span class="va">i</span><span class="op">]</span>, sd <span class="op">=</span> <span class="va">sigma</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">}</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Code of model without covariate</span></span>
<span><span class="va">model_sans</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/nimble/man/nimbleCode.html">nimbleCode</a></span><span class="op">(</span><span class="op">{</span></span>
<span>  <span class="co"># priors</span></span>
<span>  <span class="va">beta0</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1.5</span><span class="op">)</span> </span>
<span>  <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Exponential.html">dexp</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span> </span>
<span>  <span class="co"># likelihood</span></span>
<span>  <span class="kw">for</span><span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">n</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">y</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">beta0</span>, sd <span class="op">=</span> <span class="va">sigma</span><span class="op">)</span> </span>
<span>  <span class="op">}</span></span>
<span><span class="op">}</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Data, initial values</span></span>
<span><span class="va">dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">y</span>, n <span class="op">=</span> <span class="va">n</span><span class="op">)</span> <span class="co"># données</span></span>
<span><span class="va">inits_avec</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>beta0 <span class="op">=</span> <span class="op">-</span><span class="fl">0.5</span>, beta1 <span class="op">=</span> <span class="op">-</span><span class="fl">0.5</span>, sigma <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span>, <span class="co"># inits chain 1</span></span>
<span>                   <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>beta0 <span class="op">=</span> <span class="fl">0</span>, beta1 <span class="op">=</span> <span class="fl">0</span>, sigma <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>, <span class="co"># inits chain 2</span></span>
<span>                   <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>beta0 <span class="op">=</span> <span class="fl">0.5</span>, beta1 <span class="op">=</span> <span class="fl">0.5</span>, sigma <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span><span class="op">)</span> <span class="co"># inits chain 3</span></span>
<span><span class="va">inits_sans</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>beta0 <span class="op">=</span> <span class="op">-</span><span class="fl">0.5</span>, sigma <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span>, <span class="co"># inits chain 1</span></span>
<span>                   <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>beta0 <span class="op">=</span> <span class="fl">0</span>, sigma <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>, <span class="co"># inits chain 2</span></span>
<span>                   <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>beta0 <span class="op">=</span> <span class="fl">0.5</span>, sigma <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span><span class="op">)</span> <span class="co"># inits chain 3</span></span>
<span></span>
<span><span class="co"># Model with covariate</span></span>
<span><span class="va">lm.avec</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/nimble/man/nimbleMCMC.html">nimbleMCMC</a></span><span class="op">(</span></span>
<span>  code <span class="op">=</span> <span class="va">model_avec</span>,</span>
<span>  data <span class="op">=</span> <span class="va">dat</span>,</span>
<span>  inits <span class="op">=</span> <span class="va">inits_avec</span>,</span>
<span>  niter <span class="op">=</span> <span class="fl">2000</span>,</span>
<span>  nburnin <span class="op">=</span> <span class="fl">1000</span>,</span>
<span>  nchains <span class="op">=</span> <span class="fl">3</span>,</span>
<span>  WAIC <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="co">#&gt; |-------------|-------------|-------------|-------------|</span></span>
<span><span class="co">#&gt; |-------------------------------------------------------|</span></span>
<span><span class="co">#&gt; |-------------|-------------|-------------|-------------|</span></span>
<span><span class="co">#&gt; |-------------------------------------------------------|</span></span>
<span><span class="co">#&gt; |-------------|-------------|-------------|-------------|</span></span>
<span><span class="co">#&gt; |-------------------------------------------------------|</span></span>
<span></span>
<span><span class="co"># Model without covariate</span></span>
<span><span class="va">lm.sans</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/nimble/man/nimbleMCMC.html">nimbleMCMC</a></span><span class="op">(</span></span>
<span>  code <span class="op">=</span> <span class="va">model_sans</span>,</span>
<span>  data <span class="op">=</span> <span class="va">dat</span>,</span>
<span>  inits <span class="op">=</span> <span class="va">inits_sans</span>,</span>
<span>  niter <span class="op">=</span> <span class="fl">2000</span>,</span>
<span>  nburnin <span class="op">=</span> <span class="fl">1000</span>,</span>
<span>  nchains <span class="op">=</span> <span class="fl">3</span>,</span>
<span>  WAIC <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="co">#&gt; |-------------|-------------|-------------|-------------|</span></span>
<span><span class="co">#&gt; |-------------------------------------------------------|</span></span>
<span><span class="co">#&gt; |-------------|-------------|-------------|-------------|</span></span>
<span><span class="co">#&gt; |-------------------------------------------------------|</span></span>
<span><span class="co">#&gt; |-------------|-------------|-------------|-------------|</span></span>
<span><span class="co">#&gt; |-------------------------------------------------------|</span></span>
<span><span class="co">#&gt;   [Warning] There are 1 individual pWAIC values that are greater than 0.4. This may indicate that the WAIC estimate is unstable (Vehtari et al., 2017), at least in cases without grouping of data nodes or multivariate data nodes.</span></span>
<span></span>
<span><span class="co"># Compute WAIC</span></span>
<span><span class="va">lm.avec</span><span class="op">$</span><span class="va">WAIC</span><span class="op">$</span><span class="va">WAIC</span></span>
<span><span class="co">#&gt; [1] 172.4424</span></span>
<span><span class="va">lm.sans</span><span class="op">$</span><span class="va">WAIC</span><span class="op">$</span><span class="va">WAIC</span></span>
<span><span class="co">#&gt; [1] 333.3443</span></span></code></pre></div>
<p>We reach the same conclusion as with <code>brms</code>. Note that <code>NIMBLE</code> does not directly provide a <code><a href="https://mc-stan.org/loo/reference/loo.html">loo()</a></code> function like <code>brms</code>, even though one could estimate LOO-CV “by hand”.</p>
</div>
<div id="in-summary-2" class="section level2" number="5.5">
<h2>
<span class="header-section-number">5.5</span> In summary<a class="anchor" aria-label="anchor" href="#in-summary-2"><i class="fas fa-link"></i></a>
</h2>
<ul>
<li><p>Linear regression makes it possible to model the relationship between a continuous response variable and one or more explanatory variables, while accounting for residual variability.</p></li>
<li><p>Simulating data from a model is an excellent way to understand how it works and to test your code.</p></li>
<li><p>Weakly informative prior distributions (such as <span class="math inline">\(N(0, 1.5)\)</span> for the coefficients or <span class="math inline">\(\text{Exp}(1)\)</span> for <span class="math inline">\(\sigma\)</span>) help constrain realistic values while still allowing the model the freedom to learn from the data.</p></li>
<li><p>Model validation and comparison can be performed using posterior predictive checks and criteria such as WAIC. These tools make it possible to evaluate model quality with respect to the data and to arbitrate between competing models.</p></li>
</ul>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="prior.html"><span class="header-section-number">4</span> Prior distributions</a></div>
<div class="next"><a href="glms.html"><span class="header-section-number">6</span> Generalized linear models, and generalized linear mixed models</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#lms"><span class="header-section-number">5</span> Regression</a></li>
<li><a class="nav-link" href="#introduction-5"><span class="header-section-number">5.1</span> Introduction</a></li>
<li>
<a class="nav-link" href="#linear-regression"><span class="header-section-number">5.2</span> Linear regression</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#the-model"><span class="header-section-number">5.2.1</span> The model</a></li>
<li><a class="nav-link" href="#simulating-data"><span class="header-section-number">5.2.2</span> Simulating data</a></li>
<li><a class="nav-link" href="#fitting-with-brms"><span class="header-section-number">5.2.3</span> Fitting with brms</a></li>
<li><a class="nav-link" href="#weakly-informative-priors"><span class="header-section-number">5.2.4</span> Weakly informative priors</a></li>
<li><a class="nav-link" href="#fitting-with-nimble"><span class="header-section-number">5.2.5</span> Fitting with NIMBLE</a></li>
<li><a class="nav-link" href="#maximum-likelihood-fitting"><span class="header-section-number">5.2.6</span> Maximum likelihood fitting</a></li>
</ul>
</li>
<li><a class="nav-link" href="#model-evaluation"><span class="header-section-number">5.3</span> Model evaluation</a></li>
<li><a class="nav-link" href="#model-comparison"><span class="header-section-number">5.4</span> Model comparison</a></li>
<li><a class="nav-link" href="#in-summary-2"><span class="header-section-number">5.5</span> In summary</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/oliviergimenez/introduction-to-bayesian-statistics-with-R/blob/master/05-regression.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/oliviergimenez/introduction-to-bayesian-statistics-with-R/edit/master/05-regression.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Introduction to Bayesian Statistics with R</strong> using NIMBLE and brms" was written by Olivier Gimenez. Last updated 2026-02-24.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built with the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
