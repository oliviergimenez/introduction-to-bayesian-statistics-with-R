<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 5 La régression | Introduction to Bayesian Statistics with R</title>
<meta name="author" content="Olivier Gimenez">
<meta name="description" content="5.1 Introduction Ce chapitre présente l’application de la statistique bayésienne à la régression linéaire. On prendra un exemple qui nous permettra d’aller un peu plus loin que notre exemple fil...">
<meta name="generator" content="bookdown 0.43 with bs4_book()">
<meta property="og:title" content="Chapter 5 La régression | Introduction to Bayesian Statistics with R">
<meta property="og:type" content="book">
<meta property="og:url" content="https://oliviergimenez.github.io/introduction-to-bayesian-statistics-with-R/lms.html">
<meta property="og:description" content="5.1 Introduction Ce chapitre présente l’application de la statistique bayésienne à la régression linéaire. On prendra un exemple qui nous permettra d’aller un peu plus loin que notre exemple fil...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 5 La régression | Introduction to Bayesian Statistics with R">
<meta name="twitter:description" content="5.1 Introduction Ce chapitre présente l’application de la statistique bayésienne à la régression linéaire. On prendra un exemple qui nous permettra d’aller un peu plus loin que notre exemple fil...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><link href="libs/Roboto-0.4.10/font.css" rel="stylesheet">
<script src="libs/bs3compat-0.9.0/transition.js"></script><script src="libs/bs3compat-0.9.0/tabs.js"></script><script src="libs/bs3compat-0.9.0/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><!-- Google tag (gtag.js) --><script async src="https://www.googletagmanager.com/gtag/js?id=G-MTKSQWQE5K"></script><script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-MTKSQWQE5K');
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
          margin-bottom: 0em;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
<link rel="stylesheet" href="style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="Using NIMBLE and brms">Introduction to Bayesian Statistics with R</a>:
        <small class="text-muted">Using NIMBLE and brms</small>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Introduction</a></li>
<li><a class="" href="principes.html"><span class="header-section-number">1</span> The Bayesian approach</a></li>
<li><a class="" href="mcmc.html"><span class="header-section-number">2</span> MCMC methods</a></li>
<li><a class="" href="logiciels.html"><span class="header-section-number">3</span> Practical implementation</a></li>
<li><a class="" href="prior.html"><span class="header-section-number">4</span> Prior distributions</a></li>
<li><a class="active" href="lms.html"><span class="header-section-number">5</span> La régression</a></li>
<li><a class="" href="glms.html"><span class="header-section-number">6</span> Modèles linéaires généralisés, et généralisés mixtes</a></li>
<li><a class="" href="conclusions.html">Conclusions</a></li>
<li><a class="" href="r%C3%A9f%C3%A9rences.html">Références</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/oliviergimenez/introduction-to-bayesian-statistics-with-R">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="lms" class="section level1" number="5">
<h1>
<span class="header-section-number">5</span> La régression<a class="anchor" aria-label="anchor" href="#lms"><i class="fas fa-link"></i></a>
</h1>
<div id="introduction-5" class="section level2" number="5.1">
<h2>
<span class="header-section-number">5.1</span> Introduction<a class="anchor" aria-label="anchor" href="#introduction-5"><i class="fas fa-link"></i></a>
</h2>
<p>Ce chapitre présente l’application de la statistique bayésienne à la régression linéaire. On prendra un exemple qui nous permettra d’aller un peu plus loin que notre exemple fil rouge sur la survie. Ce sera l’occasion d’aborder comment et pourquoi utiliser un modèle pour simuler des données. Nous en profiterons pour illustrer la comparaison et la validation des modèles. Nous utiliserons <code>NIMBLE</code> et <code>brms</code> et comparerons avec l’approche fréquentiste.</p>
</div>
<div id="la-régression-linéaire" class="section level2" number="5.2">
<h2>
<span class="header-section-number">5.2</span> La régression linéaire<a class="anchor" aria-label="anchor" href="#la-r%C3%A9gression-lin%C3%A9aire"><i class="fas fa-link"></i></a>
</h2>
<div id="le-modèle" class="section level3" number="5.2.1">
<h3>
<span class="header-section-number">5.2.1</span> Le modèle<a class="anchor" aria-label="anchor" href="#le-mod%C3%A8le"><i class="fas fa-link"></i></a>
</h3>
<p>Pour changer un peu, je vous propose d’utiliser <code>NIMBLE</code> et <code>brms</code> sur un exemple différent de celui de l’estimation de la survie. Attardons-nous sur la régression linéaire.</p>
<p>Commençons par poser les bases de notre modèle linéaire. On a <span class="math inline">\(n\)</span> mesures d’une variable réponse <span class="math inline">\(y_i\)</span> avec <span class="math inline">\(i\)</span> qui varie de 1 à <span class="math inline">\(n\)</span>. Pensez par exemple à la masse (en kilogrammes) de nos ragondins dans l’exemple fil rouge. On associe chaque mesure à une variable explicative <span class="math inline">\(x_i\)</span>, par exemple la température extérieure moyenne en hiver (en degrés Celsius) pour nos ragondins. On cherche à étudier l’effet de la température sur la masse. Le plus simple est de supposer une relation linéaire entre les deux, on utilise donc un modèle de régression linéaire. Le modèle comporte une ordonnée à l’origine (ou intercept) <span class="math inline">\(\beta_0\)</span>, et une pente <span class="math inline">\(\beta_1\)</span> qui décrit l’effet de <span class="math inline">\(x_i\)</span> sur <span class="math inline">\(y_i\)</span>, ou de la température sur la masse des ragondins. On a aussi besoin d’un paramètre pour décrire la variabilité résiduelle représentée par un paramètre de variance <span class="math inline">\(\sigma^2\)</span>, qui capte la part de variation dans les <span class="math inline">\(y_i\)</span> non expliquée par les <span class="math inline">\(x_i\)</span>. Vous avez probablement déjà rencontré ce modèle sous la forme : <span class="math inline">\(y_i = \beta_0 + \beta_1 x_i + \varepsilon_i\)</span> où les erreurs <span class="math inline">\(\varepsilon_i\)</span> sont supposées indépendantes et distribuées selon une loi normale de moyenne 0 et de variance <span class="math inline">\(\sigma^2\)</span>.</p>
<p>L’intercept <span class="math inline">\(\beta_0\)</span> nous donne la masse quand la température est de 0 degré (<span class="math inline">\(x_i = 0\)</span>). Le paramètre <span class="math inline">\(\beta_1\)</span> nous renseigne sur le changement dans la variable réponse pour une augmentation d’une unité (ici 1 degré Celsius) de la variable explicative (d’où le terme “pente” pour désigner ce paramètre). En général, on conseille (fortement) de centrer (soustraire la moyenne) et réduire (diviser par l’écart-type) les valeurs de la variable explicative pour des questions numériques et d’interprétation. Numérique d’abord car cela permet aux algorithmes, qu’ils soient fréquentistes ou bayésiens, de ne pas se perdre dans des recoins de l’espace du paramètre. Interprétation ensuite, car on interprète alors l’intercept <span class="math inline">\(\beta_0\)</span> comme la valeur de la variable réponse pour une valeur moyenne de la variable explicative.</p>
<p>Dans cette section, plutôt que d’analyser de “vraies” données, nous allons, à partir des paramètres <span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span> et <span class="math inline">\(\sigma\)</span>, simuler des données artificielles, comme si elles provenaient d’un vrai processus sous-jacent.</p>
<!-- Cette étape est très utile pour vérifier que notre modèle est capable de retrouver les paramètres utilisés — un bon réflexe à adopter avant d’analyser des données réelles. -->
</div>
<div id="simuler-des-données" class="section level3" number="5.2.2">
<h3>
<span class="header-section-number">5.2.2</span> Simuler des données<a class="anchor" aria-label="anchor" href="#simuler-des-donn%C3%A9es"><i class="fas fa-link"></i></a>
</h3>
<p>Qu’est-ce que j’entends par simuler des données ? L’analyse et la simulation des données sont deux faces d’un même modèle. Dans l’analyse, on utilise les données pour estimer les paramètres d’un modèle. Dans la simulation, on fixe les paramètres et on utilise le modèle pour générer des données. Une raison d’utiliser les simulations est que cette gymnastique va nous obliger à bien comprendre le modèle ; si je n’arrive pas à simuler des données à partir d’un modèle, c’est que je n’ai pas complètement compris comment il marchait. Il y a des tas d’autres bonnes raisons pour utiliser les simulations. Comme la vérité (les paramètres et le modèle) est connue, on peut vérifier que le modèle est bien codé. On peut évaluer le biais et la précision des estimations de nos paramètres, évaluer les effets de ne pas respecter les hypothèses du modèle, planifier un protocole de récolte de données ou encore évaluer la puissance d’un test statistique. Bref, c’est une technique très utile à avoir dans votre boîte à outils !</p>
<p>Revenons à notre exemple. Pour simuler des données selon le modèle de régression linéaire, on commence par fixer nos paramètres : <span class="math inline">\(\beta_0 = 0.1\)</span>, <span class="math inline">\(\beta_1 = 1\)</span> et <span class="math inline">\(\sigma^2 = 0.5\)</span> :</p>
<div class="sourceCode" id="cb69"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">beta0</span> <span class="op">&lt;-</span> <span class="fl">0.1</span> <span class="co"># valeur vraie de l'intercept</span></span>
<span><span class="va">beta1</span> <span class="op">&lt;-</span> <span class="fl">1</span> <span class="co"># valeur vraie du coefficient de x</span></span>
<span><span class="va">sigma</span> <span class="op">&lt;-</span> <span class="fl">0.5</span> <span class="co"># écart-type des erreurs</span></span></code></pre></div>
<p>Puis on simule <span class="math inline">\(n = 100\)</span> valeurs <span class="math inline">\(x_i\)</span> de notre variable explicative selon une loi normale de moyenne 0 et d’écart-type 1, autrement dit <span class="math inline">\(N(0,1)\)</span> :</p>
<div class="sourceCode" id="cb70"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">666</span><span class="op">)</span> <span class="co"># pour rendre la simulation reproductible</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">100</span> <span class="co"># nombre d'observations</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">n</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1</span><span class="op">)</span> <span class="co"># covariable x simulée selon une loi normale standard</span></span></code></pre></div>
<p>Enfin, on simule les valeurs de la variable réponse, en ajoutant une erreur normale <code>epsilon</code> à la relation linéaire <code>beta0 + beta1 * x</code> :</p>
<div class="sourceCode" id="cb71"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">epsilon</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="va">sigma</span><span class="op">)</span> <span class="co"># génère les erreurs normales</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="va">beta0</span> <span class="op">+</span> <span class="va">beta1</span> <span class="op">*</span> <span class="va">x</span> <span class="op">+</span> <span class="va">epsilon</span> <span class="co"># ajoute les erreurs à la relation linéaire</span></span>
<span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>y <span class="op">=</span> <span class="va">y</span>, x <span class="op">=</span> <span class="va">x</span><span class="op">)</span></span></code></pre></div>
La Figure <a href="lms.html#fig:donnees-simulees">5.1</a> ci-dessous montre les données simulées, ainsi que la droite de régression correspondant au modèle utilisé pour les générer :
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:donnees-simulees"></span>
<img src="05-regression_files/figure-html/donnees-simulees-1.png" alt="Données simulées (n = 100) selon le modèle \(y_i = \beta_0 + \beta_1 x_i + \varepsilon_i\), avec \(\beta_0 = 0.1\), \(\beta_1 = 1\) et \(\sigma = 1\). La droite rouge correspond à la droite de régression." width="90%"><p class="caption">
Figure 5.1: Données simulées (n = 100) selon le modèle <span class="math inline">\(y_i = \beta_0 + \beta_1 x_i + \varepsilon_i\)</span>, avec <span class="math inline">\(\beta_0 = 0.1\)</span>, <span class="math inline">\(\beta_1 = 1\)</span> et <span class="math inline">\(\sigma = 1\)</span>. La droite rouge correspond à la droite de régression.
</p>
</div>
</div>
<div id="lajustement-avec-brms" class="section level3" number="5.2.3">
<h3>
<span class="header-section-number">5.2.3</span> L’ajustement avec <code>brms</code><a class="anchor" aria-label="anchor" href="#lajustement-avec-brms"><i class="fas fa-link"></i></a>
</h3>
<p>Dans cette section, on utilise <code>brms</code> pour ajuster le modèle de régression linéaire aux données qu’on vient de générer. Si tout se passe bien, les paramètres estimés devraient être proches des valeurs utilisées pour générer les données. Je vais relativement vite ici puisqu’on a couvert les différentes étapes au Chapitre <a href="logiciels.html#logiciels">3</a>. La syntaxe est très proche de celle qu’on utiliserait pour ajuster le modèle par maximum de vraisemblance avec la fonction <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code> dans <code>R</code> :</p>
<div class="sourceCode" id="cb72"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">lm.brms</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://paulbuerkner.com/brms/reference/brm.html">brm</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">x</span>, <span class="co"># formule : y en fonction de x</span></span>
<span>               data <span class="op">=</span> <span class="va">data</span>, <span class="co"># jeu de données</span></span>
<span>               family <span class="op">=</span> <span class="va">gaussian</span><span class="op">)</span> <span class="co"># distribution normale</span></span></code></pre></div>
<p>Jetons un coup d’oeil aux résumés numériques et aux diagnostics de convergence :</p>
<div class="sourceCode" id="cb73"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">lm.brms</span><span class="op">)</span></span>
<span><span class="co">#&gt;  Family: gaussian </span></span>
<span><span class="co">#&gt;   Links: mu = identity; sigma = identity </span></span>
<span><span class="co">#&gt; Formula: y ~ x </span></span>
<span><span class="co">#&gt;    Data: data (Number of observations: 100) </span></span>
<span><span class="co">#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;</span></span>
<span><span class="co">#&gt;          total post-warmup draws = 4000</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Regression Coefficients:</span></span>
<span><span class="co">#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS</span></span>
<span><span class="co">#&gt; Intercept     0.06      0.06    -0.05     0.17 1.00     4366     3028</span></span>
<span><span class="co">#&gt; x             1.10      0.06     0.99     1.21 1.00     4188     3147</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Further Distributional Parameters:</span></span>
<span><span class="co">#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS</span></span>
<span><span class="co">#&gt; sigma     0.57      0.04     0.49     0.65 1.00     4090     3050</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS</span></span>
<span><span class="co">#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential</span></span>
<span><span class="co">#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).</span></span></code></pre></div>
<p>Par défaut, <code>brms</code> a utilisé quatre chaînes qui ont tourné pendant 2000 itérations chacune avec 1000 itérations utilisées comme burn-in, soit au total 4000 itérations pour l’inférence a posteriori. Dans les sorties, <code>Intercept</code>, <code>x</code> et <code>sigma</code> correspondent respectivement aux paramètres <span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span> et <span class="math inline">\(\sigma\)</span> du modèle. Le <span class="math inline">\(\hat{R}\)</span> pour les 3 paramètres vaut 1, et les tailles d’échantillon efficaces sont satisfaisantes. Les intervalles de crédibilité contiennent la vraie valeur du paramètre utilisée pour simuler les données.</p>
<p>On vérifie que le mixing est bon (Figure <a href="lms.html#fig:fig-posterior-regression">5.2</a>) :</p>
<div class="sourceCode" id="cb74"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">lm.brms</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:fig-posterior-regression"></span>
<img src="05-regression_files/figure-html/fig-posterior-regression-1.png" alt="Histogrammes des distributions a posteriori (colonne de gauche) et traces (colonne de droite) des paramètres de la régression linéaire. Dans les histogrammes, l’axe des abscisses représente les valeurs possibles du paramètre estimé (intercept, pente ou écart-type) et l’axe des ordonnées correspond à leur fréquence dans l’échantillon a posteriori. Dans les trace plots, l’axe des abscisses indique le numéro d’itération du MCMC, tandis que l’axe des ordonnées représente la valeur simulée du paramètre à chaque itération." width="90%"><p class="caption">
Figure 5.2: Histogrammes des distributions a posteriori (colonne de gauche) et traces (colonne de droite) des paramètres de la régression linéaire. Dans les histogrammes, l’axe des abscisses représente les valeurs possibles du paramètre estimé (intercept, pente ou écart-type) et l’axe des ordonnées correspond à leur fréquence dans l’échantillon a posteriori. Dans les trace plots, l’axe des abscisses indique le numéro d’itération du MCMC, tandis que l’axe des ordonnées représente la valeur simulée du paramètre à chaque itération.
</p>
</div>
</div>
<div id="weakly-informative-priors" class="section level3" number="5.2.4">
<h3>
<span class="header-section-number">5.2.4</span> Des priors faiblement informatifs<a class="anchor" aria-label="anchor" href="#weakly-informative-priors"><i class="fas fa-link"></i></a>
</h3>
<p>Plutôt que d’utiliser les priors par défaut de <code>brms</code>, choisissons d’autres priors. Nous allons utiliser des priors faiblement informatifs, et plus spécifiquement une normale avec moyenne 0 et écart-type 1.5 ou <span class="math inline">\(N(0,1.5)\)</span> pour les paramètres de régression <span class="math inline">\(\beta_0\)</span> et <span class="math inline">\(\beta_1\)</span>. On a déjà parlé des priors faiblement informatifs au Chapitre <a href="prior.html#prior">4</a>. L’idée est proche de celle des priors vagues ou non-informatifs, dans le sens où l’on s’efforce de refléter via les priors faiblement informatifs le fait qu’on n’a pas vraiment d’information sur les paramètres du modèle. La différence est que les priors non-informatifs peuvent induire des valeurs aberrantes comme on l’a vu au Chapitre <a href="prior.html#prior">4</a>. C’est encore le cas ici. Prenez par exemple des <span class="math inline">\(N(0,100)\)</span> pour les paramètres de la relation linéaire qui lie la masse des ragondins à la température, et simulez tout un tas de valeurs dans ces priors, puis formez la relation linéaire :</p>
<div class="sourceCode" id="cb75"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="co"># nombre de droites à simuler</span></span>
<span><span class="va">n_lines</span> <span class="op">&lt;-</span> <span class="fl">100</span></span>
<span></span>
<span><span class="co"># tirages des intercepts et pentes selon les priors</span></span>
<span><span class="va">intercepts</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n_lines</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">100</span><span class="op">)</span></span>
<span><span class="va">slopes</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n_lines</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">100</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># création d'un data frame</span></span>
<span><span class="va">lines_df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">n_lines</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">y_vals</span> <span class="op">&lt;-</span> <span class="va">intercepts</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">+</span> <span class="va">slopes</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">*</span> <span class="va">x</span></span>
<span>  <span class="va">temp_df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">y_vals</span>, line <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">as.factor</a></span><span class="op">(</span><span class="va">i</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="va">lines_df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">rbind</a></span><span class="op">(</span><span class="va">lines_df</span>, <span class="va">temp_df</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># tracé avec ggplot2</span></span>
<span><span class="fu">ggplot</span><span class="op">(</span><span class="va">lines_df</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">y</span>, group <span class="op">=</span> <span class="va">line</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_line</span><span class="op">(</span>alpha <span class="op">=</span> <span class="fl">0.3</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme_minimal</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span>x <span class="op">=</span> <span class="st">"x"</span>, y <span class="op">=</span> <span class="st">"y"</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:fig-prior-regression-vague"></span>
<img src="05-regression_files/figure-html/fig-prior-regression-vague-1.png" alt="Simulation de droites de régression issues des distributions a priori. Chaque ligne correspond à un tirage des paramètres : intercept et pente ~ N(0, 100)." width="90%"><p class="caption">
Figure 5.3: Simulation de droites de régression issues des distributions a priori. Chaque ligne correspond à un tirage des paramètres : intercept et pente ~ N(0, 100).
</p>
</div>
On voit dans la Figure <a href="lms.html#fig:fig-prior-regression-vague">5.3</a> qu’on obtient des valeurs aberrantes pour les <span class="math inline">\(y_i\)</span>, avec des ragondins de plus de 400 kilogrammes, et des valeurs (très) négatives pour la masse. On vient de faire un “prior predictive check”, comme au Chapitre <a href="prior.html#prior">4</a>. Dans la Figure <a href="lms.html#fig:fig-prior-regression">5.4</a>, on fait la même chose avec notre prior faiblement informatif <span class="math inline">\(N(0,1.5)\)</span> :
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:fig-prior-regression"></span>
<img src="05-regression_files/figure-html/fig-prior-regression-1.png" alt="Simulation de droites de régression issues des distributions a priori. Chaque ligne correspond à un tirage des paramètres : intercept et pente ~ N(0, 1.5)." width="90%"><p class="caption">
Figure 5.4: Simulation de droites de régression issues des distributions a priori. Chaque ligne correspond à un tirage des paramètres : intercept et pente ~ N(0, 1.5).
</p>
</div>
<p>On obtient des valeurs plus raisonnables pour la masse des ragondins qui dépassent rarement 10 kilogrammes. On a toujours des valeurs négatives, mais moindres, l’algorithme MCMC devrait s’en sortir. Il y a aussi un avantage numérique à utiliser des priors faiblement informatifs, ils aident les méthodes MCMC à ne pas se perdre dans l’espace de toutes les valeurs possibles pour les paramètres à estimer, et leur permettent de se focaliser sur les valeurs réalistes de ces paramètres. En faisant ça, vous avez peut-être l’impression qu’on utilise les données pour construire les priors, alors qu’on a dit que le prior devait refléter l’information disponible avant de voir les données. C’est l’occasion de préciser un peu ce point. L’important est surtout que le prior représente l’information indépendante des données qui sont utilisées dans la vraisemblance.</p>
<p>On s’est jusqu’ici concentrés sur les paramètres de régression, l’intercept <span class="math inline">\(\beta_0\)</span> et la pente <span class="math inline">\(\beta_1\)</span>. Mais qu’en est-il de l’écart-type, <span class="math inline">\(\sigma\)</span> ? Ce paramètre est tout aussi important : il reflète à quel point les observations s’écartent de la tendance moyenne décrite par la droite de régression.</p>
<p>Une option souvent envisagée est de lui attribuer une loi uniforme, par exemple <span class="math inline">\(\sigma \sim U(0, B)\)</span>, avec une borne inférieure naturelle (0, puisque <span class="math inline">\(\sigma\)</span> est toujours positive), mais une borne supérieure <span class="math inline">\(B\)</span> difficile à choisir. Quelle valeur maximale donner à un écart-type ? Dans certains cas, une valeur apparemment raisonnable peut se révéler trop large. Par exemple, si l’on modélise des tailles humaines et que l’on fixe <span class="math inline">\(\sigma \sim U(0, 50)\)</span> (en cm), cela revient à supposer que 95% des tailles sont réparties sur une plage de 100 cm autour de la moyenne – ce qui est très improbable.</p>
<p>Une alternative plus souple et plus réaliste consiste à utiliser une loi exponentielle <span class="math inline">\(\sigma \sim \exp(\lambda)\)</span> où <span class="math inline">\(\lambda &gt; 0\)</span> est un paramètre de taux. Cette loi est définie uniquement pour des valeurs positives, ce qui est cohérent avec la nature de <span class="math inline">\(\sigma\)</span>, et elle favorise les petites valeurs d’écart-type tout en laissant la possibilité à <span class="math inline">\(\sigma\)</span> d’être plus grande si les données le justifient.</p>
<p>Par défaut, on prend souvent <span class="math inline">\(\lambda = 1\)</span>. Avec <span class="math inline">\(\lambda = 1\)</span>, la moyenne et l’écart-type de cette loi sont tous deux égaux à <span class="math inline">\(1\)</span>, ce qui induit une loi a priori modeste mais non restrictive (Figure <a href="lms.html#fig:fig-prior-sigma">5.5</a>).</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:fig-prior-sigma"></span>
<img src="05-regression_files/figure-html/fig-prior-sigma-1.png" alt="Comparaison entre deux lois a priori pour l’écart-type \(\sigma\) : une loi uniforme \(\text{U}(0,5)\), qui donne la même densité entre 0 et 5, et une loi exponentielle \(\text{Exp}(1)\), qui favorise les petites valeurs tout en conservant une queue plus lourde." width="90%"><p class="caption">
Figure 5.5: Comparaison entre deux lois a priori pour l’écart-type <span class="math inline">\(\sigma\)</span> : une loi uniforme <span class="math inline">\(\text{U}(0,5)\)</span>, qui donne la même densité entre 0 et 5, et une loi exponentielle <span class="math inline">\(\text{Exp}(1)\)</span>, qui favorise les petites valeurs tout en conservant une queue plus lourde.
</p>
</div>
<p>On peut formaliser ce modèle comme suit :
<span class="math display">\[\begin{align}
y_i &amp;\sim \text{Normale}(\mu_i, \sigma^2) &amp;\text{[vraisemblance]}\\
\mu_i &amp;= \beta_0 + \beta_1 \; x_i &amp;\text{[relation linéaire]}\\
\beta_0, \beta_1 &amp;\sim \text{Normale}(0, 1.5) &amp;\text{[prior sur les paramètres]} \\
\sigma &amp;\sim \text{Exp}(1) &amp;\text{[prior sur les paramètres]} \\
\end{align}\]</span></p>
<p>Spécifions ces priors :</p>
<div class="sourceCode" id="cb76"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">myprior</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://paulbuerkner.com/brms/reference/set_prior.html">prior</a></span><span class="op">(</span><span class="fu">normal</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1.5</span><span class="op">)</span>, class <span class="op">=</span> <span class="va">b</span><span class="op">)</span>, <span class="co"># prior sur le coefficient de x</span></span>
<span>  <span class="fu"><a href="https://paulbuerkner.com/brms/reference/set_prior.html">prior</a></span><span class="op">(</span><span class="fu">normal</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1.5</span><span class="op">)</span>, class <span class="op">=</span> <span class="va">Intercept</span><span class="op">)</span>, <span class="co"># prior sur l'intercept</span></span>
<span>  <span class="fu"><a href="https://paulbuerkner.com/brms/reference/set_prior.html">prior</a></span><span class="op">(</span><span class="fu"><a href="https://paulbuerkner.com/brms/reference/brmsfamily.html">exponential</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span>, class <span class="op">=</span> <span class="va">sigma</span><span class="op">)</span> <span class="co"># prior sur l'écart-type de l'erreur</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>Puis refaisons l’ajustement avec <code>brms</code> :</p>
<div class="sourceCode" id="cb77"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">lm.brms</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://paulbuerkner.com/brms/reference/brm.html">brm</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">x</span>, </span>
<span>               data <span class="op">=</span> <span class="va">data</span>, </span>
<span>               family <span class="op">=</span> <span class="va">gaussian</span>, </span>
<span>               prior <span class="op">=</span> <span class="va">myprior</span><span class="op">)</span></span></code></pre></div>
<p>On vérifie que les résumés numériques obtenus sont proches de ceux obtenus avec les priors par défaut, et surtout des valeurs utilisées pour simuler les données :</p>
<div class="sourceCode" id="cb78"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">lm.brms</span><span class="op">)</span></span>
<span><span class="co">#&gt;  Family: gaussian </span></span>
<span><span class="co">#&gt;   Links: mu = identity; sigma = identity </span></span>
<span><span class="co">#&gt; Formula: y ~ x </span></span>
<span><span class="co">#&gt;    Data: data (Number of observations: 100) </span></span>
<span><span class="co">#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;</span></span>
<span><span class="co">#&gt;          total post-warmup draws = 4000</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Regression Coefficients:</span></span>
<span><span class="co">#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS</span></span>
<span><span class="co">#&gt; Intercept     0.06      0.06    -0.05     0.18 1.00     3562     2765</span></span>
<span><span class="co">#&gt; x             1.10      0.06     0.99     1.21 1.00     3870     2731</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Further Distributional Parameters:</span></span>
<span><span class="co">#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS</span></span>
<span><span class="co">#&gt; sigma     0.57      0.04     0.49     0.66 1.00     3540     2633</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS</span></span>
<span><span class="co">#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential</span></span>
<span><span class="co">#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).</span></span></code></pre></div>
<p>Ici, les deux modèles donnent quasiment la même chose, ce qui n’a rien de surprenant car les données sont suffisamment informatives pour qu’elles “prennent le dessus sur” le prior. L’intérêt des priors faiblement informatifs ne se voit pas tant dans ce petit exemple que dans d’autres situations : ils évitent les valeurs aberrantes, stabilisent les calculs MCMC et restent utiles quand on a moins de données ou des modèles plus complexes.</p>
</div>
<div id="lajustement-avec-nimble" class="section level3" number="5.2.5">
<h3>
<span class="header-section-number">5.2.5</span> L’ajustement avec <code>NIMBLE</code><a class="anchor" aria-label="anchor" href="#lajustement-avec-nimble"><i class="fas fa-link"></i></a>
</h3>
<p>On commence par écrire le modèle :</p>
<div class="sourceCode" id="cb79"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/nimble/man/nimbleCode.html">nimbleCode</a></span><span class="op">(</span><span class="op">{</span></span>
<span>  <span class="co"># les priors</span></span>
<span>  <span class="va">beta0</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1.5</span><span class="op">)</span> <span class="co"># prior normal sur l'intercept</span></span>
<span>  <span class="va">beta1</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1.5</span><span class="op">)</span> <span class="co"># prior normal sur le coefficient</span></span>
<span>  <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Exponential.html">dexp</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span> <span class="co"># prior exponentiel sur l'écart-type</span></span>
<span>  <span class="co"># la vraisemblance</span></span>
<span>  <span class="kw">for</span><span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">n</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">y</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">beta0</span> <span class="op">+</span> <span class="va">beta1</span> <span class="op">*</span> <span class="va">x</span><span class="op">[</span><span class="va">i</span><span class="op">]</span>, sd <span class="op">=</span> <span class="va">sigma</span><span class="op">)</span> <span class="co"># equiv de yi = beta0 + beta1 * xi + epsiloni</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">}</span><span class="op">)</span></span></code></pre></div>
<p>Dans ce bloc de code, on commence par spécifier des priors sur les trois paramètres du modèle : un prior normal centré en 0 avec un écart-type de 1.5 pour l’intercept <span class="math inline">\(\beta_0\)</span> et pour la pente <span class="math inline">\(\beta_1\)</span>, ainsi qu’un prior exponentiel pour l’écart-type <span class="math inline">\(\sigma\)</span> des erreurs. La partie suivante est une boucle <code>for(i in 1:n)</code> qui définit la vraisemblance. On spécifie la vraisemblance observation par observation, <code>NIMBLE</code> en déduit automatiquement le produit des vraisemblances sur tous les individus, ce qui correspond à la vraisemblance du jeu de données. Pour chaque observation <span class="math inline">\(i\)</span>, on a une distribution normale centrée en <code>beta0 + beta1 * x[i]</code>, avec un écart-type <code>sigma</code>. On retrouve la relation <span class="math inline">\(y_i = \beta_0 + \beta_1 x_i + \varepsilon_i\)</span> où <span class="math inline">\(\varepsilon_i \sim N(0,\sigma^2)\)</span> qui est strictement équivalente à <span class="math inline">\(y_i \sim N(\beta_0 + \beta_1 x_i,\sigma^2)\)</span>.</p>
<p>Les étapes suivantes consistent à mettre les données dans une liste, spécifier les valeurs initiales, et préciser les paramètres pour lesquels on souhaite des sorties :</p>
<div class="sourceCode" id="cb80"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">y</span>, n <span class="op">=</span> <span class="va">n</span><span class="op">)</span> <span class="co"># données</span></span>
<span><span class="va">inits</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>beta0 <span class="op">=</span> <span class="op">-</span><span class="fl">0.5</span>, beta1 <span class="op">=</span> <span class="op">-</span><span class="fl">0.5</span>, sigma <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span>, <span class="co"># valeurs initiales chaine 1</span></span>
<span>              <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>beta0 <span class="op">=</span> <span class="fl">0</span>, beta1 <span class="op">=</span> <span class="fl">0</span>, sigma <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>, <span class="co"># valeurs initiales chaine 2</span></span>
<span>              <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>beta0 <span class="op">=</span> <span class="fl">0.5</span>, beta1 <span class="op">=</span> <span class="fl">0.5</span>, sigma <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span><span class="op">)</span> <span class="co"># valeurs initiales chaine 3</span></span>
<span><span class="va">par</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"beta0"</span>, <span class="st">"beta1"</span>, <span class="st">"sigma"</span><span class="op">)</span></span></code></pre></div>
<p>On a alors tous les ingrédients pour lancer <code>NIMBLE</code> :</p>
<div class="sourceCode" id="cb81"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">lm.nimble</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/nimble/man/nimbleMCMC.html">nimbleMCMC</a></span><span class="op">(</span></span>
<span>  code <span class="op">=</span> <span class="va">model</span>,</span>
<span>  data <span class="op">=</span> <span class="va">dat</span>,</span>
<span>  inits <span class="op">=</span> <span class="va">inits</span>,</span>
<span>  monitors <span class="op">=</span> <span class="va">par</span>,</span>
<span>  niter <span class="op">=</span> <span class="fl">2000</span>,</span>
<span>  nburnin <span class="op">=</span> <span class="fl">1000</span>,</span>
<span>  nchains <span class="op">=</span> <span class="fl">3</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>Inspectons les résultats :</p>
<div class="sourceCode" id="cb82"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/MCMCvis/man/MCMCsummary.html">MCMCsummary</a></span><span class="op">(</span><span class="va">lm.nimble</span>, round <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="co">#&gt;       mean   sd  2.5%  50% 97.5% Rhat n.eff</span></span>
<span><span class="co">#&gt; beta0 0.06 0.06 -0.05 0.06  0.17 1.00  3000</span></span>
<span><span class="co">#&gt; beta1 1.10 0.06  0.99 1.10  1.21 1.00  3000</span></span>
<span><span class="co">#&gt; sigma 0.57 0.04  0.49 0.56  0.65 1.01   772</span></span></code></pre></div>
<p>On retrouve des résumés numériques proches de ceux obtenus avec <code>brms</code>, et proches des vraies valeurs des paramètres utilisés pour simuler les données.</p>
<p>Concernant la convergence, on peut inspecter les trace plots :</p>
<div class="sourceCode" id="cb83"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/MCMCvis/man/MCMCtrace.html">MCMCtrace</a></span><span class="op">(</span>object <span class="op">=</span> <span class="va">lm.nimble</span>,</span>
<span>          pdf <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>          ind <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>          Rhat <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>          n.eff <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="05-regression_files/figure-html/unnamed-chunk-19-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>Tout va bien. Le mélange est correct, les diagnostics de convergence sont au vert.</p>
</div>
<div id="lajustement-par-maximum-de-vraisemblance" class="section level3" number="5.2.6">
<h3>
<span class="header-section-number">5.2.6</span> L’ajustement par maximum de vraisemblance<a class="anchor" aria-label="anchor" href="#lajustement-par-maximum-de-vraisemblance"><i class="fas fa-link"></i></a>
</h3>
<p>Et pour finir, on peut comparer avec l’ajustement par maximum de vraisemblance qu’on obtient simplement avec la commande <code>lm(y ~ x, data = data)</code>, tout est dans la Figure <a href="lms.html#fig:comparaison-methodes">5.6</a> :</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:comparaison-methodes"></span>
<img src="05-regression_files/figure-html/comparaison-methodes-1.png" alt="Comparaison des estimations des paramètres du modèle (intercept ou ordonnée à l'origine et pente) selon les différentes méthodes (brms, lm et NIMBLE). Les points donnent les moyennes a posteriori pour brms et NIMBLE, et l'estimation du maximum de vraisemblance pour lm. On donne également les intervalles de crédibilité (pour brms et NIMBLE) et de confiance (pour lm) à 95%. La ligne en tirets noirs indique la vraie valeur utilisée pour simuler les données." width="90%"><p class="caption">
Figure 5.6: Comparaison des estimations des paramètres du modèle (intercept ou ordonnée à l’origine et pente) selon les différentes méthodes (brms, lm et NIMBLE). Les points donnent les moyennes a posteriori pour brms et NIMBLE, et l’estimation du maximum de vraisemblance pour lm. On donne également les intervalles de crédibilité (pour brms et NIMBLE) et de confiance (pour lm) à 95%. La ligne en tirets noirs indique la vraie valeur utilisée pour simuler les données.
</p>
</div>
<p>Les moyennes a posteriori obtenues avec <code>NIMBLE</code> et <code>brms</code> sont proches des estimations par maximum de vraisemblance pour l’incercept et la pente, dans une moindre mesure. Les intervalles de crédibilité obtenus avec <code>NIMBLE</code> et <code>brms</code> et l’intervalle de confiance obtenu par maximum de vraisemblance englobent tous les vraies valeurs des paramètres qui ont servi à simuler les données. Gardez à l’esprit qu’il s’agit d’une seule simulation, il faudrait répéter l’exercice un grand nombre de fois pour évaluer formellement la distance entre les vraies valeurs et les estimations des paramètres (le biais).</p>
</div>
</div>
<div id="lévaluation-des-modèles" class="section level2" number="5.3">
<h2>
<span class="header-section-number">5.3</span> L’évaluation des modèles<a class="anchor" aria-label="anchor" href="#l%C3%A9valuation-des-mod%C3%A8les"><i class="fas fa-link"></i></a>
</h2>
<p>La qualité de l’ajustement d’un modèle aux données est essentielle pour évaluer la confiance que l’on peut accorder aux estimations des paramètres. Les tests de qualité d’ajustement (ou goodness-of-fit en anglais) sont bien établis en statistique fréquentiste, et beaucoup d’entre eux peuvent aussi être utilisés dans des modèles bayésiens simples. C’est le cas par exemple de l’analyse des résidus.</p>
<p>Dans le cas d’une régression linéaire, il y a plusieurs hypothèses sur lesquelles repose le modèle. Ce sont les hypothèses d’indépendance, de normalité, de linéarité et d’homoscédasticité (<span class="math inline">\(\sigma\)</span> ne varie pas avec la variable explicative). On peut en général évaluer les deux premières avec le contexte. Concernant les deux autres, on peut visualiser l’ajustement en superposant la droite de régression estimée au nuage de points observés. Avec le package <code>brms</code>, cela donne la Figure <a href="lms.html#fig:brms-fit-plot">5.7</a> :</p>
<div class="sourceCode" id="cb84"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># extrait les valeurs tirées dans les distributions a posteriori des paramètres</span></span>
<span><span class="va">post</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/posterior/reference/draws_df.html">as_draws_df</a></span><span class="op">(</span><span class="va">lm.brms</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># crée une grille de x pour tracer l'intervalle de crédibilité</span></span>
<span><span class="va">grille_x</span> <span class="op">&lt;-</span> <span class="fu">tibble</span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">min</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">x</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">x</span><span class="op">)</span>, length.out <span class="op">=</span> <span class="fl">100</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># pour chaque x, simule des valeurs de y à partir des échantillons</span></span>
<span><span class="va">pred</span> <span class="op">&lt;-</span> <span class="va">post</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">select</span><span class="op">(</span><span class="va">b_Intercept</span>, <span class="va">b_x</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">expand_grid</span><span class="op">(</span><span class="va">grille_x</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">mutate</span><span class="op">(</span>y <span class="op">=</span> <span class="va">b_Intercept</span> <span class="op">+</span> <span class="va">b_x</span> <span class="op">*</span> <span class="va">x</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">group_by</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">summarise</span><span class="op">(</span></span>
<span>    mean <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span>,</span>
<span>    lower <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/quantile.html">quantile</a></span><span class="op">(</span><span class="va">y</span>, <span class="fl">0.025</span><span class="op">)</span>,</span>
<span>    upper <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/quantile.html">quantile</a></span><span class="op">(</span><span class="va">y</span>, <span class="fl">0.975</span><span class="op">)</span>,</span>
<span>    .groups <span class="op">=</span> <span class="st">"drop"</span></span>
<span>  <span class="op">)</span></span>
<span></span>
<span><span class="co"># extrait les moyennes a posteriori des paramètres</span></span>
<span><span class="va">intercept</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">lm.brms</span><span class="op">)</span><span class="op">$</span><span class="va">fixed</span><span class="op">[</span><span class="fl">1</span>,<span class="fl">1</span><span class="op">]</span></span>
<span><span class="va">slope</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">lm.brms</span><span class="op">)</span><span class="op">$</span><span class="va">fixed</span><span class="op">[</span><span class="fl">2</span>,<span class="fl">1</span><span class="op">]</span></span>
<span></span>
<span><span class="co"># tracé</span></span>
<span><span class="fu">ggplot</span><span class="op">(</span><span class="va">data</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">y</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_point</span><span class="op">(</span>alpha <span class="op">=</span> <span class="fl">0.6</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_ribbon</span><span class="op">(</span>data <span class="op">=</span> <span class="va">pred</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, ymin <span class="op">=</span> <span class="va">lower</span>, ymax <span class="op">=</span> <span class="va">upper</span><span class="op">)</span>, fill <span class="op">=</span> <span class="st">"blue"</span>, alpha <span class="op">=</span> <span class="fl">0.2</span>, inherit.aes <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_line</span><span class="op">(</span>data <span class="op">=</span> <span class="va">pred</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">mean</span><span class="op">)</span>, color <span class="op">=</span> <span class="st">"blue"</span>, size <span class="op">=</span> <span class="fl">1.2</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span>x <span class="op">=</span> <span class="st">"x"</span>, y <span class="op">=</span> <span class="st">"y"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">coord_cartesian</span><span class="op">(</span>xlim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/range.html">range</a></span><span class="op">(</span><span class="va">grille_x</span><span class="op">$</span><span class="va">x</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme_minimal</span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:brms-fit-plot"></span>
<img src="05-regression_files/figure-html/brms-fit-plot-1.png" alt="Ajustement du modèle linéaire par brms. La droite bleue est la régression estimée, obtenue en fixant l'ordonnée à l'origine et la pente à leur moyenne a posteriori, entourée de son intervalle de crédibilité à 95 %." width="90%"><p class="caption">
Figure 5.7: Ajustement du modèle linéaire par brms. La droite bleue est la régression estimée, obtenue en fixant l’ordonnée à l’origine et la pente à leur moyenne a posteriori, entourée de son intervalle de crédibilité à 95 %.
</p>
</div>
<p>Avec <code>NIMBLE</code>, c’est la Figure <a href="lms.html#fig:nimble-fit-plot">5.8</a> :</p>
<div class="sourceCode" id="cb85"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># données simulées</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="va">data</span><span class="op">$</span><span class="va">x</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="va">data</span><span class="op">$</span><span class="va">y</span></span>
<span></span>
<span><span class="co"># tirages postérieurs</span></span>
<span><span class="va">posterior</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">rbind</a></span><span class="op">(</span><span class="va">lm.nimble</span><span class="op">$</span><span class="va">chain1</span>, <span class="va">lm.nimble</span><span class="op">$</span><span class="va">chain2</span>, <span class="va">lm.nimble</span><span class="op">$</span><span class="va">chain3</span><span class="op">)</span></span>
<span><span class="va">beta0</span> <span class="op">&lt;-</span> <span class="va">posterior</span><span class="op">[</span>,<span class="st">'beta0'</span><span class="op">]</span></span>
<span><span class="va">beta1</span> <span class="op">&lt;-</span> <span class="va">posterior</span><span class="op">[</span>,<span class="st">'beta1'</span><span class="op">]</span></span>
<span></span>
<span><span class="co"># grille d'abscisses</span></span>
<span><span class="va">x_seq</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">min</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">x</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">x</span><span class="op">)</span>, length.out <span class="op">=</span> <span class="fl">100</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># calcul des prédictions pour chaque x</span></span>
<span><span class="va">pred_matrix</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">sapply</a></span><span class="op">(</span><span class="va">x_seq</span>, <span class="kw">function</span><span class="op">(</span><span class="va">xi</span><span class="op">)</span> <span class="va">beta0</span> <span class="op">+</span> <span class="va">beta1</span> <span class="op">*</span> <span class="va">xi</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># résumé (moyenne et intervalle)</span></span>
<span><span class="va">pred_df</span> <span class="op">&lt;-</span> <span class="fu">tibble</span><span class="op">(</span></span>
<span>  x <span class="op">=</span> <span class="va">x_seq</span>,</span>
<span>  y_mean <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/colSums.html">colMeans</a></span><span class="op">(</span><span class="va">pred_matrix</span><span class="op">)</span>,</span>
<span>  y_lower <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">pred_matrix</span>, <span class="fl">2</span>, <span class="va">quantile</span>, probs <span class="op">=</span> <span class="fl">0.025</span><span class="op">)</span>,</span>
<span>  y_upper <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">pred_matrix</span>, <span class="fl">2</span>, <span class="va">quantile</span>, probs <span class="op">=</span> <span class="fl">0.975</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># données et vraie relation</span></span>
<span><span class="va">true_df</span> <span class="op">&lt;-</span> <span class="fu">tibble</span><span class="op">(</span>x <span class="op">=</span> <span class="va">x_seq</span>, y_true <span class="op">=</span> <span class="fl">0.1</span> <span class="op">+</span> <span class="fl">1</span> <span class="op">*</span> <span class="va">x_seq</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># tracé</span></span>
<span><span class="fu">ggplot</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_point</span><span class="op">(</span>data <span class="op">=</span> <span class="va">data</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">y</span><span class="op">)</span>, alpha <span class="op">=</span> <span class="fl">0.6</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_ribbon</span><span class="op">(</span>data <span class="op">=</span> <span class="va">pred_df</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, ymin <span class="op">=</span> <span class="va">y_lower</span>, ymax <span class="op">=</span> <span class="va">y_upper</span><span class="op">)</span>, fill <span class="op">=</span> <span class="st">"blue"</span>, alpha <span class="op">=</span> <span class="fl">0.2</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_line</span><span class="op">(</span>data <span class="op">=</span> <span class="va">pred_df</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">y_mean</span><span class="op">)</span>, color <span class="op">=</span> <span class="st">"blue"</span>, size <span class="op">=</span> <span class="fl">1.2</span><span class="op">)</span> <span class="op">+</span></span>
<span> <span class="co"># geom_line(data = true_df, aes(x = x, y = y_true), color = "red", size = 1.2) +</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span>x <span class="op">=</span> <span class="st">"x"</span>, y <span class="op">=</span> <span class="st">"y"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme_minimal</span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:nimble-fit-plot"></span>
<img src="05-regression_files/figure-html/nimble-fit-plot-1.png" alt="Ajustement du modèle linéaire par NIMBLE. La droite bleue est la régression estimée, obtenue en fixant l'ordonnée à l'origine et la pente à leur moyenne a posteriori, entourée de son intervalle de crédibilité à 95 %." width="90%"><p class="caption">
Figure 5.8: Ajustement du modèle linéaire par NIMBLE. La droite bleue est la régression estimée, obtenue en fixant l’ordonnée à l’origine et la pente à leur moyenne a posteriori, entourée de son intervalle de crédibilité à 95 %.
</p>
</div>
<p>Les méthodes bayésiennes sont souvent utilisées pour des modèles plus complexes que la régression linéaire (comme les modèles mixtes, voir Chapitre <a href="glms.html#glms">6</a>), pour lesquels il n’existe pas de tests de qualité d’ajustement standards “clé en main”. Dans ces situations, on utilise couramment ce qu’on appelle des posterior predictive checks. L’idée est de simuler de nouveaux jeux de données à partir de la distribution a posteriori des paramètres du modèle, puis de les comparer aux données observées. Plus les données simulées ressemblent aux données réelles, plus cela suggère que le modèle s’ajuste bien. Cette comparaison peut se faire de manière visuelle ou à l’aide d’une Bayesian p-value qui quantifie l’écart entre données simulées et observées.</p>
<p>Dans <code>brms</code>, il suffit de faire :</p>
<div class="sourceCode" id="cb86"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://mc-stan.org/bayesplot/reference/pp_check.html">pp_check</a></span><span class="op">(</span><span class="va">lm.brms</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:ppcheck-brms"></span>
<img src="05-regression_files/figure-html/ppcheck-brms-1.png" alt="Posterior predictive checks réalisés avec brms. La courbe noire correspond aux données observées, les courbes bleues aux données simulées selon le modèle. L’axe des abscisses représente les valeurs possibles de la variable réponse simulée ou observée. L’axe des ordonnées indique leur densité estimée." width="90%"><p class="caption">
Figure 5.9: Posterior predictive checks réalisés avec brms. La courbe noire correspond aux données observées, les courbes bleues aux données simulées selon le modèle. L’axe des abscisses représente les valeurs possibles de la variable réponse simulée ou observée. L’axe des ordonnées indique leur densité estimée.
</p>
</div>
<p>La fonction <code><a href="https://mc-stan.org/bayesplot/reference/pp_check.html">pp_check()</a></code> génère des graphiques de posterior predictive checks (Figure <a href="lms.html#fig:ppcheck-brms">5.9</a>). Elle compare les données observées à des données simulées à partir du modèle ajusté. Si le modèle est bien ajusté aux données, alors on devrait pouvoir l’utiliser pour générer des données qui ressemblent aux données observées. Par conséquent, si les courbes simulées recouvrent bien les observations, cela indique que le modèle capte correctement la structure des données. Dans le cas contraire, cela peut suggérer un problème de spécification du modèle, par exemple un lien ou une famille de distribution inadaptée (voir Chapitre <a href="glms.html#glms">6</a>).</p>
<p>Il n’y a pas de fonction dédiée dans <code>NIMBLE</code> donc il va falloir simuler des données selon le modèle avec les paramètres estimés. On pourrait le faire à la main comme avec l’espérance de vie, mais le plus simple est d’inclure une ligne supplémentaire dans le code <code>NIMBLE</code> :</p>
<div class="sourceCode" id="cb87"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/nimble/man/nimbleCode.html">nimbleCode</a></span><span class="op">(</span><span class="op">{</span></span>
<span>  <span class="va">beta0</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1.5</span><span class="op">)</span> <span class="co"># prior normal sur l'intercept</span></span>
<span>  <span class="va">beta1</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1.5</span><span class="op">)</span> <span class="co"># prior normal sur le coefficient</span></span>
<span>  <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Exponential.html">dexp</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span> <span class="co"># prior exponentiel sur l'écart-type</span></span>
<span>  <span class="kw">for</span><span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">n</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">y</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">beta0</span> <span class="op">+</span> <span class="va">beta1</span> <span class="op">*</span> <span class="va">x</span><span class="op">[</span><span class="va">i</span><span class="op">]</span>, sd <span class="op">=</span> <span class="va">sigma</span><span class="op">)</span> <span class="co"># modèle pour les données observées</span></span>
<span>    <span class="va">y_sim</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">beta0</span> <span class="op">+</span> <span class="va">beta1</span> <span class="op">*</span> <span class="va">x</span><span class="op">[</span><span class="va">i</span><span class="op">]</span>, sd <span class="op">=</span> <span class="va">sigma</span><span class="op">)</span> <span class="co"># modèle pour les données simulées</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">}</span><span class="op">)</span></span></code></pre></div>
<p>C’est la ligne <code>y_sim[i] ~ dnorm(beta0 + beta1 * x[i], sd = sigma)</code> que j’ai ajoutée pour simuler selon le modèle ajusté. Les données et les valeurs initiales ne changent pas, il nous faut juste ajouter <code>y_sim</code> à la liste des paramètres qu’on veut retrouver dans les sorties :</p>
<div class="sourceCode" id="cb88"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">par</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"beta0"</span>, <span class="st">"beta1"</span>, <span class="st">"sigma"</span>, <span class="st">"y_sim"</span><span class="op">)</span></span></code></pre></div>
<p>Puis on relance <code>NIMBLE</code> :</p>
<div class="sourceCode" id="cb89"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">lm.nimble</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/nimble/man/nimbleMCMC.html">nimbleMCMC</a></span><span class="op">(</span></span>
<span>  code <span class="op">=</span> <span class="va">model</span>,</span>
<span>  data <span class="op">=</span> <span class="va">dat</span>,</span>
<span>  inits <span class="op">=</span> <span class="va">inits</span>,</span>
<span>  monitors <span class="op">=</span> <span class="va">par</span>,</span>
<span>  niter <span class="op">=</span> <span class="fl">2000</span>,</span>
<span>  nburnin <span class="op">=</span> <span class="fl">1000</span>,</span>
<span>  nchains <span class="op">=</span> <span class="fl">3</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; |-------------|-------------|-------------|-------------|</span></span>
<span><span class="co">#&gt; |-------------------------------------------------------|</span></span>
<span><span class="co">#&gt; |-------------|-------------|-------------|-------------|</span></span>
<span><span class="co">#&gt; |-------------------------------------------------------|</span></span>
<span><span class="co">#&gt; |-------------|-------------|-------------|-------------|</span></span>
<span><span class="co">#&gt; |-------------------------------------------------------|</span></span></code></pre></div>
<p>On fusionne alors les 3 chaînes, puis on sélectionne uniquement les colonnes correspondant à <code>y_sim</code> :</p>
<div class="sourceCode" id="cb90"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># fusion des trois chaînes MCMC obtenues avec NIMBLE</span></span>
<span><span class="va">y_sim_mcmc</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">rbind</a></span><span class="op">(</span><span class="va">lm.nimble</span><span class="op">$</span><span class="va">chain1</span>, <span class="va">lm.nimble</span><span class="op">$</span><span class="va">chain2</span>, <span class="va">lm.nimble</span><span class="op">$</span><span class="va">chain3</span><span class="op">)</span></span>
<span><span class="co"># sélection des colonnes correspondant aux simulations de y (les y_sim[i])</span></span>
<span><span class="va">y_sim_cols</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/grep.html">grep</a></span><span class="op">(</span><span class="st">"^y_sim\\["</span>, <span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="va">y_sim_mcmc</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co"># extraction de la matrice des valeurs simulées pour y</span></span>
<span><span class="va">y_sim_matrix</span> <span class="op">&lt;-</span> <span class="va">y_sim_mcmc</span><span class="op">[</span>, <span class="va">y_sim_cols</span><span class="op">]</span></span></code></pre></div>
<p>On fait ensuite 10 tirages, comme par défaut dans <code>brms</code>, puis on met les résultats en forme :</p>
<div class="sourceCode" id="cb91"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># fixe la graine pour reproductibilité</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span>
<span><span class="co"># sélectionne au hasard 10 tirages parmi les simulations (comme le fait brms par défaut)</span></span>
<span><span class="va">sim_indices</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">y_sim_matrix</span><span class="op">)</span>, <span class="fl">10</span><span class="op">)</span></span>
<span><span class="co"># mise en forme des simulations </span></span>
<span><span class="va">simulations_df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span></span>
<span>  y_sim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/vector.html">as.vector</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">y_sim_matrix</span><span class="op">[</span><span class="va">sim_indices</span>, <span class="op">]</span><span class="op">)</span><span class="op">)</span>, <span class="co"># valeurs simulées</span></span>
<span>  Replicate <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">sim_indices</span><span class="op">)</span>, each <span class="op">=</span> <span class="va">n</span><span class="op">)</span>, <span class="co"># identifiant du tirage (1 à 10)</span></span>
<span>  Observation <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">n</span>, times <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">sim_indices</span><span class="op">)</span><span class="op">)</span> <span class="co"># identifiant de l'observation (1 à n)</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>Enfin, on obtient le graphe des posterior predictive checks dans la Figure <a href="lms.html#fig:ppcheck-nimble">5.10</a> :</p>
<div class="sourceCode" id="cb92"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">ggplot</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_density</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">y_sim</span>, group <span class="op">=</span> <span class="va">Replicate</span><span class="op">)</span>, color <span class="op">=</span> <span class="st">"lightblue"</span>, alpha <span class="op">=</span> <span class="fl">0.2</span>, data <span class="op">=</span> <span class="va">simulations_df</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_density</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">y</span><span class="op">)</span>, color <span class="op">=</span> <span class="st">"black"</span>, alpha <span class="op">=</span> <span class="fl">0.5</span>, size <span class="op">=</span> <span class="fl">1.2</span>, data <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>y <span class="op">=</span> <span class="va">y</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span>x <span class="op">=</span> <span class="st">""</span>,</span>
<span>       y <span class="op">=</span> <span class="st">""</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme_minimal</span><span class="op">(</span>base_size <span class="op">=</span> <span class="fl">14</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:ppcheck-nimble"></span>
<img src="05-regression_files/figure-html/ppcheck-nimble-1.png" alt="Posterior predictive checks réalisés avec NIMBLE. La courbe noire correspond aux données observées, les courbes bleues aux données simulées selon le modèle. L’axe des abscisses représente les valeurs possibles de la variable réponse simulée ou observée. L’axe des ordonnées indique leur densité estimée." width="90%"><p class="caption">
Figure 5.10: Posterior predictive checks réalisés avec NIMBLE. La courbe noire correspond aux données observées, les courbes bleues aux données simulées selon le modèle. L’axe des abscisses représente les valeurs possibles de la variable réponse simulée ou observée. L’axe des ordonnées indique leur densité estimée.
</p>
</div>
<p>On peut également calculer une Bayesian p-value (ou p-valeur bayésienne) qui représente la proportion de jeux de données simulés sous le modèle pour lesquels la statistique choisie (ici la moyenne) est aussi grande ou plus grande que celle observée. Une valeur proche de 0 ou de 1 peut indiquer un mauvais ajustement du modèle pour cette statistique particulière, tandis qu’une valeur proche de 0.5 suggère un bon ajustement. Cette Bayesian p-value s’obtient comme suit :</p>
<div class="sourceCode" id="cb93"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Statistique de test observée : ici la moyenne des y observés</span></span>
<span><span class="va">T_obs</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Statistique de test sur les données simulées</span></span>
<span><span class="va">T_sim</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">y_sim_matrix</span>, <span class="fl">1</span>, <span class="va">mean</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Valeur-p bayésienne : proportion des simulations où T_sim est plus extrême que T_obs</span></span>
<span><span class="va">bayes_pval</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">T_sim</span> <span class="op">&gt;=</span> <span class="va">T_obs</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Affichage du résultat</span></span>
<span><span class="va">bayes_pval</span></span>
<span><span class="co">#&gt; [1] 0.512</span></span></code></pre></div>
<p>Avec <code>brms</code>, on peut aussi obtenir cette Bayesian p-value :</p>
<div class="sourceCode" id="cb94"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Extraire les simulations de y_rep</span></span>
<span><span class="va">y_rep</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/rstantools/reference/posterior_predict.html">posterior_predict</a></span><span class="op">(</span><span class="va">lm.brms</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Calculer la statistique de test sur les données simulées (moyenne ici)</span></span>
<span><span class="va">T_sim</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/colSums.html">rowMeans</a></span><span class="op">(</span><span class="va">y_rep</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Calculer la statistique observée</span></span>
<span><span class="va">T_obs</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">lm.brms</span><span class="op">$</span><span class="va">data</span><span class="op">$</span><span class="va">y</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Calculer la Bayesian p-value</span></span>
<span><span class="va">bayes_pval</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">T_sim</span> <span class="op">&gt;=</span> <span class="va">T_obs</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Afficher le résultat</span></span>
<span><span class="va">bayes_pval</span></span>
<span><span class="co">#&gt; [1] 0.49075</span></span></code></pre></div>
</div>
<div id="la-comparaison-de-modèles" class="section level2" number="5.4">
<h2>
<span class="header-section-number">5.4</span> La comparaison de modèles<a class="anchor" aria-label="anchor" href="#la-comparaison-de-mod%C3%A8les"><i class="fas fa-link"></i></a>
</h2>
<p>Comme on l’a vu dans le Chapitre <a href="principes.html#principes">1</a>, la statistique bayésienne permet de comparer plusieurs hypothèses entre elles, et de savoir à quel point une hypothèse est plausible à partir des données que nous avons collectées.</p>
<!-- Formellement, cela revient à estimer la probabilité qu’un modèle soit vrai étant donné les données, ce qu’on appelle la probabilité a posteriori du modèle. Une méthode classique pour obtenir ces probabilités repose sur les facteurs de Bayes. Mais ces derniers peuvent être coûteux à calculer, et sont souvent très sensibles aux choix des lois a priori, ce qui limite leur utilisation en pratique. Une autre possibilité consiste à estimer directement les probabilités a posteriori des modèles via un algorithme de type MCMC à sauts réversibles (reversible jump MCMC), relativement simple à mettre en œuvre lorsqu’on souhaite sélectionner un sous-ensemble de covariables explicatives. -->
<p>Il est essentiel, avant de comparer des modèles, de se demander quel est l’objectif de l’analyse : s’agit-il de mieux comprendre un phénomène (approche explicative), ou plutôt de faire des prédictions (approche prédictive) ?</p>
<p>Une stratégie consiste à construire un modèle unique incluant les variables jugées pertinentes, puis à l’ajuster, l’examiner, le tester, et l’améliorer progressivement. Cette approche vise moins à identifier le meilleur modèle qu’à explorer différentes variantes pour mieux comprendre le système étudié.</p>
<p>Pour évaluer la capacité prédictive d’un modèle, on peut s’appuyer sur des données déjà utilisées pour l’ajustement (prédiction interne) ou, de manière plus fiable, sur de nouvelles données (prédiction externe). Cette dernière approche nécessite toutefois de diviser les données en un jeu d’apprentissage et un jeu de test. À défaut, il est possible d’estimer les performances prédictives sur les données d’apprentissage elles-mêmes à l’aide d’outils comme le WAIC ou le LOO-CV.</p>
<p>Le WAIC (Watanabe-Akaike Information Criterion) et le LOO-CV (Leave-One-Out cross-validation) permettent de comparer des modèles en estimant leur capacité à prédire de nouvelles données. Ils combinent l’ajustement aux données observées avec une pénalisation de la complexité du modèle. Une valeur de WAIC ou de LOO-CV plus faible indique un meilleur modèle. Le WAIC est basé sur une approximation théorique, tandis que le LOO-CV repose sur une validation croisée. Le LOO-CV est généralement plus précis, surtout pour les modèles complexes ou les jeux de données de taille limitée, mais il est aussi plus coûteux en calcul. En pratique, lorsque les modèles sont bien spécifiés et que l’échantillon est grand, WAIC et LOO-CV donnent souvent des résultats très proches pour un même modèle.</p>
<p>Je reviens à l’exemple de la régression linéaire. On aimerait tester l’hypothèse que la variable <span class="math inline">\(x\)</span> explique bien une part importante de la variation dans <span class="math inline">\(y\)</span>. Cela revient à comparer les modèles avec et sans cette variable.</p>
<p>Dans <code>brms</code>, on ajuste ces deux modèles avec des priors faiblement informatifs :</p>
<div class="sourceCode" id="cb95"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb95-1"><a href="lms.html#cb95-1" tabindex="-1"></a><span class="co"># Modèle avec covariable</span></span>
<span id="cb95-2"><a href="lms.html#cb95-2" tabindex="-1"></a>fit1 <span class="ot">&lt;-</span> <span class="fu">brm</span>(y <span class="sc">~</span> x, <span class="at">data =</span> data, <span class="at">family =</span> <span class="fu">gaussian</span>(),</span>
<span id="cb95-3"><a href="lms.html#cb95-3" tabindex="-1"></a>            <span class="at">prior =</span> <span class="fu">c</span>(</span>
<span id="cb95-4"><a href="lms.html#cb95-4" tabindex="-1"></a>              <span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">0</span>, <span class="fl">1.5</span>), <span class="at">class =</span> Intercept),</span>
<span id="cb95-5"><a href="lms.html#cb95-5" tabindex="-1"></a>              <span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">0</span>, <span class="fl">1.5</span>), <span class="at">class =</span> b),</span>
<span id="cb95-6"><a href="lms.html#cb95-6" tabindex="-1"></a>              <span class="fu">prior</span>(<span class="fu">exponential</span>(<span class="dv">1</span>), <span class="at">class =</span> sigma)</span>
<span id="cb95-7"><a href="lms.html#cb95-7" tabindex="-1"></a>            ))</span>
<span id="cb95-8"><a href="lms.html#cb95-8" tabindex="-1"></a></span>
<span id="cb95-9"><a href="lms.html#cb95-9" tabindex="-1"></a><span class="co"># Modèle sans covariable</span></span>
<span id="cb95-10"><a href="lms.html#cb95-10" tabindex="-1"></a>fit0 <span class="ot">&lt;-</span> <span class="fu">brm</span>(y <span class="sc">~</span> <span class="dv">1</span>, <span class="at">data =</span> data, <span class="at">family =</span> <span class="fu">gaussian</span>(),</span>
<span id="cb95-11"><a href="lms.html#cb95-11" tabindex="-1"></a>            <span class="at">prior =</span> <span class="fu">c</span>(</span>
<span id="cb95-12"><a href="lms.html#cb95-12" tabindex="-1"></a>              <span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">0</span>, <span class="fl">1.5</span>), <span class="at">class =</span> Intercept),</span>
<span id="cb95-13"><a href="lms.html#cb95-13" tabindex="-1"></a>              <span class="fu">prior</span>(<span class="fu">exponential</span>(<span class="dv">1</span>), <span class="at">class =</span> sigma))</span></code></pre></div>
<p>La fonction <code><a href="https://mc-stan.org/loo/reference/waic.html">waic()</a></code> permet d’extraire le WAIC, où le modèle avec la plus petite valeur est préféré. Si le modèle avec <span class="math inline">\(x\)</span> est bien le bon (c’est ce qu’on attend puisque c’est comme ça que les données ont été simulées), on devrait voir qu’il est nettement meilleur que celui sans covariable :</p>
<div class="sourceCode" id="cb96"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Calcul du WAIC pour chaque modèle</span></span>
<span><span class="va">waic1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/loo/reference/waic.html">waic</a></span><span class="op">(</span><span class="va">fit1</span><span class="op">)</span></span>
<span><span class="va">waic0</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/loo/reference/waic.html">waic</a></span><span class="op">(</span><span class="va">fit0</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Comparaison</span></span>
<span><span class="va">waic1</span><span class="op">$</span><span class="va">estimates</span><span class="op">[</span><span class="st">'waic'</span>,<span class="op">]</span></span>
<span><span class="co">#&gt;  Estimate        SE </span></span>
<span><span class="co">#&gt; 172.50456  13.13435</span></span>
<span><span class="va">waic0</span><span class="op">$</span><span class="va">estimates</span><span class="op">[</span><span class="st">'waic'</span>,<span class="op">]</span></span>
<span><span class="co">#&gt;  Estimate        SE </span></span>
<span><span class="co">#&gt; 333.97491  17.23233</span></span></code></pre></div>
<p>Ouf, c’est bien le cas. La fonction <code><a href="https://mc-stan.org/loo/reference/loo.html">loo()</a></code> permet de calculer le LOO-CV (une approximation en fait) :</p>
<div class="sourceCode" id="cb97"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Leave-one-out cross-validation</span></span>
<span><span class="va">loo1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/loo/reference/loo.html">loo</a></span><span class="op">(</span><span class="va">fit1</span><span class="op">)</span></span>
<span><span class="va">loo0</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/loo/reference/loo.html">loo</a></span><span class="op">(</span><span class="va">fit0</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Comparaison</span></span>
<span><span class="fu"><a href="https://mc-stan.org/loo/reference/loo_compare.html">loo_compare</a></span><span class="op">(</span><span class="va">loo0</span>, <span class="va">loo1</span><span class="op">)</span></span>
<span><span class="co">#&gt;      elpd_diff se_diff</span></span>
<span><span class="co">#&gt; fit1   0.0       0.0  </span></span>
<span><span class="co">#&gt; fit0 -80.7       9.1</span></span></code></pre></div>
<p>Dans cette sortie <code>R</code>, <code>elpd_diff</code> donne l’écart de LOO-CV entre chaque modèle et celui qui a la plus grande valeur. Ainsi, le meilleur modèle est sur la première ligne avec un elpd_diff égal à zéro ; ici, c’est le modèle avec la covariable. On arrive donc à la même conclusion qu’avec le WAIC.</p>
<p>On peut obtenir les valeurs de WAIC avec <code>NIMBLE</code> également. Pour ce faire il suffit d’ajouter <code>WAIC = TRUE</code> dans l’appel à la fonction <code>nimbleMCMC</code>:</p>
<div class="sourceCode" id="cb98"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Code du modèle avec covariable</span></span>
<span><span class="va">model_avec</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/nimble/man/nimbleCode.html">nimbleCode</a></span><span class="op">(</span><span class="op">{</span></span>
<span>  <span class="co"># les priors</span></span>
<span>  <span class="va">beta0</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1.5</span><span class="op">)</span> <span class="co"># prior normal sur l'intercept</span></span>
<span>  <span class="va">beta1</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1.5</span><span class="op">)</span> <span class="co"># prior normal sur le coefficient</span></span>
<span>  <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Exponential.html">dexp</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span> <span class="co"># prior exponentiel sur l'écart-type</span></span>
<span>  <span class="co"># la vraisemblance</span></span>
<span>  <span class="kw">for</span><span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">n</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">y</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">beta0</span> <span class="op">+</span> <span class="va">beta1</span> <span class="op">*</span> <span class="va">x</span><span class="op">[</span><span class="va">i</span><span class="op">]</span>, sd <span class="op">=</span> <span class="va">sigma</span><span class="op">)</span> <span class="co"># equiv de yi = beta0 + beta1 * xi + epsiloni</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">}</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Code du modèle sans covariable</span></span>
<span><span class="va">model_sans</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/nimble/man/nimbleCode.html">nimbleCode</a></span><span class="op">(</span><span class="op">{</span></span>
<span>  <span class="co"># les priors</span></span>
<span>  <span class="va">beta0</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1.5</span><span class="op">)</span> <span class="co"># prior normal sur l'intercept</span></span>
<span>  <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Exponential.html">dexp</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span> <span class="co"># prior exponentiel sur l'écart-type</span></span>
<span>  <span class="co"># la vraisemblance</span></span>
<span>  <span class="kw">for</span><span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">n</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">y</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">beta0</span>, sd <span class="op">=</span> <span class="va">sigma</span><span class="op">)</span> <span class="co"># equiv de yi = beta0 + beta1 * xi + epsiloni</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">}</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Données, valeurs initiales</span></span>
<span><span class="va">dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">y</span>, n <span class="op">=</span> <span class="va">n</span><span class="op">)</span> <span class="co"># données</span></span>
<span><span class="va">inits_avec</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>beta0 <span class="op">=</span> <span class="op">-</span><span class="fl">0.5</span>, beta1 <span class="op">=</span> <span class="op">-</span><span class="fl">0.5</span>, sigma <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span>, <span class="co"># valeurs initiales chaine 1</span></span>
<span>                   <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>beta0 <span class="op">=</span> <span class="fl">0</span>, beta1 <span class="op">=</span> <span class="fl">0</span>, sigma <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>, <span class="co"># valeurs initiales chaine 2</span></span>
<span>                   <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>beta0 <span class="op">=</span> <span class="fl">0.5</span>, beta1 <span class="op">=</span> <span class="fl">0.5</span>, sigma <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span><span class="op">)</span> <span class="co"># valeurs initiales chaine 3</span></span>
<span><span class="va">inits_sans</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>beta0 <span class="op">=</span> <span class="op">-</span><span class="fl">0.5</span>, sigma <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span>, <span class="co"># valeurs initiales chaine 1</span></span>
<span>                   <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>beta0 <span class="op">=</span> <span class="fl">0</span>, sigma <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>, <span class="co"># valeurs initiales chaine 2</span></span>
<span>                   <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>beta0 <span class="op">=</span> <span class="fl">0.5</span>, sigma <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span><span class="op">)</span> <span class="co"># valeurs initiales chaine 3</span></span>
<span></span>
<span><span class="co"># Modèle avec covariable</span></span>
<span><span class="va">lm.avec</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/nimble/man/nimbleMCMC.html">nimbleMCMC</a></span><span class="op">(</span></span>
<span>  code <span class="op">=</span> <span class="va">model_avec</span>,</span>
<span>  data <span class="op">=</span> <span class="va">dat</span>,</span>
<span>  inits <span class="op">=</span> <span class="va">inits_avec</span>,</span>
<span>  niter <span class="op">=</span> <span class="fl">2000</span>,</span>
<span>  nburnin <span class="op">=</span> <span class="fl">1000</span>,</span>
<span>  nchains <span class="op">=</span> <span class="fl">3</span>,</span>
<span>  WAIC <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="co">#&gt; |-------------|-------------|-------------|-------------|</span></span>
<span><span class="co">#&gt; |-------------------------------------------------------|</span></span>
<span><span class="co">#&gt; |-------------|-------------|-------------|-------------|</span></span>
<span><span class="co">#&gt; |-------------------------------------------------------|</span></span>
<span><span class="co">#&gt; |-------------|-------------|-------------|-------------|</span></span>
<span><span class="co">#&gt; |-------------------------------------------------------|</span></span>
<span></span>
<span><span class="co"># Modèle sans covariable</span></span>
<span><span class="va">lm.sans</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/nimble/man/nimbleMCMC.html">nimbleMCMC</a></span><span class="op">(</span></span>
<span>  code <span class="op">=</span> <span class="va">model_sans</span>,</span>
<span>  data <span class="op">=</span> <span class="va">dat</span>,</span>
<span>  inits <span class="op">=</span> <span class="va">inits_sans</span>,</span>
<span>  niter <span class="op">=</span> <span class="fl">2000</span>,</span>
<span>  nburnin <span class="op">=</span> <span class="fl">1000</span>,</span>
<span>  nchains <span class="op">=</span> <span class="fl">3</span>,</span>
<span>  WAIC <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="co">#&gt; |-------------|-------------|-------------|-------------|</span></span>
<span><span class="co">#&gt; |-------------------------------------------------------|</span></span>
<span><span class="co">#&gt; |-------------|-------------|-------------|-------------|</span></span>
<span><span class="co">#&gt; |-------------------------------------------------------|</span></span>
<span><span class="co">#&gt; |-------------|-------------|-------------|-------------|</span></span>
<span><span class="co">#&gt; |-------------------------------------------------------|</span></span>
<span><span class="co">#&gt;   [Warning] There are 1 individual pWAIC values that are greater than 0.4. This may indicate that the WAIC estimate is unstable (Vehtari et al., 2017), at least in cases without grouping of data nodes or multivariate data nodes.</span></span>
<span></span>
<span><span class="co"># Calcul du WAIC pour chaque modèle</span></span>
<span><span class="va">lm.avec</span><span class="op">$</span><span class="va">WAIC</span><span class="op">$</span><span class="va">WAIC</span></span>
<span><span class="co">#&gt; [1] 172.4424</span></span>
<span><span class="va">lm.sans</span><span class="op">$</span><span class="va">WAIC</span><span class="op">$</span><span class="va">WAIC</span></span>
<span><span class="co">#&gt; [1] 333.3443</span></span></code></pre></div>
<p>On arrive à la même conclusion qu’avec <code>brms</code>. A noter que <code>NIMBLE</code> ne fournit pas directement une fonction <code><a href="https://mc-stan.org/loo/reference/loo.html">loo()</a></code> comme <code>brms</code>, même si on pourrait estimer le LOO-CV à la main.</p>
</div>
<div id="en-résumé" class="section level2" number="5.5">
<h2>
<span class="header-section-number">5.5</span> En résumé<a class="anchor" aria-label="anchor" href="#en-r%C3%A9sum%C3%A9"><i class="fas fa-link"></i></a>
</h2>
<ul>
<li><p>La régression linéaire permet de modéliser la relation entre une variable réponse continue et une ou plusieurs variables explicatives, en tenant compte d’une variabilité résiduelle.</p></li>
<li><p>Simuler des données à partir d’un modèle est un excellent moyen de comprendre son fonctionnement et de tester son code.</p></li>
<li><p>Les lois a priori faiblement informatives (comme <span class="math inline">\(N(0, 1.5)\)</span> pour les coefficients ou <span class="math inline">\(\text{Exp}(1)\)</span> pour <span class="math inline">\(\sigma\)</span>) aident à encadrer les valeurs réalistes tout en laissant au modèle la liberté d’apprendre des données.</p></li>
<li><p>La validation et la comparaison des modèles peuvent se faire à l’aide de posterior predictive checks et de critères comme le WAIC. Ces outils permettent d’évaluer la qualité du modèle au regard des données, et d’arbitrer entre plusieurs modèles concurrents.</p></li>
</ul>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="prior.html"><span class="header-section-number">4</span> Prior distributions</a></div>
<div class="next"><a href="glms.html"><span class="header-section-number">6</span> Modèles linéaires généralisés, et généralisés mixtes</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#lms"><span class="header-section-number">5</span> La régression</a></li>
<li><a class="nav-link" href="#introduction-5"><span class="header-section-number">5.1</span> Introduction</a></li>
<li>
<a class="nav-link" href="#la-r%C3%A9gression-lin%C3%A9aire"><span class="header-section-number">5.2</span> La régression linéaire</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#le-mod%C3%A8le"><span class="header-section-number">5.2.1</span> Le modèle</a></li>
<li><a class="nav-link" href="#simuler-des-donn%C3%A9es"><span class="header-section-number">5.2.2</span> Simuler des données</a></li>
<li><a class="nav-link" href="#lajustement-avec-brms"><span class="header-section-number">5.2.3</span> L’ajustement avec brms</a></li>
<li><a class="nav-link" href="#weakly-informative-priors"><span class="header-section-number">5.2.4</span> Des priors faiblement informatifs</a></li>
<li><a class="nav-link" href="#lajustement-avec-nimble"><span class="header-section-number">5.2.5</span> L’ajustement avec NIMBLE</a></li>
<li><a class="nav-link" href="#lajustement-par-maximum-de-vraisemblance"><span class="header-section-number">5.2.6</span> L’ajustement par maximum de vraisemblance</a></li>
</ul>
</li>
<li><a class="nav-link" href="#l%C3%A9valuation-des-mod%C3%A8les"><span class="header-section-number">5.3</span> L’évaluation des modèles</a></li>
<li><a class="nav-link" href="#la-comparaison-de-mod%C3%A8les"><span class="header-section-number">5.4</span> La comparaison de modèles</a></li>
<li><a class="nav-link" href="#en-r%C3%A9sum%C3%A9"><span class="header-section-number">5.5</span> En résumé</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/oliviergimenez/introduction-to-bayesian-statistics-with-R/blob/master/05-regression.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/oliviergimenez/introduction-to-bayesian-statistics-with-R/edit/master/05-regression.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Introduction to Bayesian Statistics with R</strong>: Using NIMBLE and brms" a été écrit par Olivier Gimenez. Dernière mise à jour le 2026-02-23.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>Ce livre a été généré avec le <a class="text-light" href="https://bookdown.org">package R bookdown</a>.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
