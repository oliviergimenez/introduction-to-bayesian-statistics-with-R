<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 6 Generalized linear models, and generalized linear mixed models | Introduction to Bayesian Statistics with R</title>
<meta name="author" content="Olivier Gimenez">
<meta name="description" content="6.1 Introduction This chapter presents the application of Bayesian statistics to extensions of the linear model seen in the previous chapter: generalized linear models (GLMs) and generalized...">
<meta name="generator" content="bookdown 0.43 with bs4_book()">
<meta property="og:title" content="Chapter 6 Generalized linear models, and generalized linear mixed models | Introduction to Bayesian Statistics with R">
<meta property="og:type" content="book">
<meta property="og:url" content="https://oliviergimenez.github.io/introduction-to-bayesian-statistics-with-R/glms.html">
<meta property="og:description" content="6.1 Introduction This chapter presents the application of Bayesian statistics to extensions of the linear model seen in the previous chapter: generalized linear models (GLMs) and generalized...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 6 Generalized linear models, and generalized linear mixed models | Introduction to Bayesian Statistics with R">
<meta name="twitter:description" content="6.1 Introduction This chapter presents the application of Bayesian statistics to extensions of the linear model seen in the previous chapter: generalized linear models (GLMs) and generalized...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><link href="libs/Roboto-0.4.10/font.css" rel="stylesheet">
<script src="libs/bs3compat-0.9.0/transition.js"></script><script src="libs/bs3compat-0.9.0/tabs.js"></script><script src="libs/bs3compat-0.9.0/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><!-- Google tag (gtag.js) --><script async src="https://www.googletagmanager.com/gtag/js?id=G-MTKSQWQE5K"></script><script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-MTKSQWQE5K');
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
          margin-bottom: 0em;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
<link rel="stylesheet" href="style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="using NIMBLE and brms">Introduction to Bayesian Statistics with R</a>:
        <small class="text-muted">using NIMBLE and brms</small>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Introduction</a></li>
<li><a class="" href="principles.html"><span class="header-section-number">1</span> The Bayesian approach</a></li>
<li><a class="" href="mcmc.html"><span class="header-section-number">2</span> MCMC methods</a></li>
<li><a class="" href="software.html"><span class="header-section-number">3</span> Practical implementation</a></li>
<li><a class="" href="prior.html"><span class="header-section-number">4</span> Prior distributions</a></li>
<li><a class="" href="lms.html"><span class="header-section-number">5</span> Regression</a></li>
<li><a class="active" href="glms.html"><span class="header-section-number">6</span> Generalized linear models, and generalized linear mixed models</a></li>
<li><a class="" href="conclusions.html">Conclusions</a></li>
<li><a class="" href="r%C3%A9f%C3%A9rences.html">Références</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/oliviergimenez/introduction-to-bayesian-statistics-with-R">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="glms" class="section level1" number="6">
<h1>
<span class="header-section-number">6</span> Generalized linear models, and generalized linear mixed models<a class="anchor" aria-label="anchor" href="#glms"><i class="fas fa-link"></i></a>
</h1>
<div id="introduction-6" class="section level2" number="6.1">
<h2>
<span class="header-section-number">6.1</span> Introduction<a class="anchor" aria-label="anchor" href="#introduction-6"><i class="fas fa-link"></i></a>
</h2>
<p>This chapter presents the application of Bayesian statistics to extensions of the linear model seen in the previous chapter: generalized linear models (GLMs) and generalized linear mixed models (GLMMs). We will start with a GLM that will allow us to revisit our running example on coypu (ragondin) survival and binary data. We will then use a GLMM to analyze count data. We will then use a GLMM to analyze count data. We will use <code>NIMBLE</code> and <code>brms</code> and compare with the frequentist approach.</p>
</div>
<div id="generalized-linear-models-glms" class="section level2" number="6.2">
<h2>
<span class="header-section-number">6.2</span> Generalized linear models (GLMs)<a class="anchor" aria-label="anchor" href="#generalized-linear-models-glms"><i class="fas fa-link"></i></a>
</h2>
<p>In Chapter <a href="lms.html#lms">5</a>, we introduced linear regression <span class="math inline">\(y_i \sim N(\mu_i,\sigma^2)\)</span> with <span class="math inline">\(\mu_i = \beta_0 + \beta_1 x_i\)</span>, where we model the mean <span class="math inline">\(\mu\)</span> of the response variable <span class="math inline">\(y\)</span> as a function of an explanatory variable <span class="math inline">\(x\)</span>. This so-called linear model is well suited to a continuous response variable. But what happens when the response variable is discrete? Let us go back to our coypu example in which we study the number of animals that survive. If we apply linear regression to these data, we will obtain a decimal number of coypu, which is a bit annoying for a count that is, by definition, discrete. Moreover, if we introduce an explanatory variable <span class="math inline">\(x_i\)</span> such as body mass to explain variation in the number of coypu that survive, we may end up with a negative survival probability, or one greater than one. Why? Because nothing forces the linear model to consider only values that are positive and less than one.</p>
<p>We saw the solution in Chapter <a href="principles.html#principles">1</a>. We set <span class="math inline">\(z_i = 1\)</span> when coypu <span class="math inline">\(i\)</span> survived, and <span class="math inline">\(z_i = 0\)</span> otherwise, and we assume that the survival event is like a coin flip with probability <span class="math inline">\(\theta\)</span>; in other words, each <span class="math inline">\(z_i\)</span> follows a Bernoulli distribution with parameter <span class="math inline">\(\theta\)</span>. If we assume that individuals are independent and share the same distribution, then the total number of coypu that survive the winter <span class="math inline">\(\displaystyle\sum_{i=1}^n{z_i} = y\)</span> follows a binomial distribution <span class="math inline">\(y \sim \text{Bin}(n, \theta)\)</span>, with <span class="math inline">\(\theta\)</span> the survival probability.</p>
<p>We also saw in Chapters <a href="mcmc.html#mcmc">2</a> and <a href="software.html#software">3</a> that we can use the logit function to force a parameter to be properly estimated between 0 and 1. This amounts to writing <span class="math inline">\(\text{logit}(\theta_i) = \beta_0 + \beta_1 x_i\)</span>, as explained in Figure <a href="glms.html#fig:logit-link">6.1</a>.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:logit-link"></span>
<img src="06-glms_files/figure-html/logit-link-1.png" alt="Left: the logit function transforms a probability p into an unbounded continuous value logit(p) that lives between minus infinity and plus infinity. Right: the inverse logit function transforms a linear combination of predictors (linear value on the figure) into a probability that lives between 0 and 1. The logit function is used in logistic regression (a GLM with binomial distribution) to transform a probability (between 0 and 1) into a continuous variable defined on the real line. Then, the inverse logit function allows you to return to the probability scale." width="90%"><p class="caption">
Figure 6.1: Left: the logit function transforms a probability p into an unbounded continuous value logit(p) that lives between minus infinity and plus infinity. Right: the inverse logit function transforms a linear combination of predictors (linear value on the figure) into a probability that lives between 0 and 1. The logit function is used in logistic regression (a GLM with binomial distribution) to transform a probability (between 0 and 1) into a continuous variable defined on the real line. Then, the inverse logit function allows you to return to the probability scale.
</p>
</div>
<p>To formalize things a bit, we have:
<span class="math display">\[\begin{align}
z_i &amp;\sim \text{Bernoulli}(\theta_i) &amp;\text{[likelihood]}\\
\text{logit}(\theta_i) &amp;= \beta_0 + \beta_1 \; x_i &amp;\text{[linear relationship]}\\
\theta_i &amp;= \text{logit}^{-1}(\beta_0 + \beta_1 \; x_i) = \dfrac {e^{\beta_0 + \beta_1 \; x_i}} {1+e^{\beta_0 + \beta_1 \; x_i}} &amp;\text{[transformed relationship]}\\
  \beta_0, \beta_1 &amp;\sim \text{Normal}(0, 1.5) &amp;\text{[prior on the parameters]} \\
\end{align}\]</span></p>
<p>To illustrate all this, we can go back to the coypu data and add individual body mass data; to do so, we recreate the raw data, i.e. the <span class="math inline">\(z_i\)</span>:</p>
<div class="sourceCode" id="cb99"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Total number of coypus released, and surviving</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">57</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fl">19</span></span>
<span></span>
<span><span class="co"># Create individual data (0 = dead, 1 = alive)</span></span>
<span><span class="va">z</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="va">y</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">n</span> <span class="op">-</span> <span class="va">y</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Add a continuous covariate (ex: mass)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span>
<span><span class="va">mass</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span>, mean <span class="op">=</span> <span class="fl">5</span>, sd <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>  <span class="co"># mass in kg</span></span>
<span></span>
<span><span class="va">df_bern</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>survival <span class="op">=</span> <span class="va">z</span>, mass <span class="op">=</span> <span class="va">mass</span><span class="op">)</span></span></code></pre></div>
<p>We can now fit the two models with <code>brms</code>, for example (we would get the same thing with <code>NIMBLE</code>): linear regression and logistic regression:</p>
<div class="sourceCode" id="cb100"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Fit linear regression</span></span>
<span><span class="va">fit_lm</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://paulbuerkner.com/brms/reference/brm.html">brm</a></span><span class="op">(</span><span class="va">survival</span> <span class="op">~</span> <span class="va">mass</span>, </span>
<span>              data <span class="op">=</span> <span class="va">df_bern</span>, </span>
<span>              family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html">gaussian</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Fit logistic regression</span></span>
<span><span class="va">fit_logit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://paulbuerkner.com/brms/reference/brm.html">brm</a></span><span class="op">(</span><span class="va">survival</span> <span class="op">~</span> <span class="va">mass</span>, </span>
<span>                 data <span class="op">=</span> <span class="va">df_bern</span>, </span>
<span>                 family <span class="op">=</span> <span class="fu"><a href="https://paulbuerkner.com/brms/reference/brmsfamily.html">bernoulli</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>By the way, interpreting the coefficients of logistic regression is not easy. People often introduce the notion of odds ratios to help, but personally it does not speak to me any more than that. I always come back to a graphical representation of the relationship between the probability of success (survival here) and the explanatory variables (body mass here), as in Figure <a href="glms.html#fig:logit-vs-gaussian">6.3</a>. We observe a positive trend here, but it is due only to the randomness of the simulation (since the data were generated without any effect of body mass). Another intuitive way to deal with this is to use the rule of 4 proposed by Andrew Gelman and colleagues. The trick is to divide the slope of the logistic regression by 4. This gives an approximate estimate of the expected change in probability for a one-unit change in the explanatory variable, at the point where the curve is steepest. If the slope is estimated at 0.23, for example, then the maximum slope of the logistic curve (around the inflection point, where it changes shape) is approximately <span class="math inline">\(0.23/4 = 0.06\)</span>. This means that an increase of one unit in the explanatory variable (here, the coypu’s body mass increases by 1 kg) increases the survival probability by about 6% at the point where the slope is strongest (we go from a survival probability of 0.5 to 0.53), as illustrated in Figure <a href="glms.html#fig:gelman-rule">6.2</a>:</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:gelman-rule"></span>
<img src="06-glms_files/figure-html/gelman-rule-1.png" alt="Illustration of Gelman’s rule of 4. Here, we approximate the effect of coypu body mass on survival probability (the black logistic curve) around the inflection point by a straight line whose slope is given by the estimated coefficient divided by 4 (the red dashed line)." width="90%"><p class="caption">
Figure 6.2: Illustration of Gelman’s rule of 4. Here, we approximate the effect of coypu body mass on survival probability (the black logistic curve) around the inflection point by a straight line whose slope is given by the estimated coefficient divided by 4 (the red dashed line).
</p>
</div>
<p>But I am digressing—let’s return to the problem of applying linear regression to binary data. As you can see in Figure <a href="glms.html#fig:logit-vs-gaussian">6.3</a>, linear regression amounts to fitting an unbounded straight line to binary data, which can lead to survival probabilities greater than 1 (and/or smaller than 0, even if that is not the case here). Logistic regression, by contrast, naturally constrains predictions between 0 and 1 thanks to the logit transformation, making it a suitable choice for success/failure variables. By the way, I used the Bernoulli formulation to introduce an explanatory variable measured at the individual scale, but if that is not necessary, we can go back to the grouped formulation with the binomial distribution as in the previous chapters.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:logit-vs-gaussian"></span>
<img src="06-glms_files/figure-html/logit-vs-gaussian-1.png" alt="Comparison between a linear regression and a logistic regression fitted to binary data. Linear regression (in blue) produces predictions greater than 1 (a problem for a survival probability), whereas logistic regression (in red) guarantees a valid probability estimate." width="90%"><p class="caption">
Figure 6.3: Comparison between a linear regression and a logistic regression fitted to binary data. Linear regression (in blue) produces predictions greater than 1 (a problem for a survival probability), whereas logistic regression (in red) guarantees a valid probability estimate.
</p>
</div>
</div>
<div id="generalized-linear-mixed-models-glmms" class="section level2" number="6.3">
<h2>
<span class="header-section-number">6.3</span> Generalized linear mixed models (GLMMs)<a class="anchor" aria-label="anchor" href="#generalized-linear-mixed-models-glmms"><i class="fas fa-link"></i></a>
</h2>
<div id="introduction-7" class="section level3" number="6.3.1">
<h3>
<span class="header-section-number">6.3.1</span> Introduction<a class="anchor" aria-label="anchor" href="#introduction-7"><i class="fas fa-link"></i></a>
</h3>
<p>Often, data are collected or measured with some structure: they are hierarchical or grouped—for instance, the relationship between coypu survival and their body mass across different populations from different watersheds. In such cases, it is relevant to model this structure in the data. Doing so helps explain variability in mean survival that is not explained by body mass, and thus yields better estimates. To achieve this, we introduce generalized linear mixed models (GLMMs), which combine fixed effects as in GLMs—representing the average effect of an explanatory variable (body mass in the coypu example)—and random effects representing variability among groups or hierarchical levels.</p>
<p>What is a random effect? An effect is random when it represents a random selection of units from a larger population—for example, sampling sites or individuals; if we were to repeat the experiment, the particular sites or individuals would not matter, and what matters is the ability to generalize the interpretation of effects. In this sense, the sex of coypu, for example, cannot be considered a random effect; if we repeat the experiment, the sex variable still has the same two levels, male and female. By contrast, treating the sites within a study area for our coypu as a fixed effect only allows us to say things about these specific sites, without being able to generalize to the “population” of sites, or to the study area.</p>
<p>Along the way, you will see the terms <em>hierarchical models</em>, <em>multilevel models</em>, or <em>random-effects models</em> used to refer to a GLMM in the scientific literature. Sometimes this is exactly the same thing; sometimes it refers to GLMMs that are slightly modified. To avoid confusion, remember that GLMMs are used to analyze data that come with a grouped structure.</p>
</div>
<div id="example" class="section level3" number="6.3.2">
<h3>
<span class="header-section-number">6.3.2</span> Example<a class="anchor" aria-label="anchor" href="#example"><i class="fas fa-link"></i></a>
</h3>
<p>To illustrate a GLMM concretely, imagine the situation where we want to estimate coypu abundance in the Lez watershed, in Montpellier, where the Lez is a river that runs through the city. We lay out ten transects across the study area. On each transect, we count the number of coypu present at ten regularly spaced points. We are interested in how the number of coypu (counts) responds to temperature. The measurements are clearly hierarchical: we take one count at each of the 10 points within each of the 10 transects. The protocol is illustrated in Figure <a href="glms.html#fig:protocole">6.4</a> and is inspired by the book of my colleague Jason Matthiopoulos <span class="citation">(<a href="r%C3%A9f%C3%A9rences.html#ref-matthiopoulosHowBeQuantitative2011">Matthiopoulos 2011</a>)</span>.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:protocole"></span>
<img src="06-glms_files/figure-html/protocole-1.png" alt="Diagram of the coypu data under a sampling protocol with 10 points in 10 transects. The study area is in black. The top panel shows the number of coypu, and the bottom panel shows temperature." width="90%"><p class="caption">
Figure 6.4: Diagram of the coypu data under a sampling protocol with 10 points in 10 transects. The study area is in black. The top panel shows the number of coypu, and the bottom panel shows temperature.
</p>
</div>
<p>Starting from this protocol, let us simulate data with the following script. We will make it a bit more challenging by assuming that, among our ten transects, we had sampling issues on three of them, for which we could only sample two or three points:</p>
<div class="sourceCode" id="cb101"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span> <span class="co"># for reproducibility</span></span>
<span><span class="va">transects</span> <span class="op">&lt;-</span> <span class="fl">10</span> <span class="co"># total number of transects</span></span>
<span><span class="va">nb_points</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">10</span>, <span class="fl">10</span>, <span class="fl">10</span>, <span class="fl">3</span>, <span class="fl">2</span>, <span class="fl">10</span>, <span class="fl">10</span>, <span class="fl">3</span>, <span class="fl">10</span>, <span class="fl">10</span><span class="op">)</span> <span class="co"># number of points per transect</span></span>
<span><span class="va">data</span> <span class="op">&lt;-</span> <span class="cn">NULL</span> <span class="co"># object that will store the simulated data</span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">tr</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">transects</span><span class="op">)</span><span class="op">{</span></span>
<span>  <span class="va">ref</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">0</span>, <span class="fl">.3</span><span class="op">)</span> <span class="co"># transect random effect (N(0, 0.3^2))</span></span>
<span>  <span class="co"># temperature simulated along the transect:</span></span>
<span>  <span class="co"># random starting point between 18 and 22 °C, then a slight slope per segment</span></span>
<span>  <span class="va">t</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">18</span>, <span class="fl">22</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span><span class="fl">1</span>, <span class="op">-</span><span class="fl">0.2</span>, <span class="fl">0.2</span><span class="op">)</span> <span class="op">*</span> <span class="fl">1</span><span class="op">:</span><span class="fl">10</span></span>
<span>  <span class="co"># expected intensity (log scale): linear relationship with temperature</span></span>
<span>  <span class="va">ans</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="va">ref</span> <span class="op">+</span> <span class="fl">0.2</span> <span class="op">*</span> <span class="va">t</span><span class="op">)</span></span>
<span>  <span class="co"># Poisson counts of coypu at each point</span></span>
<span>  <span class="va">an</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Poisson.html">rpois</a></span><span class="op">(</span><span class="va">nb_points</span><span class="op">[</span><span class="va">tr</span><span class="op">]</span>, <span class="va">ans</span><span class="op">)</span></span>
<span>  <span class="co"># stack the points from the current transect</span></span>
<span>  <span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">rbind</a></span><span class="op">(</span><span class="va">data</span>, <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="va">tr</span>, <span class="va">nb_points</span><span class="op">[</span><span class="va">tr</span><span class="op">]</span><span class="op">)</span>, <span class="va">t</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="va">nb_points</span><span class="op">[</span><span class="va">tr</span><span class="op">]</span><span class="op">]</span>, <span class="va">an</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span><span class="co"># put everything into a data.frame</span></span>
<span><span class="va">sim_simple</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span></span>
<span>  Transect    <span class="op">=</span> <span class="va">data</span><span class="op">[</span>, <span class="fl">1</span><span class="op">]</span>,</span>
<span>  Temperature <span class="op">=</span> <span class="va">data</span><span class="op">[</span>, <span class="fl">2</span><span class="op">]</span>,</span>
<span>  Ragondins    <span class="op">=</span> <span class="va">data</span><span class="op">[</span>, <span class="fl">3</span><span class="op">]</span></span>
<span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">sim_simple</span><span class="op">)</span></span>
<span><span class="co">#&gt;   Transect Temperature Ragondins</span></span>
<span><span class="co">#&gt; 1        1    19.78911        54</span></span>
<span><span class="co">#&gt; 2        1    19.94232        46</span></span>
<span><span class="co">#&gt; 3        1    20.09553        47</span></span>
<span><span class="co">#&gt; 4        1    20.24874        60</span></span>
<span><span class="co">#&gt; 5        1    20.40194        53</span></span>
<span><span class="co">#&gt; 6        1    20.55515        42</span></span></code></pre></div>
<p>I have commented the code, which should make it easier to read. Nevertheless, a few explanations of the different steps are in order. We begin with a loop <code>for (tr in 1:transects)</code> that simulates the data for each of the ten transects, one by one. Each time, we draw a transect-specific random effect (<code>ref</code>), which slightly shifts the intercept of the relationship between temperature and the number of coypu depending on the transect. Next, we generate a temperature sequence (<code>t</code>) with a randomly drawn starting point and a small slope that changes temperature slightly from one point to the next. From this temperature, we compute the expected intensity of the counting process (<code>ans</code>) by assuming a linear relationship (on the log scale), and then we generate the observed data (<code>an</code>) by drawing values from a Poisson distribution with mean <code>ans</code>. Finally, we gather everything into a table (<code>sim_simple</code>) so we can analyze it. Figure <a href="glms.html#fig:plotsimple">6.5</a> illustrates the data we obtain:</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:plotsimple"></span>
<img src="06-glms_files/figure-html/plotsimple-1.png" alt="Relationship between the number of coypu and temperature by transect, with multiple count points (10 for all transects, except transects 4, 5, and 8 for which we have 3, 2, and 3 points) per transect." width="90%"><p class="caption">
Figure 6.5: Relationship between the number of coypu and temperature by transect, with multiple count points (10 for all transects, except transects 4, 5, and 8 for which we have 3, 2, and 3 points) per transect.
</p>
</div>
</div>
<div id="the-glm-approach" class="section level3" number="6.3.3">
<h3>
<span class="header-section-number">6.3.3</span> The GLM approach<a class="anchor" aria-label="anchor" href="#the-glm-approach"><i class="fas fa-link"></i></a>
</h3>
<p>We want to analyse these data. Here we are not dealing with binary data as in the beginning of this chapter, but with <strong>count data</strong>. To model this type of response, we use a <strong>Poisson</strong> distribution with a <strong>log link</strong>,
<span class="math inline">\(\log(\theta_i) = \beta_0 + \beta_1\, \text{temp}_i\)</span>, where <span class="math inline">\(\text{temp}_i\)</span> is temperature:</p>
<p><span class="math display">\[\begin{align}
  y_i &amp;\sim \text{Poisson}(\theta_i) &amp;\text{[likelihood]}\\
  \log(\theta_i) &amp;= \beta_{0} + \beta_1 \; \text{temp}_{i} &amp;\text{[linear predictor]} \\
  \theta_i &amp;= \exp(\beta_0 + \beta_1 \; \text{temp}_{i}) &amp;\text{[transformed mean]} \\
  \beta_0, \beta_1 &amp;\sim \text{Normal}(0, 1.5) &amp;\text{[priors]} \\
\end{align}\]</span></p>
<p>This distribution is relatively easy to handle because, among other things, it has a single parameter <span class="math inline">\(\text{theta}\)</span> that gives the rate of occurrence of the event being modelled, and because on average the expected number of coypus here should be equal to that parameter.</p>
<p>In a Poisson GLM, the coefficients <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> are interpreted on the <strong>log scale</strong>. More precisely, a one-unit increase in temperature multiplies the mean number of coypus by <span class="math inline">\(\exp(\beta_1)\)</span>. For instance, if <span class="math inline">\(\beta_1 = 0.3\)</span>, then a one-degree increase corresponds to an expected increase of about <span class="math inline">\(35\%\)</span> in the mean number of coypus, because <span class="math inline">\(\exp(0.3) \approx 1.35\)</span>. We can also visualise the relationship between coypu counts and temperature, as in Figures <a href="glms.html#fig:pooling-coypus">6.8</a> and <a href="glms.html#fig:partial-coypus">6.10</a> below.</p>
<p>In a first model, let us ignore the grouping / multilevel structure in the data (here: transects). We fit a single curve through the point cloud: this is the <strong>complete pooling</strong> model:</p>
<div class="sourceCode" id="cb102"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># do not forget to standardise the temperature covariate</span></span>
<span><span class="va">sim_simple</span><span class="op">$</span><span class="va">Temp</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/scale.html">scale</a></span><span class="op">(</span><span class="va">sim_simple</span><span class="op">$</span><span class="va">Temperature</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># complete pooling model</span></span>
<span><span class="va">fit_complete</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://paulbuerkner.com/brms/reference/brm.html">brm</a></span><span class="op">(</span><span class="va">Ragondins</span> <span class="op">~</span> <span class="va">Temp</span>,</span>
<span>                    data <span class="op">=</span> <span class="va">sim_simple</span>,              <span class="co"># simulated data</span></span>
<span>                    family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html">poisson</a></span><span class="op">(</span><span class="st">"log"</span><span class="op">)</span><span class="op">)</span>         <span class="co"># Poisson distribution, log link</span></span></code></pre></div>
<p>The results are:</p>
<div class="sourceCode" id="cb103"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">fit_complete</span><span class="op">)</span></span>
<span><span class="co">#&gt;  Family: poisson </span></span>
<span><span class="co">#&gt;   Links: mu = log </span></span>
<span><span class="co">#&gt; Formula: Ragondins ~ Temp </span></span>
<span><span class="co">#&gt;    Data: sim_simple (Number of observations: 78) </span></span>
<span><span class="co">#&gt;   Draws: 2 chains, each with iter = 5000; warmup = 1000; thin = 1;</span></span>
<span><span class="co">#&gt;          total post-warmup draws = 8000</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Regression Coefficients:</span></span>
<span><span class="co">#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS</span></span>
<span><span class="co">#&gt; Intercept     4.13      0.01     4.11     4.16 1.00     5374     5177</span></span>
<span><span class="co">#&gt; Temp          0.10      0.01     0.07     0.13 1.00     5936     5368</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS</span></span>
<span><span class="co">#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential</span></span>
<span><span class="co">#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).</span></span></code></pre></div>
<p>Here we ignore that observations are collected by transect, and we incorrectly assume that all observations are independent. The risk is to draw misleading conclusions: we might think there is a single relationship while differences are actually due to transect-to-transect variation, or conversely we might miss a true trend. A model check shows in Figure <a href="glms.html#fig:ppcheck-complete">6.6</a> that the fit is poor:</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:ppcheck-complete"></span>
<img src="06-glms_files/figure-html/ppcheck-complete-1.png" alt="Model-check for the complete pooling model. The x-axis shows possible values of the observed or simulated response. The y-axis shows the estimated density. Simulated distributions (blue) are compared with the observed data (black). Poor overlap indicates a lack of fit." width="90%"><p class="caption">
Figure 6.6: Model-check for the complete pooling model. The x-axis shows possible values of the observed or simulated response. The y-axis shows the estimated density. Simulated distributions (blue) are compared with the observed data (black). Poor overlap indicates a lack of fit.
</p>
</div>
<p>To account for the structure in the data, we can fit another model in which transect is treated as a <strong>fixed effect</strong>. In other words, we fit a separate curve for each transect, with its own intercept, but a common slope:</p>
<div class="sourceCode" id="cb104"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># no pooling model (transect as a fixed effect)</span></span>
<span><span class="va">fit_nopool</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://paulbuerkner.com/brms/reference/brm.html">brm</a></span><span class="op">(</span><span class="va">Ragondins</span> <span class="op">~</span> <span class="va">Temp</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">as.factor</a></span><span class="op">(</span><span class="va">Transect</span><span class="op">)</span>,</span>
<span>                  data <span class="op">=</span> <span class="va">sim_simple</span>,</span>
<span>                  family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html">poisson</a></span><span class="op">(</span><span class="st">"log"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>The results are:</p>
<div class="sourceCode" id="cb105"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">fit_nopool</span><span class="op">)</span></span>
<span><span class="co">#&gt;  Family: poisson </span></span>
<span><span class="co">#&gt;   Links: mu = log </span></span>
<span><span class="co">#&gt; Formula: Ragondins ~ Temp + as.factor(Transect) </span></span>
<span><span class="co">#&gt;    Data: sim_simple (Number of observations: 78) </span></span>
<span><span class="co">#&gt;   Draws: 2 chains, each with iter = 5000; warmup = 1000; thin = 1;</span></span>
<span><span class="co">#&gt;          total post-warmup draws = 8000</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Regression Coefficients:</span></span>
<span><span class="co">#&gt;                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS</span></span>
<span><span class="co">#&gt; Intercept               3.90      0.05     3.81     3.99 1.00     3659     4650</span></span>
<span><span class="co">#&gt; Temp                    0.20      0.06     0.08     0.32 1.00     2684     3611</span></span>
<span><span class="co">#&gt; as.factorTransect2      0.04      0.12    -0.21     0.28 1.00     3001     3973</span></span>
<span><span class="co">#&gt; as.factorTransect3     -0.12      0.07    -0.26     0.03 1.00     4207     5527</span></span>
<span><span class="co">#&gt; as.factorTransect4      0.05      0.11    -0.16     0.26 1.00     3737     4859</span></span>
<span><span class="co">#&gt; as.factorTransect5      0.09      0.10    -0.12     0.29 1.00     5687     5484</span></span>
<span><span class="co">#&gt; as.factorTransect6      0.49      0.10     0.29     0.68 1.00     3009     4224</span></span>
<span><span class="co">#&gt; as.factorTransect7      0.19      0.09     0.02     0.37 1.00     3322     4124</span></span>
<span><span class="co">#&gt; as.factorTransect8      0.08      0.09    -0.09     0.26 1.00     5512     5480</span></span>
<span><span class="co">#&gt; as.factorTransect9      0.28      0.08     0.13     0.43 1.00     3452     4601</span></span>
<span><span class="co">#&gt; as.factorTransect10     0.64      0.06     0.53     0.77 1.00     3729     4715</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS</span></span>
<span><span class="co">#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential</span></span>
<span><span class="co">#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).</span></span></code></pre></div>
<p>Here I told <code>brms</code> to treat transect as a categorical variable (a factor), via <code>as.factor(Transect)</code> in the call to <code><a href="https://paulbuerkner.com/brms/reference/brm.html">brm()</a></code>. By default, the first factor level (here transect 1) is used as the reference. This means that the intercept <span class="math inline">\(\beta_0\)</span> estimated in the model corresponds to transect 1, and the coefficients for other transects represent (on the log scale) deviations relative to transect 1. For example, the intercept for transect 1 is estimated as 3.9. The shift between transect 1 and transect 2 is estimated as 0.04. Therefore, the intercept for transect 2 is: 3.94.</p>
<p>We can repeat this for each transect to obtain transect-specific intercepts, and then exponentiate them to recover the expected mean number of coypus (on the original scale) at <strong>average temperature</strong> (which equals 0 here because temperature has been standardised):</p>
<div class="sourceCode" id="cb106"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># extract the intercept (reference = Transect 1)</span></span>
<span><span class="va">beta0</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/nlme/man/fixed.effects.html">fixef</a></span><span class="op">(</span><span class="va">fit_nopool</span><span class="op">)</span><span class="op">[</span><span class="st">"Intercept"</span>, <span class="st">"Estimate"</span><span class="op">]</span></span>
<span></span>
<span><span class="co"># all model coefficients</span></span>
<span><span class="va">coefs</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/nlme/man/fixed.effects.html">fixef</a></span><span class="op">(</span><span class="va">fit_nopool</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># effects associated with the other transects</span></span>
<span><span class="va">coefs_transects</span> <span class="op">&lt;-</span> <span class="va">coefs</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/grep.html">grep</a></span><span class="op">(</span><span class="st">"as.factor"</span>, <span class="fu"><a href="https://rdrr.io/r/base/colnames.html">rownames</a></span><span class="op">(</span><span class="va">coefs</span><span class="op">)</span><span class="op">)</span>, <span class="st">"Estimate"</span><span class="op">]</span></span>
<span></span>
<span><span class="co"># compute intercepts by transect (on the log scale)</span></span>
<span><span class="va">intercepts_log</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span></span>
<span>  Transect1 <span class="op">=</span> <span class="va">beta0</span>,</span>
<span>  <span class="va">beta0</span> <span class="op">+</span> <span class="va">coefs_transects</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># expected mean counts on the original scale</span></span>
<span><span class="va">means</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="va">intercepts_log</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># summary table</span></span>
<span><span class="va">df_intercepts</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span></span>
<span>  Transect <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="va">intercepts_log</span><span class="op">)</span>,</span>
<span>  Intercept_log <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="va">intercepts_log</span>, <span class="fl">2</span><span class="op">)</span>,</span>
<span>  Mean_count <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="va">means</span>, <span class="fl">2</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># display</span></span>
<span><span class="va">df_intercepts</span></span>
<span><span class="co">#&gt;                                Transect Intercept_log Mean_count</span></span>
<span><span class="co">#&gt; Transect1                     Transect1          3.90      49.60</span></span>
<span><span class="co">#&gt; as.factorTransect2   as.factorTransect2          3.94      51.48</span></span>
<span><span class="co">#&gt; as.factorTransect3   as.factorTransect3          3.79      44.15</span></span>
<span><span class="co">#&gt; as.factorTransect4   as.factorTransect4          3.95      51.94</span></span>
<span><span class="co">#&gt; as.factorTransect5   as.factorTransect5          3.99      54.02</span></span>
<span><span class="co">#&gt; as.factorTransect6   as.factorTransect6          4.39      80.75</span></span>
<span><span class="co">#&gt; as.factorTransect7   as.factorTransect7          4.10      60.22</span></span>
<span><span class="co">#&gt; as.factorTransect8   as.factorTransect8          3.98      53.74</span></span>
<span><span class="co">#&gt; as.factorTransect9   as.factorTransect9          4.19      65.76</span></span>
<span><span class="co">#&gt; as.factorTransect10 as.factorTransect10          4.55      94.53</span></span></code></pre></div>
<p>We indeed estimate one intercept per transect (so 10 intercepts), and a common slope (the temperature effect) shared by all transects. Note that the <code>Mean_count</code> values are Poisson means. They are continuous (possibly non-integer) even though the observed data are integer counts. This is a key feature of Poisson models: the response is discrete, but the model is parameterised through a continuous mean.</p>
<p>The fit is better, as shown in Figure <a href="glms.html#fig:ppcheck-nopool">6.7</a>:</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:ppcheck-nopool"></span>
<img src="06-glms_files/figure-html/ppcheck-nopool-1.png" alt="Model-check for the no pooling model. The x-axis shows possible values of the observed or simulated response. The y-axis shows the estimated density. Simulated distributions (blue) are compared with the observed data (black)." width="90%"><p class="caption">
Figure 6.7: Model-check for the no pooling model. The x-axis shows possible values of the observed or simulated response. The y-axis shows the estimated density. Simulated distributions (blue) are compared with the observed data (black).
</p>
</div>
<p>This <strong>no pooling</strong> model improves on the <strong>complete pooling</strong> model (Figure <a href="glms.html#fig:pooling-coypus">6.8</a>), but it remains unsatisfying. No pooling means fitting an independent model for each transect, without sharing information across groups. This creates two issues: (i) we cannot generalise conclusions beyond the specific transects observed, and (ii) we potentially waste information by assuming that each transect has nothing to learn from the others. This strategy becomes especially inefficient when some groups have few observations.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:pooling-coypus"></span>
<img src="06-glms_files/figure-html/pooling-coypus-1.png" alt="Comparison between complete pooling (black) and no pooling (red) models to predict coypu counts as a function of temperature, by transect. The no pooling model fits an independent curve for each transect, whereas complete pooling assumes a common relationship." width="90%"><p class="caption">
Figure 6.8: Comparison between complete pooling (black) and no pooling (red) models to predict coypu counts as a function of temperature, by transect. The no pooling model fits an independent curve for each transect, whereas complete pooling assumes a common relationship.
</p>
</div>
</div>
<div id="the-glmm-approach" class="section level3" number="6.3.4">
<h3>
<span class="header-section-number">6.3.4</span> The GLMM approach<a class="anchor" aria-label="anchor" href="#the-glmm-approach"><i class="fas fa-link"></i></a>
</h3>
<p>Let us return to our objective: assess the effect of temperature on coypu abundance while accounting for the hierarchical structure of the data (segments nested within transects). So far, the complete pooling and no pooling models represented two extremes: either all transects share exactly the same temperature–abundance relationship, or each transect has a completely independent relationship (via a transect-specific intercept). <strong>Generalised linear mixed models (GLMMs)</strong> implement a more realistic compromise, often called <strong>partial pooling</strong>.</p>
<p>We build a GLMM where each transect has its own intercept—i.e., its own baseline abundance—but these intercepts are not treated as unrelated. Instead, they are modelled as random deviations around a global intercept <span class="math inline">\(\beta_0\)</span>, drawn from a common normal distribution. This means that the transect-specific intercepts <span class="math inline">\(\beta_{0j}\)</span> (with <span class="math inline">\(j = 1,\dots,10\)</span>) are viewed as coming from a larger population of possible transects, where baseline abundance varies across space. We capture this heterogeneity with a random effect, written here as <span class="math inline">\(\beta_{0j} \sim \text{Normal}(\beta_0, \sigma)\)</span>, where <span class="math inline">\(\sigma\)</span> is the between-transect variability.</p>
<p>Equivalently, each transect intercept can be written as <span class="math inline">\(\beta_{0j} = \beta_0 + b_j\)</span>, with <span class="math inline">\(b_j \sim \text{Normal}(0, \sigma)\)</span>. Here <span class="math inline">\(\beta_0\)</span> is the intercept for a “typical” transect, and <span class="math inline">\(\sigma\)</span> quantifies how much transects vary around that mean. For instance, if <span class="math inline">\(\beta_0 = 2\)</span> but transect 4 has <span class="math inline">\(\beta_{04} = 3\)</span>, then the transect-specific deviation is <span class="math inline">\(b_4 = 1\)</span>, corresponding to higher-than-average abundance.</p>
<p>This hierarchical structure shares information across groups, which is particularly useful when some transects have few observations. You can also view the partial pooling model (3 parameters estimated here: <span class="math inline">\(\beta_0, \beta_1, \sigma\)</span>) as a compromise between the complete pooling model (2 parameters: <span class="math inline">\(\beta_0, \beta_1\)</span>) and the no pooling model (11 parameters: 10 intercepts and 1 common slope <span class="math inline">\(\beta_1\)</span>).</p>
<p>Formally, the GLMM can be written as:</p>
<p><span class="math display">\[\begin{align}
  y_i &amp;\sim \text{Poisson}(\theta_i) &amp;\text{[likelihood]}\\
  \log(\theta_i) &amp;= \beta_{0j} + \beta_1 \; \text{temp}_{i} &amp;\text{[linear predictor]} \\
  \beta_{0j} &amp;\sim \text{Normal}(\beta_0, \sigma) &amp;\text{[random effect]} \\
  \beta_0 &amp;\sim \text{Normal}(0, 1.5) &amp;\text{[prior for the mean intercept]} \\
  \sigma &amp;\sim \text{Exp}(1) &amp;\text{[prior for the random-effect SD]} \\
  \beta_1 &amp;\sim \text{Normal}(0, 1.5) &amp;\text{[prior for the slope]} \\
\end{align}\]</span></p>
<div id="fitting-the-model-with-brms" class="section level4" number="6.3.4.1">
<h4>
<span class="header-section-number">6.3.4.1</span> Fitting the model with <code>brms</code><a class="anchor" aria-label="anchor" href="#fitting-the-model-with-brms"><i class="fas fa-link"></i></a>
</h4>
<p>We first fit the partial pooling GLMM with <code>brms</code>:</p>
<div class="sourceCode" id="cb107"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># partial pooling model (transect random intercept)</span></span>
<span><span class="va">fit_partial</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://paulbuerkner.com/brms/reference/brm.html">brm</a></span><span class="op">(</span><span class="va">Ragondins</span> <span class="op">~</span> <span class="va">Temp</span> <span class="op">+</span> <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">Transect</span><span class="op">)</span>, <span class="co"># count ~ temperature with a transect random intercept</span></span>
<span>                   data <span class="op">=</span> <span class="va">sim_simple</span>,</span>
<span>                   family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html">poisson</a></span><span class="op">(</span><span class="st">"log"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>In this syntax, the random intercept is specified as <code>(1 | Transect)</code>, where <code>1</code> means we are modelling the intercept, and <code>|</code> indicates “one intercept per transect”. If we wanted to include a random slope as well, we would write <code>(1 + Temp | Transect)</code>.</p>
<p>The results are:</p>
<div class="sourceCode" id="cb108"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">fit_partial</span><span class="op">)</span></span>
<span><span class="co">#&gt;  Family: poisson </span></span>
<span><span class="co">#&gt;   Links: mu = log </span></span>
<span><span class="co">#&gt; Formula: Ragondins ~ Temp + (1 | Transect) </span></span>
<span><span class="co">#&gt;    Data: sim_simple (Number of observations: 78) </span></span>
<span><span class="co">#&gt;   Draws: 2 chains, each with iter = 5000; warmup = 1000; thin = 1;</span></span>
<span><span class="co">#&gt;          total post-warmup draws = 8000</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Multilevel Hyperparameters:</span></span>
<span><span class="co">#&gt; ~Transect (Number of levels: 10) </span></span>
<span><span class="co">#&gt;               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS</span></span>
<span><span class="co">#&gt; sd(Intercept)     0.27      0.08     0.16     0.47 1.00     2119     3183</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Regression Coefficients:</span></span>
<span><span class="co">#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS</span></span>
<span><span class="co">#&gt; Intercept     4.09      0.09     3.92     4.27 1.00     2087     2747</span></span>
<span><span class="co">#&gt; Temp          0.17      0.05     0.06     0.27 1.00     3559     4119</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS</span></span>
<span><span class="co">#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential</span></span>
<span><span class="co">#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).</span></span></code></pre></div>
<p>This summary reports posterior estimates for the fixed effects and the standard deviations of the random effects. The line <code>sd(Intercept)</code> corresponds to <span class="math inline">\(\sigma\)</span>, close to the value 0.3 used to simulate the data (the credible interval includes the true value). The lines <code>Intercept</code> and <code>Temp</code> provide estimates of <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> on the log scale. We will see below how to check that these estimates are close to the values used in simulation.</p>
<p>We can also inspect posterior densities and trace plots (Figure <a href="glms.html#fig:model-diagnostics">6.9</a>):</p>
<div class="sourceCode" id="cb109"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">fit_partial</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:model-diagnostics"></span>
<img src="06-glms_files/figure-html/model-diagnostics-1.png" alt="Convergence diagnostics for the partial pooling model. In the histograms (left column), the x-axis shows possible parameter values (intercept, slope, or SD) and the y-axis shows their frequency in the posterior sample. In the trace plots (right column), the x-axis shows the MCMC iteration and the y-axis shows the sampled parameter value." width="90%"><p class="caption">
Figure 6.9: Convergence diagnostics for the partial pooling model. In the histograms (left column), the x-axis shows possible parameter values (intercept, slope, or SD) and the y-axis shows their frequency in the posterior sample. In the trace plots (right column), the x-axis shows the MCMC iteration and the y-axis shows the sampled parameter value.
</p>
</div>
<p>We can now update Figure <a href="glms.html#fig:pooling-coypus">6.8</a> with Figure <a href="glms.html#fig:partial-coypus">6.10</a>:</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:partial-coypus"></span>
<img src="06-glms_files/figure-html/partial-coypus-1.png" alt="Comparison among complete pooling (black), no pooling (red), and partial pooling (blue) models to predict coypu counts as a function of temperature, by transect. No pooling fits a separate curve for each transect, complete pooling assumes a common relationship, and partial pooling provides a compromise via a transect random effect." width="90%"><p class="caption">
Figure 6.10: Comparison among complete pooling (black), no pooling (red), and partial pooling (blue) models to predict coypu counts as a function of temperature, by transect. No pooling fits a separate curve for each transect, complete pooling assumes a common relationship, and partial pooling provides a compromise via a transect random effect.
</p>
</div>
<p>We see that the partial pooling fit is very similar to the no pooling fit, and much better than complete pooling. There is a small difference for transects with few sampling points (transects 4, 5, and 8): for those, partial pooling is closer to complete pooling. In the absence of much information for these transects, it is reasonable that their estimates are pulled toward the overall mean rather than toward extreme, transect-specific values.</p>
<p>This is the information-sharing mechanism known as <strong>borrowing strength</strong>. It leads to <strong>shrinkage</strong>, which buffers the tendency of the no pooling (fixed-effect) model to overfit. In that sense, partial pooling also provides a form of <strong>regularisation</strong>.</p>
<p>Model fit is validated in Figure <a href="glms.html#fig:ppcheck-partial">6.11</a>:</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:ppcheck-partial"></span>
<img src="06-glms_files/figure-html/ppcheck-partial-1.png" alt="Model-check for the partial pooling model. The x-axis shows possible values of the observed or simulated response. The y-axis shows the estimated density. Simulated distributions (blue) are compared with the observed data (black)." width="90%"><p class="caption">
Figure 6.11: Model-check for the partial pooling model. The x-axis shows possible values of the observed or simulated response. The y-axis shows the estimated density. Simulated distributions (blue) are compared with the observed data (black).
</p>
</div>
<p>When fitting a model with a standardised predictor (here, temperature), coefficients <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> are interpreted on that modified scale: <span class="math inline">\(\beta_1\)</span> corresponds to a one-standard-deviation change in temperature, and <span class="math inline">\(\beta_0\)</span> corresponds to the expected value when standardised temperature equals 0 (i.e., at mean temperature). In practice we often want effects in natural units (degrees Celsius) rather than in standard deviations. We can convert coefficients back to the original scale using:</p>
<p><span class="math display">\[
\beta_1^{\text{original}} = \frac{\beta_1^{\text{standardised}}}{\text{SD}(\text{temperature})}
\]</span></p>
<p><span class="math display">\[
\beta_0^{\text{original}} = \beta_0^{\text{standardised}} - \beta_1^{\text{standardised}} \times \frac{\text{Mean}(\text{temperature})}{\text{SD}(\text{temperature})}
\]</span></p>
<p>In <code>R</code>, you can use:</p>
<div class="sourceCode" id="cb110"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># extract posterior draws for fixed effects</span></span>
<span><span class="va">post</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/posterior/reference/draws_matrix.html">as_draws_matrix</a></span><span class="op">(</span><span class="va">fit_partial</span><span class="op">)</span></span>
<span><span class="va">sbzero</span> <span class="op">&lt;-</span> <span class="va">post</span><span class="op">[</span>, <span class="st">"b_Intercept"</span><span class="op">]</span></span>
<span><span class="va">sbun</span>   <span class="op">&lt;-</span> <span class="va">post</span><span class="op">[</span>, <span class="st">"b_Temp"</span><span class="op">]</span></span>
<span></span>
<span><span class="co"># mean and SD of temperature</span></span>
<span><span class="va">mu</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/attr.html">attr</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/scale.html">scale</a></span><span class="op">(</span><span class="va">sim_simple</span><span class="op">$</span><span class="va">Temperature</span><span class="op">)</span>, <span class="st">"scaled:center"</span><span class="op">)</span></span>
<span><span class="va">sg</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/attr.html">attr</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/scale.html">scale</a></span><span class="op">(</span><span class="va">sim_simple</span><span class="op">$</span><span class="va">Temperature</span><span class="op">)</span>, <span class="st">"scaled:scale"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># convert standardised coefficients to the original scale</span></span>
<span><span class="va">bun</span>   <span class="op">&lt;-</span> <span class="va">sbun</span> <span class="op">/</span> <span class="va">sg</span>                 <span class="co"># beta1 (original scale)</span></span>
<span><span class="va">bzero</span> <span class="op">&lt;-</span> <span class="va">sbzero</span> <span class="op">-</span> <span class="va">sbun</span> <span class="op">*</span> <span class="va">mu</span> <span class="op">/</span> <span class="va">sg</span>   <span class="co"># beta0 (original scale)</span></span></code></pre></div>
<p>We can then visualise coefficients on the original scale and compare them to the values used for simulation (Figures <a href="glms.html#fig:hist-b0-original-brms">6.12</a> and <a href="glms.html#fig:hist-b1-original-brms">6.13</a>):</p>
<div class="sourceCode" id="cb111"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">tibble</span><span class="op">(</span>b0 <span class="op">=</span> <span class="va">bzero</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">b0</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_histogram</span><span class="op">(</span>color <span class="op">=</span> <span class="st">"white"</span>, fill <span class="op">=</span> <span class="st">"skyblue"</span>, bins <span class="op">=</span> <span class="fl">30</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_vline</span><span class="op">(</span>xintercept <span class="op">=</span> <span class="fl">0</span>, color <span class="op">=</span> <span class="st">"red"</span>, linewidth <span class="op">=</span> <span class="fl">1.2</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span></span>
<span>    x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="va">beta</span><span class="op">[</span><span class="fl">0</span><span class="op">]</span><span class="op">)</span>,</span>
<span>    y <span class="op">=</span> <span class="st">"Frequency"</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme_minimal</span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:hist-b0-original-brms"></span>
<img src="06-glms_files/figure-html/hist-b0-original-brms-1.png" alt="Posterior distribution of the mean intercept (original scale). The red line indicates the true value (0)." width="90%"><p class="caption">
Figure 6.12: Posterior distribution of the mean intercept (original scale). The red line indicates the true value (0).
</p>
</div>
<div class="sourceCode" id="cb112"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">tibble</span><span class="op">(</span>b1 <span class="op">=</span> <span class="va">bun</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">b1</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_histogram</span><span class="op">(</span>color <span class="op">=</span> <span class="st">"white"</span>, fill <span class="op">=</span> <span class="st">"skyblue"</span>, bins <span class="op">=</span> <span class="fl">30</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_vline</span><span class="op">(</span>xintercept <span class="op">=</span> <span class="fl">0.2</span>, color <span class="op">=</span> <span class="st">"red"</span>, linewidth <span class="op">=</span> <span class="fl">1.2</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span></span>
<span>    x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="va">beta</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span>,</span>
<span>    y <span class="op">=</span> <span class="st">"Frequency"</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme_minimal</span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:hist-b1-original-brms"></span>
<img src="06-glms_files/figure-html/hist-b1-original-brms-1.png" alt="Posterior distribution of the temperature effect (original scale). The red line indicates the true value (0.2)." width="90%"><p class="caption">
Figure 6.13: Posterior distribution of the temperature effect (original scale). The red line indicates the true value (0.2).
</p>
</div>
<p>We recover the parameters used to simulate the data (in red). This is only one simulation run, so it is normal that the posterior mode does not coincide exactly with the true value. Repeating the simulation many times would allow us to assess bias and variability more formally.</p>
<p>As a bonus, let us compare models with and without a temperature effect. This evaluates whether temperature is a useful predictor:</p>
<div class="sourceCode" id="cb113"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># partial pooling model without temperature</span></span>
<span><span class="va">fit_partial2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://paulbuerkner.com/brms/reference/brm.html">brm</a></span><span class="op">(</span><span class="va">Ragondins</span> <span class="op">~</span> <span class="fl">1</span> <span class="op">+</span> <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">Transect</span><span class="op">)</span>,</span>
<span>                    data <span class="op">=</span> <span class="va">sim_simple</span>,</span>
<span>                    family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html">poisson</a></span><span class="op">(</span><span class="st">"log"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>We compute WAIC for each model and compare:</p>
<div class="sourceCode" id="cb114"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">waic1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/loo/reference/waic.html">waic</a></span><span class="op">(</span><span class="va">fit_partial</span><span class="op">)</span></span>
<span><span class="va">waic2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/loo/reference/waic.html">waic</a></span><span class="op">(</span><span class="va">fit_partial2</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">tibble</span><span class="op">(</span></span>
<span>  Model <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"With temperature"</span>, <span class="st">"Without temperature"</span><span class="op">)</span>,</span>
<span>  WAIC  <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">waic1</span><span class="op">$</span><span class="va">estimates</span><span class="op">[</span><span class="st">"waic"</span>, <span class="st">"Estimate"</span><span class="op">]</span>,</span>
<span>            <span class="va">waic2</span><span class="op">$</span><span class="va">estimates</span><span class="op">[</span><span class="st">"waic"</span>, <span class="st">"Estimate"</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; # A tibble: 2 × 2</span></span>
<span><span class="co">#&gt;   Model                WAIC</span></span>
<span><span class="co">#&gt;   &lt;chr&gt;               &lt;dbl&gt;</span></span>
<span><span class="co">#&gt; 1 With temperature     542.</span></span>
<span><span class="co">#&gt; 2 Without temperature  551.</span></span></code></pre></div>
<p>In conclusion, the model including temperature provides a better fit according to WAIC—which is reassuring since the data were simulated under that model.</p>
</div>
<div id="fitting-the-model-with-nimble" class="section level4" number="6.3.4.2">
<h4>
<span class="header-section-number">6.3.4.2</span> Fitting the model with <code>NIMBLE</code><a class="anchor" aria-label="anchor" href="#fitting-the-model-with-nimble"><i class="fas fa-link"></i></a>
</h4>
<p>We now repeat the analysis with a GLMM in <code>NIMBLE</code>. We start by writing the model code:</p>
<div class="sourceCode" id="cb115"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/nimble/man/nimbleCode.html">nimbleCode</a></span><span class="op">(</span><span class="op">{</span></span>
<span>  <span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">n</span><span class="op">)</span><span class="op">{</span></span>
<span>    <span class="va">count</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Poisson.html">dpois</a></span><span class="op">(</span><span class="va">theta</span><span class="op">[</span><span class="va">i</span><span class="op">]</span><span class="op">)</span>                <span class="co"># Poisson likelihood</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">theta</span><span class="op">[</span><span class="va">i</span><span class="op">]</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="va">intercept</span><span class="op">[</span><span class="va">transect</span><span class="op">[</span><span class="va">i</span><span class="op">]</span><span class="op">]</span> <span class="op">+</span> <span class="co"># random intercept by transect</span></span>
<span>                     <span class="va">beta1</span> <span class="op">*</span> <span class="va">x</span><span class="op">[</span><span class="va">i</span><span class="op">]</span>             <span class="co"># temperature effect</span></span>
<span>  <span class="op">}</span></span>
<span></span>
<span>  <span class="kw">for</span> <span class="op">(</span><span class="va">j</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">nbtransects</span><span class="op">)</span><span class="op">{</span></span>
<span>    <span class="va">intercept</span><span class="op">[</span><span class="va">j</span><span class="op">]</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">beta0</span>, sd <span class="op">=</span> <span class="va">sigma</span><span class="op">)</span>   <span class="co"># intercepts ~ Normal(beta0, sigma)</span></span>
<span>  <span class="op">}</span></span>
<span></span>
<span>  <span class="va">beta0</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1.5</span><span class="op">)</span>                  <span class="co"># prior for the mean intercept</span></span>
<span>  <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Exponential.html">dexp</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span>                             <span class="co"># prior for the random-effect SD</span></span>
<span>  <span class="va">beta1</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1.5</span><span class="op">)</span>                  <span class="co"># prior for the slope</span></span>
<span><span class="op">}</span><span class="op">)</span></span></code></pre></div>
<p>Let us comment briefly on this code. In the loop <code>for (i in 1:n)</code>, we define a Poisson likelihood for each observation, <code>count[i] ~ dpois(theta[i])</code>. The intensity <code>theta[i]</code> (the expected number of coypus) depends on two components: <code>intercept[transect[i]]</code> is the intercept specific to the transect to which observation <span class="math inline">\(i\)</span> belongs, and <code>beta1 * x[i]</code> is the linear temperature effect.</p>
<p>The term <code>intercept[transect[i]]</code> illustrates <strong>nested indexing</strong>: for each observation <span class="math inline">\(i\)</span>, we retrieve the appropriate intercept from a vector of transect-specific intercepts (<code>intercept[j]</code>) using the index <code>transect[i]</code>. The vector <code>transect</code> contains, for each observation <span class="math inline">\(i\)</span>, the identifier of the transect it belongs to. For example, if observation 5 belongs to transect 3, then <code>transect[5] = 3</code> and we use <code>intercept[3]</code>. This avoids writing a double loop over transects: each observation dynamically picks the intercept that corresponds to its group.</p>
<p>The block <code>for (j in 1:nbtransects){ intercept[j] ~ dnorm(beta0, sd = sigma) }</code> defines the hierarchical structure: transect intercepts are not estimated independently (as in a fixed-effect model), but are treated as random draws around a global mean <code>beta0</code>, with between-transect variability <code>sigma</code>.</p>
<p>We read constants and data:</p>
<div class="sourceCode" id="cb116"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">my.constants</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span></span>
<span>  n <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">sim_simple</span><span class="op">)</span>,       <span class="co"># number of observations</span></span>
<span>  nbtransects <span class="op">=</span> <span class="va">transects</span>     <span class="co"># number of transects</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">my.data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span></span>
<span>  x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/vector.html">as.vector</a></span><span class="op">(</span><span class="va">sim_simple</span><span class="op">$</span><span class="va">Temp</span><span class="op">)</span>,               <span class="co"># standardised covariate</span></span>
<span>  count <span class="op">=</span> <span class="va">sim_simple</span><span class="op">$</span><span class="va">Ragondins</span>,                 <span class="co"># counts</span></span>
<span>  transect <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="va">sim_simple</span><span class="op">$</span><span class="va">Transect</span><span class="op">)</span>    <span class="co"># transect ID</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>We specify initial values for two MCMC chains:</p>
<div class="sourceCode" id="cb117"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">init1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span></span>
<span>  intercept <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">transects</span><span class="op">)</span>,</span>
<span>  beta1 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span>,</span>
<span>  beta0 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span>,</span>
<span>  sigma <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Exponential.html">rexp</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">init2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span></span>
<span>  intercept <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">transects</span><span class="op">)</span>,</span>
<span>  beta1 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span>,</span>
<span>  beta0 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span>,</span>
<span>  sigma <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Exponential.html">rexp</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">initial.values</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="va">init1</span>, <span class="va">init2</span><span class="op">)</span></span></code></pre></div>
<p>We also specify parameters to monitor and MCMC settings:</p>
<div class="sourceCode" id="cb118"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">parameters.to.save</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"beta1"</span>, <span class="st">"beta0"</span>, <span class="st">"sigma"</span><span class="op">)</span></span>
<span><span class="va">n.iter</span>   <span class="op">&lt;-</span> <span class="fl">5000</span>   <span class="co"># total iterations</span></span>
<span><span class="va">n.burnin</span> <span class="op">&lt;-</span> <span class="fl">1000</span>   <span class="co"># burn-in</span></span>
<span><span class="va">n.chains</span> <span class="op">&lt;-</span> <span class="fl">2</span>      <span class="co"># number of chains</span></span></code></pre></div>
<p>Finally, we run <code>NIMBLE</code>:</p>
<div class="sourceCode" id="cb119"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mcmc.output</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/nimble/man/nimbleMCMC.html">nimbleMCMC</a></span><span class="op">(</span></span>
<span>  code <span class="op">=</span> <span class="va">model</span>,</span>
<span>  data <span class="op">=</span> <span class="va">my.data</span>,</span>
<span>  constants <span class="op">=</span> <span class="va">my.constants</span>,</span>
<span>  inits <span class="op">=</span> <span class="va">initial.values</span>,</span>
<span>  monitors <span class="op">=</span> <span class="va">parameters.to.save</span>,</span>
<span>  niter <span class="op">=</span> <span class="va">n.iter</span>,</span>
<span>  nburnin <span class="op">=</span> <span class="va">n.burnin</span>,</span>
<span>  nchains <span class="op">=</span> <span class="va">n.chains</span>,</span>
<span>  progressBar <span class="op">=</span> <span class="cn">FALSE</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>The results are:</p>
<div class="sourceCode" id="cb120"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/MCMCvis/man/MCMCsummary.html">MCMCsummary</a></span><span class="op">(</span>object <span class="op">=</span> <span class="va">mcmc.output</span>, round <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="co">#&gt;       mean   sd 2.5%  50% 97.5% Rhat n.eff</span></span>
<span><span class="co">#&gt; beta0 4.07 0.09 3.88 4.07  4.24 1.00  4587</span></span>
<span><span class="co">#&gt; beta1 0.17 0.05 0.07 0.16  0.28 1.03    77</span></span>
<span><span class="co">#&gt; sigma 0.26 0.08 0.16 0.25  0.46 1.00   856</span></span></code></pre></div>
<p>As with <code>brms</code>, coefficients are estimated on the standardised temperature scale. To return to the original scale we use:</p>
<p><span class="math display">\[
\beta_1^{\text{original}} = \frac{\beta_1^{\text{standardised}}}{\text{SD}(\text{temperature})}
\]</span></p>
<p><span class="math display">\[
\beta_0^{\text{original}} = \beta_0^{\text{standardised}} - \beta_1^{\text{standardised}} \times \frac{\text{Mean}(\text{temperature})}{\text{SD}(\text{temperature})}
\]</span></p>
<p>In <code>R</code>:</p>
<div class="sourceCode" id="cb121"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># concatenate the two chains</span></span>
<span><span class="va">samples</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">rbind</a></span><span class="op">(</span><span class="va">mcmc.output</span><span class="op">$</span><span class="va">chain1</span>, <span class="va">mcmc.output</span><span class="op">$</span><span class="va">chain2</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># posterior draws for coefficients (standardised scale)</span></span>
<span><span class="va">sbzero</span> <span class="op">&lt;-</span> <span class="va">samples</span><span class="op">[</span>, <span class="st">"beta0"</span><span class="op">]</span>  <span class="co"># beta0 (standardised)</span></span>
<span><span class="va">sbun</span>   <span class="op">&lt;-</span> <span class="va">samples</span><span class="op">[</span>, <span class="st">"beta1"</span><span class="op">]</span>  <span class="co"># beta1 (standardised)</span></span>
<span></span>
<span><span class="co"># mean and SD of temperature</span></span>
<span><span class="va">mu</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/attr.html">attr</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/scale.html">scale</a></span><span class="op">(</span><span class="va">sim_simple</span><span class="op">$</span><span class="va">Temperature</span><span class="op">)</span>, <span class="st">"scaled:center"</span><span class="op">)</span></span>
<span><span class="va">sg</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/attr.html">attr</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/scale.html">scale</a></span><span class="op">(</span><span class="va">sim_simple</span><span class="op">$</span><span class="va">Temperature</span><span class="op">)</span>, <span class="st">"scaled:scale"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># convert to original scale</span></span>
<span><span class="va">bun</span>   <span class="op">&lt;-</span> <span class="va">sbun</span> <span class="op">/</span> <span class="va">sg</span>                 <span class="co"># beta1 (original scale)</span></span>
<span><span class="va">bzero</span> <span class="op">&lt;-</span> <span class="va">sbzero</span> <span class="op">-</span> <span class="va">sbun</span> <span class="op">*</span> <span class="va">mu</span> <span class="op">/</span> <span class="va">sg</span>   <span class="co"># beta0 (original scale)</span></span></code></pre></div>
<p>We can then visualise coefficients on the original scale and compare to the simulation values (Figures <a href="glms.html#fig:hist-b0-original">6.14</a> and <a href="glms.html#fig:hist-b1-original">6.15</a>):</p>
<div class="sourceCode" id="cb122"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">tibble</span><span class="op">(</span>b0 <span class="op">=</span> <span class="va">bzero</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">b0</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_histogram</span><span class="op">(</span>color <span class="op">=</span> <span class="st">"white"</span>, fill <span class="op">=</span> <span class="st">"skyblue"</span>, bins <span class="op">=</span> <span class="fl">30</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_vline</span><span class="op">(</span>xintercept <span class="op">=</span> <span class="fl">0</span>, color <span class="op">=</span> <span class="st">"red"</span>, linewidth <span class="op">=</span> <span class="fl">1.2</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span></span>
<span>    x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="va">beta</span><span class="op">[</span><span class="fl">0</span><span class="op">]</span><span class="op">)</span>,</span>
<span>    y <span class="op">=</span> <span class="st">"Frequency"</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme_minimal</span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:hist-b0-original"></span>
<img src="06-glms_files/figure-html/hist-b0-original-1.png" alt="Posterior distribution of the mean intercept (original scale). The red line indicates the true value (0)." width="90%"><p class="caption">
Figure 6.14: Posterior distribution of the mean intercept (original scale). The red line indicates the true value (0).
</p>
</div>
<div class="sourceCode" id="cb123"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">tibble</span><span class="op">(</span>b1 <span class="op">=</span> <span class="va">bun</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">b1</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_histogram</span><span class="op">(</span>color <span class="op">=</span> <span class="st">"white"</span>, fill <span class="op">=</span> <span class="st">"skyblue"</span>, bins <span class="op">=</span> <span class="fl">30</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_vline</span><span class="op">(</span>xintercept <span class="op">=</span> <span class="fl">0.2</span>, color <span class="op">=</span> <span class="st">"red"</span>, linewidth <span class="op">=</span> <span class="fl">1.2</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span></span>
<span>    x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="va">beta</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span>,</span>
<span>    y <span class="op">=</span> <span class="st">"Frequency"</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme_minimal</span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:hist-b1-original"></span>
<img src="06-glms_files/figure-html/hist-b1-original-1.png" alt="Posterior distribution of the temperature effect (original scale). The red line indicates the true value (0.2)." width="90%"><p class="caption">
Figure 6.15: Posterior distribution of the temperature effect (original scale). The red line indicates the true value (0.2).
</p>
</div>
<p>We recover the parameters used to simulate the data (in red). As with <code>brms</code>, we ran only one simulation, so it is normal not to match the true values exactly. Repeating simulations many times would provide a more formal assessment.</p>
<p>Let us compare models with and without temperature using WAIC. We need to fit the model without temperature:</p>
<div class="sourceCode" id="cb124"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># model code without temperature</span></span>
<span><span class="va">model.null</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/nimble/man/nimbleCode.html">nimbleCode</a></span><span class="op">(</span><span class="op">{</span></span>
<span>  <span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">n</span><span class="op">)</span><span class="op">{</span></span>
<span>    <span class="va">count</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Poisson.html">dpois</a></span><span class="op">(</span><span class="va">theta</span><span class="op">[</span><span class="va">i</span><span class="op">]</span><span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">theta</span><span class="op">[</span><span class="va">i</span><span class="op">]</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="va">intercept</span><span class="op">[</span><span class="va">transect</span><span class="op">[</span><span class="va">i</span><span class="op">]</span><span class="op">]</span></span>
<span>  <span class="op">}</span></span>
<span>  <span class="kw">for</span> <span class="op">(</span><span class="va">j</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">nbtransects</span><span class="op">)</span><span class="op">{</span></span>
<span>    <span class="va">intercept</span><span class="op">[</span><span class="va">j</span><span class="op">]</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">beta0</span>, sd <span class="op">=</span> <span class="va">sigma</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span>  <span class="va">beta0</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1.5</span><span class="op">)</span></span>
<span>  <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Exponential.html">dexp</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span></span>
<span><span class="op">}</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># run the null model</span></span>
<span><span class="va">parameters.null</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"beta0"</span>, <span class="st">"sigma"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">mcmc.null</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/nimble/man/nimbleMCMC.html">nimbleMCMC</a></span><span class="op">(</span></span>
<span>  code <span class="op">=</span> <span class="va">model.null</span>,</span>
<span>  data <span class="op">=</span> <span class="va">my.data</span>,</span>
<span>  constants <span class="op">=</span> <span class="va">my.constants</span>,</span>
<span>  inits <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>beta0 <span class="op">=</span> <span class="fl">0</span>, sigma <span class="op">=</span> <span class="fl">1</span>, intercept <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">transects</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  monitors <span class="op">=</span> <span class="va">parameters.null</span>,</span>
<span>  niter <span class="op">=</span> <span class="va">n.iter</span>,</span>
<span>  nburnin <span class="op">=</span> <span class="va">n.burnin</span>,</span>
<span>  nchains <span class="op">=</span> <span class="va">n.chains</span>,</span>
<span>  progressBar <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  WAIC <span class="op">=</span> <span class="cn">TRUE</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt;   [Warning] There are 3 individual pWAIC values that are greater than 0.4. This may indicate that the WAIC estimate is unstable (Vehtari et al., 2017), at least in cases without grouping of data nodes or multivariate data nodes.</span></span></code></pre></div>
<p>We also need to rerun the full model with <code>WAIC = TRUE</code> (not shown here).</p>
<p>We can then compare WAIC:</p>
<div class="sourceCode" id="cb125"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># WAIC values</span></span>
<span><span class="va">waic.full</span> <span class="op">&lt;-</span> <span class="va">mcmc.output</span><span class="op">$</span><span class="va">WAIC</span><span class="op">$</span><span class="va">WAIC</span></span>
<span><span class="va">waic.null</span> <span class="op">&lt;-</span> <span class="va">mcmc.null</span><span class="op">$</span><span class="va">WAIC</span><span class="op">$</span><span class="va">WAIC</span></span>
<span></span>
<span><span class="co"># comparison table</span></span>
<span><span class="fu">tibble</span><span class="op">(</span></span>
<span>  Model <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"With temperature"</span>, <span class="st">"Without temperature"</span><span class="op">)</span>,</span>
<span>  WAIC  <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">waic.full</span>, <span class="va">waic.null</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; # A tibble: 2 × 2</span></span>
<span><span class="co">#&gt;   Model                WAIC</span></span>
<span><span class="co">#&gt;   &lt;chr&gt;               &lt;dbl&gt;</span></span>
<span><span class="co">#&gt; 1 With temperature     542.</span></span>
<span><span class="co">#&gt; 2 Without temperature  552.</span></span></code></pre></div>
</div>
<div id="frequentist-fit-with-lme4" class="section level4" number="6.3.4.3">
<h4>
<span class="header-section-number">6.3.4.3</span> Frequentist fit with <code>lme4</code><a class="anchor" aria-label="anchor" href="#frequentist-fit-with-lme4"><i class="fas fa-link"></i></a>
</h4>
<p>To close this chapter, let us run the same GLMM analysis in a frequentist framework using <code>lme4</code>.</p>
<p>We load the package:</p>
<div class="sourceCode" id="cb126"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/lme4/lme4/">lme4</a></span><span class="op">)</span></span></code></pre></div>
<p>Then we fit the GLMM (note that <code>brms</code> syntax is inspired by <code>lme4</code>):</p>
<div class="sourceCode" id="cb127"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_lme4</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/lme4/man/glmer.html">glmer</a></span><span class="op">(</span></span>
<span>  <span class="va">Ragondins</span> <span class="op">~</span> <span class="va">Temp</span> <span class="op">+</span> <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">Transect</span><span class="op">)</span>,  <span class="co"># full formula</span></span>
<span>  data   <span class="op">=</span> <span class="va">sim_simple</span>,               <span class="co"># simulated data set</span></span>
<span>  family <span class="op">=</span> <span class="va">poisson</span>                   <span class="co"># Poisson family for counts</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>Results:</p>
<div class="sourceCode" id="cb128"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">fit_lme4</span><span class="op">)</span></span>
<span><span class="co">#&gt; Generalized linear mixed model fit by maximum likelihood (Laplace</span></span>
<span><span class="co">#&gt;   Approximation) [glmerMod]</span></span>
<span><span class="co">#&gt;  Family: poisson  ( log )</span></span>
<span><span class="co">#&gt; Formula: Ragondins ~ Temp + (1 | Transect)</span></span>
<span><span class="co">#&gt;    Data: sim_simple</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;       AIC       BIC    logLik -2*log(L)  df.resid </span></span>
<span><span class="co">#&gt;     568.3     575.3    -281.1     562.3        75 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Scaled residuals: </span></span>
<span><span class="co">#&gt;     Min      1Q  Median      3Q     Max </span></span>
<span><span class="co">#&gt; -1.9501 -0.6223 -0.1098  0.4779  2.3897 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Random effects:</span></span>
<span><span class="co">#&gt;  Groups   Name        Variance Std.Dev.</span></span>
<span><span class="co">#&gt;  Transect (Intercept) 0.04402  0.2098  </span></span>
<span><span class="co">#&gt; Number of obs: 78, groups:  Transect, 10</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Fixed effects:</span></span>
<span><span class="co">#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    </span></span>
<span><span class="co">#&gt; (Intercept)  4.08804    0.06898  59.266  &lt; 2e-16 ***</span></span>
<span><span class="co">#&gt; Temp         0.15797    0.04863   3.248  0.00116 ** </span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Correlation of Fixed Effects:</span></span>
<span><span class="co">#&gt;      (Intr)</span></span>
<span><span class="co">#&gt; Temp -0.106</span></span></code></pre></div>
<p>How to read the output?</p>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="40%">
<col width="60%">
</colgroup>
<thead><tr class="header">
<th>Item</th>
<th>Meaning</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><code>(Intercept)</code></td>
<td>Mean log-abundance for a typical transect at mean Temp.</td>
</tr>
<tr class="even">
<td><code>Temp</code></td>
<td>Linear effect of temperature.</td>
</tr>
<tr class="odd">
<td><code>Random effects</code></td>
<td>SD (<code>Std.Dev</code>) of the random intercept.</td>
</tr>
</tbody>
</table></div>
<p>You will notice that parameter estimates are very close to those obtained with <code>brms</code> and <code>NIMBLE</code>.</p>
</div>
</div>
</div>
<div id="summary-2" class="section level2" number="6.4">
<h2>
<span class="header-section-number">6.4</span> Summary<a class="anchor" aria-label="anchor" href="#summary-2"><i class="fas fa-link"></i></a>
</h2>
<ul>
<li><p>Generalised linear models (GLMs) extend linear models to situations where a normal error assumption is not appropriate.</p></li>
<li><p>The general idea is to use a distribution adapted to the response – Bernoulli/binomial for binary responses (0/1), Poisson for counts (0, 1, 2, …) – and to link the mean of that distribution to predictors through a link function (such as logit or log).</p></li>
<li><p>Adding random effects allows us to model hierarchical grouping structures (e.g., sites, individuals, transects), capturing heterogeneity while sharing information across groups.</p></li>
<li><p>Generalised linear mixed models (GLMMs) jointly estimate fixed effects (population-level) and random effects (group-level, assumed drawn from a common distribution).</p></li>
<li><p>A <em>complete pooling</em> model ignores group structure and assumes all data follow the same relationship. This can bias conclusions if groups truly differ. A <em>no pooling</em> model fits separate relationships per group with no information sharing, leading to highly variable estimates when some groups have small sample sizes. <em>Partial pooling</em> (GLMMs / hierarchical models) is a compromise: groups have their own parameters, but these are linked by a common distribution. This improves stability while still respecting between-group differences.</p></li>
</ul>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="lms.html"><span class="header-section-number">5</span> Regression</a></div>
<div class="next"><a href="conclusions.html">Conclusions</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#glms"><span class="header-section-number">6</span> Generalized linear models, and generalized linear mixed models</a></li>
<li><a class="nav-link" href="#introduction-6"><span class="header-section-number">6.1</span> Introduction</a></li>
<li><a class="nav-link" href="#generalized-linear-models-glms"><span class="header-section-number">6.2</span> Generalized linear models (GLMs)</a></li>
<li>
<a class="nav-link" href="#generalized-linear-mixed-models-glmms"><span class="header-section-number">6.3</span> Generalized linear mixed models (GLMMs)</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#introduction-7"><span class="header-section-number">6.3.1</span> Introduction</a></li>
<li><a class="nav-link" href="#example"><span class="header-section-number">6.3.2</span> Example</a></li>
<li><a class="nav-link" href="#the-glm-approach"><span class="header-section-number">6.3.3</span> The GLM approach</a></li>
<li><a class="nav-link" href="#the-glmm-approach"><span class="header-section-number">6.3.4</span> The GLMM approach</a></li>
</ul>
</li>
<li><a class="nav-link" href="#summary-2"><span class="header-section-number">6.4</span> Summary</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/oliviergimenez/introduction-to-bayesian-statistics-with-R/blob/master/06-glms.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/oliviergimenez/introduction-to-bayesian-statistics-with-R/edit/master/06-glms.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Introduction to Bayesian Statistics with R</strong> using NIMBLE and brms" was written by Olivier Gimenez. Last updated 2026-02-24.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built with the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
